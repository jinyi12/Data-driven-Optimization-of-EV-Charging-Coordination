{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch.nn.functional import relu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import gurobipy as gb\n",
    "import time\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100 80GB PCIe (UUID: GPU-4045b1e6-3428-f9e1-5643-862c4834363d)\n",
      "GPU 1: NVIDIA A100 80GB PCIe (UUID: GPU-35ac16d5-81e8-f772-b9cb-a681af1fd2b5)\n",
      "  MIG 2g.20gb     Device  0: (UUID: MIG-0447e452-22d5-5021-ab0b-6cc63b39ac83)\n",
      "GPU 2: NVIDIA A100 80GB PCIe (UUID: GPU-d949dd0a-b88e-ee87-9621-3a824f914f82)\n",
      "GPU 3: NVIDIA A100 80GB PCIe (UUID: GPU-8c13f3ad-24ee-bb68-5eff-7f73091e682a)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  9 11:30:57 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:17:00.0 Off |                   On |\n",
      "| N/A   64C    P0   143W / 300W |  19347MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:65:00.0 Off |                   On |\n",
      "| N/A   35C    P0    44W / 300W |     24MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  On   | 00000000:CA:00.0 Off |                   On |\n",
      "| N/A   37C    P0    45W / 300W |     24MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  On   | 00000000:E3:00.0 Off |                   On |\n",
      "| N/A   36C    P0    45W / 300W |     24MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  1    4   0   0  |      6MiB / 19968MiB | 28      0 |  2   0    1    0    0 |\n",
      "|                  |      0MiB / 32767MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0    4    0    1462980      C   .../python/3.10.5/bin/python    19319MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set CUDA to MIG-30c35cbb-1b1b-56b5-a681-575ef4494c6d\n",
    "# set CUDA_VISIBLE_DEVICES=0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = (\n",
    "        False  # Force cuDNN to use a consistent convolution algorithm\n",
    "    )\n",
    "    torch.backends.cudnn.deterministic = (\n",
    "        True  # Force cuDNN to use deterministic algorithms if available\n",
    "    )\n",
    "    torch.use_deterministic_algorithms(\n",
    "        True\n",
    "    )  # Force torch to use deterministic algorithms if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_feature(X, n_var_node_features, n, n_var_nodes, binary_indices):      \n",
    "    # Calculate the column indices corresponding to the nth feature\n",
    "    n_var_node_features_raveled = n_var_node_features*n_var_nodes\n",
    "    X_feature = X[:, :n_var_node_features_raveled]\n",
    "    return X_feature[:, n::n_var_node_features][:, binary_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feasibility_constrain_weights(y_true, obj_coeffs):\n",
    "    \n",
    "    instance_weights = []\n",
    "    \n",
    "    # # y_true is a tensor of shape (batch_size, (arbritary shape), num_vars)\n",
    "    # # convert each array in y_true to a binary array\n",
    "    # y_true_binary = []\n",
    "    # for i in range(y_true.shape[0]):\n",
    "    #     binarized = np.zeros(y_true[i].shape)\n",
    "    #     binarized[y_true[i] > 0.5] = 1\n",
    "    #     y_true_binary.append(binarized)\n",
    "    # y_true_binary = np.array(y_true_binary)\n",
    "    \n",
    "    # Compute the weights for each training instance\n",
    "    \n",
    "    for i in range(y_true.shape[0]):\n",
    "                    \n",
    "        c = obj_coeffs[i]\n",
    "        w_ij = np.exp(-np.dot(c, y_true[i].T))\n",
    "\n",
    "        sum_w_ij = sum(w_ij)\n",
    "        \n",
    "        w_ij = w_ij / sum_w_ij\n",
    "    \n",
    "        instance_weights.append(w_ij)\n",
    "    \n",
    "    return np.array(instance_weights)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    corlat_dataset = pkl.load(open(\"Data/corlat/processed_data/corlat_preprocessed.pickle\", \"rb\"))\n",
    "except:\n",
    "    # move dir to /ibm/gpfs/home/yjin0055/Project/DayAheadForecast\n",
    "    os.chdir(\"/ibm/gpfs/home/yjin0055/Project/DayAheadForecast\")\n",
    "    corlat_dataset = pkl.load(open(\"Data/corlat/processed_data/corlat_preprocessed.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = corlat_dataset[0][\"var_node_features\"].shape[0]\n",
    "n_var_node_features = corlat_dataset[0][\"var_node_features\"].shape[1]\n",
    "max_constraint_size = corlat_dataset[0][\"constraint_node_features\"].shape[0]\n",
    "n_constraint_node_features = corlat_dataset[0][\"constraint_node_features\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all check the number of nodes and features\n",
    "for i in range(len(corlat_dataset)):\n",
    "    assert num_nodes == corlat_dataset[i][\"var_node_features\"].shape[0]\n",
    "    assert n_var_node_features == corlat_dataset[i][\"var_node_features\"].shape[1]\n",
    "    # assert max_constraint_size == corlat_dataset[i][\"constraint_node_features\"].shape[0]\n",
    "    assert n_constraint_node_features == corlat_dataset[i][\"constraint_node_features\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    corlat_presolved_dataset = pkl.load(open(\"Data/corlat_presolved/processed_data/corlat_presolved_preprocessed.pickle\", \"rb\"))\n",
    "except:\n",
    "    # move dir to /ibm/gpfs/home/yjin0055/Project/DayAheadForecast\n",
    "    os.chdir(\"/ibm/gpfs/home/yjin0055/Project/DayAheadForecast\")\n",
    "    corlat_presolved_dataset = pkl.load(open(\"Data/corlat_presolved/processed_data/corlat_presolved_preprocessed.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_presolved = corlat_presolved_dataset[0][\"var_node_features\"].shape[0]\n",
    "n_var_node_features_presolved = corlat_presolved_dataset[0][\"var_node_features\"].shape[1]\n",
    "max_constraint_size_presolved = corlat_presolved_dataset[0][\"constraint_node_features\"].shape[0]\n",
    "n_constraint_node_features_presolved = corlat_presolved_dataset[0][\"constraint_node_features\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# check the number of nodes and features\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(corlat_presolved_dataset)):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39massert\u001b[39;00m num_nodes_presolved \u001b[39m==\u001b[39m corlat_presolved_dataset[i][\u001b[39m\"\u001b[39m\u001b[39mvar_node_features\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     \u001b[39massert\u001b[39;00m n_var_node_features_presolved \u001b[39m==\u001b[39m corlat_presolved_dataset[i][\u001b[39m\"\u001b[39m\u001b[39mvar_node_features\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[39m# assert max_constraint_size_presolved == corlat_presolved_dataset[i][\"constraint_node_features\"].shape[0]\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# check the number of nodes and features\n",
    "for i in range(len(corlat_presolved_dataset)):\n",
    "    assert num_nodes_presolved == corlat_presolved_dataset[i][\"var_node_features\"].shape[0]\n",
    "    assert n_var_node_features_presolved == corlat_presolved_dataset[i][\"var_node_features\"].shape[1]\n",
    "    # assert max_constraint_size_presolved == corlat_presolved_dataset[i][\"constraint_node_features\"].shape[0]\n",
    "    assert n_constraint_node_features_presolved == corlat_presolved_dataset[i][\"constraint_node_features\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_indices = corlat_dataset[0][\"indices\"][\"indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read X_train, X_test, y_train, y_test from Data/corlat/ using numpy.load\n",
    "X_train = np.load(\"Data/corlat/X_train.npy\")\n",
    "X_test = np.load(\"Data/corlat/X_test.npy\")\n",
    "y_train = np.load(\"Data/corlat/y_train.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"Data/corlat/y_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each instance in y_train and y_test, convert it to binary\n",
    "for i in range(y_train.shape[0]):\n",
    "    # make all values positive using abs\n",
    "    # y_train[i] is a tensor of shape (arbritary shape), num_vars\n",
    "    y_train[i] = np.abs(y_train[i])\n",
    "    \n",
    "    # use numpy where to convert values > 0.5 to 1, and values <= 0.5 to 0\n",
    "    y_train[i] = np.where(y_train[i] > 0.5, 1.0, 0.0)\n",
    "    \n",
    "for i in range(y_test.shape[0]):\n",
    "    # make all values positive using abs\n",
    "    # y_train[i] is a tensor of shape (arbritary shape), num_vars\n",
    "    y_test[i] = np.abs(y_test[i])\n",
    "    \n",
    "    # use numpy where to convert values > 0.5 to 1, and values <= 0.5 to 0\n",
    "    y_test[i] = np.where(y_test[i] > 0.5, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 1.],\n",
       "       [1., 1., 1., ..., 0., 0., 1.],\n",
       "       [1., 1., 1., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 1.],\n",
       "       [1., 1., 1., ..., 0., 0., 1.],\n",
       "       [1., 1., 1., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test indices\n",
    "train_indices = np.load(\"Data/corlat/train_idx.npy\")\n",
    "test_indices = np.load(\"Data/corlat/test_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "out_channels = y_train[0].shape[1]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features:  13898\n",
      "out_channels:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"n_features: \", n_features)\n",
    "print(\"out_channels: \", out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_coeffs = get_nth_feature(X_train, n_var_node_features, 0, num_nodes, binary_indices)\n",
    "test_obj_coeffs = get_nth_feature(X_test, n_var_node_features, 0, num_nodes, binary_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_obj_coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1948759/699886795.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(instance_weights)\n"
     ]
    }
   ],
   "source": [
    "weights = get_feasibility_constrain_weights(y_train, train_obj_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices_dict = {}\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    \n",
    "    # get indices of weights that are nan\n",
    "    nan_indices = np.argwhere(np.isnan(weights[i]))\n",
    "    nan_indices_dict[i] = nan_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find non empty dictionary values\n",
    "for i in range(len(nan_indices_dict)):\n",
    "    if len(nan_indices_dict[i]) > 0:\n",
    "        print(\"nan indices for instance \", i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_features//8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(n_features//8, n_features//16)\n",
    "        self.fc3 = nn.Linear(n_features//16, n_features//32)\n",
    "        self.fc4 = nn.Linear(n_features//32, out_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # add regularization\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'train_val_split': [0.80, 0.20], # These must sum to 1.0\n",
    "        'batch_size' : 32, # Num samples to average over for gradient updates\n",
    "        'EPOCHS' : 1000, # Num times to iterate over the entire dataset\n",
    "        'LEARNING_RATE' : 1e-3, # Learning rate for the optimizer\n",
    "        'BETA1' : 0.9, # Beta1 parameter for the Adam optimizer\n",
    "        'BETA2' : 0.999, # Beta2 parameter for the Adam optimizer\n",
    "        'WEIGHT_DECAY' : 1e-4, # Weight decay parameter for the Adam optimizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multipleTargetCORLATDataset(TensorDataset):\n",
    "    def __init__(self, X, y, weights=None, test=False):\n",
    "        super(multipleTargetCORLATDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = weights\n",
    "        self.test = test\n",
    "        # self.obj_coeffs = get_nth_feature(self.X, 1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        # duplicate X to match the number of targets\n",
    "        # X = np.repeat(X[np.newaxis,:], y.shape[0], axis=0)\n",
    "    \n",
    "        if self.weights is None and self.test:\n",
    "            return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        \n",
    "        weights = self.weights[index]\n",
    "        \n",
    "        \n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "        weights_tensor = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "        # obj_coeffs_tensor = torch.tensor(self.obj_coeffs[index], dtype=torch.float32)\n",
    "        return X_tensor, y_tensor, weights_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "\n",
    "def collate_fn(data):\n",
    "    # data is a list of tuples (X, Y, weights)\n",
    "    # X_list = []\n",
    "    # Y_list = []\n",
    "    # weights_list = []\n",
    "    # for item in data:        \n",
    "    \n",
    "    X = torch.stack([item[0] for item in data])\n",
    "    Y = [item[1] for item in data]\n",
    "    \n",
    "    \n",
    "    # only X, and Y no weights\n",
    "    if len(data[0]) == 2:\n",
    "        return X, Y    \n",
    "    \n",
    "    weights = [item[2] for item in data]\n",
    "    #     X_list.append(item[0])\n",
    "    #     Y_list.append(item[1])\n",
    "    #     weights_list.append(item[2])\n",
    "    \n",
    "    # X = torch.stack(X_list)\n",
    "    # Y = torch.cat(Y_list)\n",
    "    # weights = torch.cat(weights_list)\n",
    "    \n",
    "    return X, Y, weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = multipleTargetCORLATDataset(X_train, y_train, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = multipleTargetCORLATDataset(X_test, y_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()\n",
    "# net = torch.compile(net)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "# create the dataloader for X and solutions\n",
    "# train_loader = DataLoader(\n",
    "#     TensorDataset(torch.tensor(X_train), torch.tensor(y_train)),\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# valid_loader = DataLoader(\n",
    "#     TensorDataset(torch.tensor(X_test), torch.tensor(y_test)),\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n",
    "batch_size_test = 32\n",
    "valid_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "params = list(net.parameters())\n",
    "\n",
    "# optimizer = AdamW(params, lr=config['LEARNING_RATE'], weight_decay=1e-4)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "# optimizer = dadaptation.DAdaptAdam(params, lr=1, log_every=5, betas=(BETA1, BETA2), weight_decay=1e-4, decouple=True)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "total_steps = len(train_loader)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config['LEARNING_RATE'], steps_per_epoch=total_steps, epochs=config['EPOCHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss for neural network\n",
    "\n",
    "# @torch.compile\n",
    "def custom_loss(y_pred: torch.tensor, y_true: torch.tensor, weights: torch.tensor, device: torch.device):\n",
    "    # sourcery skip: raise-specific-error\n",
    "    \n",
    "    batch_loss = []\n",
    "    \n",
    "    loss_fn = nn.BCELoss(reduction='none')\n",
    "    \n",
    "    # # go through all of y_true and calculate the loss for each target\n",
    "    # for i in range(y_true.shape[0]):\n",
    "    #     loss = torch.sum(loss_fn(y_pred, y_true[i]))\n",
    "    #     loss = torch.mul(loss, weights[i])\n",
    "    #     batch_loss.append(loss)\n",
    "        \n",
    "    # sum over all targets\n",
    "    for i in range(len(y_true)):\n",
    "        loss = torch.mean(loss_fn(y_pred[i].expand(len(y_true[i]), -1), y_true[i].to(device)), dim=1)\n",
    "        loss = torch.mul(loss, weights[i].to(device))\n",
    "        batch_loss.append(torch.sum(loss))\n",
    "        \n",
    "    # batch_loss = torch.sum(loss_fn(y_pred.unsqueeze(1).expand(-1, len(y_true), -1), y_true), dim=1)\n",
    "    # batch_loss = torch.sum(torch.stack(batch_loss), dim=0)\n",
    "    \n",
    "    # # multiply by weights\n",
    "    # batch_loss = torch.mul(batch_loss, weights)\n",
    "    \n",
    "    # # now sum over all samples\n",
    "    # batch_loss = torch.sum(batch_loss)\n",
    "    \n",
    "    # sum over all samples\n",
    "    batch_loss = torch.mean(torch.stack(batch_loss))\n",
    "    \n",
    "    # if torch.isnan(batch_loss):\n",
    "    #     print(\"y_pred: \", y_pred)\n",
    "    #     print(\"y_true: \", y_true)\n",
    "    #     print(\"weights: \", weights)\n",
    "    #     print(\"batch_loss: \", batch_loss)\n",
    "    #     raise Exception(\"Loss is NaN\")\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.685 lr: 0.000040\n",
      "Epoch 2 loss: 0.636 lr: 0.000040\n",
      "Epoch 3 loss: 0.603 lr: 0.000040\n",
      "Epoch 4 loss: 0.562 lr: 0.000040\n",
      "Epoch 5 loss: 0.538 lr: 0.000040\n",
      "Epoch 6 loss: 0.532 lr: 0.000041\n",
      "Epoch 7 loss: 0.527 lr: 0.000041\n",
      "Epoch 8 loss: 0.523 lr: 0.000041\n",
      "Epoch 9 loss: 0.522 lr: 0.000042\n",
      "Epoch 10 loss: 0.523 lr: 0.000042\n",
      "Epoch 11 loss: 0.520 lr: 0.000043\n",
      "Epoch 12 loss: 0.519 lr: 0.000043\n",
      "Epoch 13 loss: 0.520 lr: 0.000044\n",
      "Epoch 14 loss: 0.517 lr: 0.000044\n",
      "Epoch 15 loss: 0.517 lr: 0.000045\n",
      "Epoch 16 loss: 0.516 lr: 0.000046\n",
      "Epoch 17 loss: 0.516 lr: 0.000047\n",
      "Epoch 18 loss: 0.515 lr: 0.000048\n",
      "Epoch 19 loss: 0.514 lr: 0.000049\n",
      "Epoch 20 loss: 0.514 lr: 0.000049\n",
      "Epoch 21 loss: 0.512 lr: 0.000050\n",
      "Epoch 22 loss: 0.510 lr: 0.000052\n",
      "Epoch 23 loss: 0.507 lr: 0.000053\n",
      "Epoch 24 loss: 0.505 lr: 0.000054\n",
      "Epoch 25 loss: 0.502 lr: 0.000055\n",
      "Epoch 26 loss: 0.505 lr: 0.000056\n",
      "Epoch 27 loss: 0.504 lr: 0.000058\n",
      "Epoch 28 loss: 0.504 lr: 0.000059\n",
      "Epoch 29 loss: 0.503 lr: 0.000060\n",
      "Epoch 30 loss: 0.501 lr: 0.000062\n",
      "Epoch 31 loss: 0.498 lr: 0.000063\n",
      "Epoch 32 loss: 0.500 lr: 0.000065\n",
      "Epoch 33 loss: 0.498 lr: 0.000067\n",
      "Epoch 34 loss: 0.496 lr: 0.000068\n",
      "Epoch 35 loss: 0.495 lr: 0.000070\n",
      "Epoch 36 loss: 0.494 lr: 0.000072\n",
      "Epoch 37 loss: 0.491 lr: 0.000074\n",
      "Epoch 38 loss: 0.491 lr: 0.000076\n",
      "Epoch 39 loss: 0.494 lr: 0.000078\n",
      "Epoch 40 loss: 0.491 lr: 0.000079\n",
      "Epoch 41 loss: 0.489 lr: 0.000082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 23\u001b[0m     loss_list\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m     24\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m loss: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m lr: \u001b[39m\u001b[39m%.6f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, running_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader), curr_lr))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "for epoch in range(config[\"EPOCHS\"]):\n",
    "    running_loss = 0.0\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels, weights = data\n",
    "        \n",
    "        inputs = inputs.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # convert outputs to binary\n",
    "        # outputs = torch.where(outputs > 0.5, 1.0, 0.0)\n",
    "        \n",
    "        # require grad for outputs\n",
    "        # outputs.requires_grad = True\n",
    "        \n",
    "        loss = custom_loss(outputs, labels, weights, device=device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        loss_list.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f lr: %.6f' % (epoch + 1, running_loss / len(train_loader), curr_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"Data/corlat/neural_network_multiple_targets.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model\n",
    "# if not os.path.exists(\"Data/corlat/neural_network_multiple_targets.pt\"):\n",
    "#     torch.save(net.state_dict(), \"Data/corlat/neural_network_multiple_targets.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "net = NeuralNetwork()\n",
    "net.load_state_dict(torch.load(\"Data/corlat/neural_network_multiple_targets.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (fc1): Linear(in_features=13898, out_features=1737, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=1737, out_features=868, bias=True)\n",
       "  (fc3): Linear(in_features=868, out_features=434, bias=True)\n",
       "  (fc4): Linear(in_features=434, out_features=100, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test number of feasible solutions\n",
    "# test the model on the test set\n",
    "net.eval()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feasibility_test(batch_size, y_pred, test_models, indices):\n",
    "    \n",
    "    n_violated_constraints = []\n",
    "\n",
    "    # convert predictions of N_samples, N_variables to binary\n",
    "    # y_pred_binary = y_pred[0]\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "    \n",
    "    # Compute the weights for each training instance\n",
    "    for i in range(len(test_models)):\n",
    "        \n",
    "        model = test_models[i]\n",
    "        \n",
    "        modelVars = model.getVars()\n",
    "        \n",
    "        instanceBinaryIndices = indices\n",
    "\n",
    "        # need to relax the binary variables to continuous variables with bounds of 0 and 1, we can use the setAttr method to change their vtype attribute\n",
    "        for j in range(len(instanceBinaryIndices)):\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"C\")\n",
    "\n",
    "            # for each index in firstInstanceTestBinaryIndices, set the value of the corresponding variable to the value predicted by xgboost\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "        \n",
    "        \n",
    "        # Compute the IIS to find the list of violated constraints and variables\n",
    "        try:\n",
    "            model.computeIIS()\n",
    "        except gb.GurobiError:\n",
    "            print(\"Model is feasible\")\n",
    "            n_violated_constraints.append(0)\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # get number of violated constraints\n",
    "        IISConstr = model.getAttr(\"IISConstr\", model.getConstrs())\n",
    "\n",
    "        # count number of non zero elements in IISConstr        \n",
    "        n_violated_constraints.append(np.count_nonzero(IISConstr))\n",
    "        \n",
    "    return n_violated_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-01\n"
     ]
    }
   ],
   "source": [
    "test_models = []\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "model_files = os.listdir(\"instances/mip/data/COR-LAT\")\n",
    "for i in range(len(test_indices)):\n",
    "    model = gb.read(\"instances/mip/data/COR-LAT/\" + model_files[test_indices[i]], env=gurobi_env)\n",
    "    test_models.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model objective sense:  -1\n"
     ]
    }
   ],
   "source": [
    "model.ModelSense\n",
    "# if -1, minimize, if 1, maximize\n",
    "print(\"Model objective sense: \", model.ModelSense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<', '=', '=', '=', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '<', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '<', '=', '=', '=', '=', '=']\n"
     ]
    }
   ],
   "source": [
    "obj = model.getObjective()\n",
    "print(model.getAttr(\"Sense\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "2\n",
      "3\n",
      "Model is feasible\n",
      "4\n",
      "Model is feasible\n",
      "5\n",
      "Model is feasible\n",
      "6\n",
      "7\n",
      "8\n",
      "Model is feasible\n",
      "9\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "10\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "11\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "n_violated_constraints = []\n",
    "for i, data in enumerate(valid_loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # get slices of test_models according to batch size\n",
    "    len_test_models = len(test_models)\n",
    "    print(i)\n",
    "    test_models_batch = test_models[i*batch_size: min((i+1)*batch_size, len_test_models)]\n",
    "    \n",
    "    n_violated_constraints_batch = feasibility_test(batch_size_test, outputs.detach().cpu().numpy(), test_models_batch, binary_indices)\n",
    "    \n",
    "    n_violated_constraints.append(n_violated_constraints_batch)\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten n_violated_constraints\n",
    "n_violated_constraints = [item for sublist in n_violated_constraints for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of violated constraints:  2.7425\n",
      "Length of n_violated_constraints:  400\n",
      "[1, 2, 1, 18, 1, 1, 1, 1, 1, 2, 1, 1, 17, 1, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 11, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 17, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 11, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 14, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 78, 1, 1, 1, 1, 0, 39, 1, 1, 2, 1, 1, 1, 29, 1, 56, 1, 1, 2, 1, 2, 1, 1, 1, 10, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 31, 1, 2, 1, 1, 1, 2, 1, 1, 27, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 12, 1, 1, 2, 1, 1, 1, 36, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 17, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 29, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 12, 1, 1, 17, 1, 1, 1, 1, 16, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 10, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 21, 27, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 21, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 32, 2, 0, 18, 2, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 34, 2, 2, 1, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of violated constraints: \", np.mean(n_violated_constraints))\n",
    "print(\"Length of n_violated_constraints: \", len(n_violated_constraints))\n",
    "print(n_violated_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-01\n",
      "Optimization time for model  0 :  0.25441479682922363\n",
      "Optimization time for model  1 :  1.4637858867645264\n",
      "Optimization time for model  2 :  0.0034940242767333984\n",
      "Optimization time for model  3 :  0.003582000732421875\n",
      "Optimization time for model  4 :  1.8587779998779297\n",
      "Optimization time for model  5 :  0.4851109981536865\n",
      "Optimization time for model  6 :  0.04686594009399414\n",
      "Optimization time for model  7 :  0.0022830963134765625\n",
      "Optimization time for model  8 :  0.23017191886901855\n",
      "Optimization time for model  9 :  1.0154509544372559\n",
      "Optimization time for model  10 :  2.583364963531494\n",
      "Optimization time for model  11 :  0.37306904792785645\n",
      "Optimization time for model  12 :  6.502914905548096\n",
      "Optimization time for model  13 :  0.19873905181884766\n",
      "Optimization time for model  14 :  0.14092206954956055\n",
      "Optimization time for model  15 :  0.3008110523223877\n",
      "Optimization time for model  16 :  0.5658800601959229\n",
      "Optimization time for model  17 :  0.8419969081878662\n",
      "Optimization time for model  18 :  0.13121795654296875\n",
      "Optimization time for model  19 :  0.3622579574584961\n",
      "Optimization time for model  20 :  1.3086628913879395\n",
      "Optimization time for model  21 :  1.0187768936157227\n",
      "Optimization time for model  22 :  1.9248929023742676\n",
      "Optimization time for model  23 :  0.003503084182739258\n",
      "Optimization time for model  24 :  1.4404308795928955\n",
      "Optimization time for model  25 :  0.7573428153991699\n",
      "Optimization time for model  26 :  1.9598979949951172\n",
      "Optimization time for model  27 :  0.006587982177734375\n",
      "Optimization time for model  28 :  1.4092528820037842\n",
      "Optimization time for model  29 :  0.08280801773071289\n",
      "Optimization time for model  30 :  0.32784414291381836\n",
      "Optimization time for model  31 :  0.10582804679870605\n",
      "Optimization time for model  32 :  1.237339973449707\n",
      "Optimization time for model  33 :  0.18960809707641602\n",
      "Optimization time for model  34 :  2.0105478763580322\n",
      "Optimization time for model  35 :  6.495073080062866\n",
      "Optimization time for model  36 :  0.7120840549468994\n",
      "Optimization time for model  37 :  0.18935084342956543\n",
      "Optimization time for model  38 :  3.5391600131988525\n",
      "Optimization time for model  39 :  1.9165940284729004\n",
      "Optimization time for model  40 :  0.0034439563751220703\n",
      "Optimization time for model  41 :  0.054327964782714844\n",
      "Optimization time for model  42 :  0.5700101852416992\n",
      "Optimization time for model  43 :  0.07551002502441406\n",
      "Optimization time for model  44 :  2.3572030067443848\n",
      "Optimization time for model  45 :  0.7169899940490723\n",
      "Optimization time for model  46 :  0.12383508682250977\n",
      "Optimization time for model  47 :  0.0007519721984863281\n",
      "Optimization time for model  48 :  0.02456498146057129\n",
      "Optimization time for model  49 :  1.0169708728790283\n",
      "Optimization time for model  50 :  0.003477811813354492\n",
      "Optimization time for model  51 :  0.13340306282043457\n",
      "Optimization time for model  52 :  0.007195949554443359\n",
      "Optimization time for model  53 :  0.27443480491638184\n",
      "Optimization time for model  54 :  0.48755908012390137\n",
      "Optimization time for model  55 :  0.006181001663208008\n",
      "Optimization time for model  56 :  1.3006389141082764\n",
      "Optimization time for model  57 :  2.2042009830474854\n",
      "Optimization time for model  58 :  0.1939089298248291\n",
      "Optimization time for model  59 :  3.498966932296753\n",
      "Optimization time for model  60 :  1.2401340007781982\n",
      "Optimization time for model  61 :  1.3489480018615723\n",
      "Optimization time for model  62 :  4.427678108215332\n",
      "Optimization time for model  63 :  0.14976882934570312\n",
      "Optimization time for model  64 :  2.7134029865264893\n",
      "Optimization time for model  65 :  0.003648996353149414\n",
      "Optimization time for model  66 :  0.3721590042114258\n",
      "Optimization time for model  67 :  2.6497931480407715\n",
      "Optimization time for model  68 :  1.302785873413086\n",
      "Optimization time for model  69 :  0.4802229404449463\n",
      "Optimization time for model  70 :  0.0073168277740478516\n",
      "Optimization time for model  71 :  0.0014178752899169922\n",
      "Optimization time for model  72 :  1.6648578643798828\n",
      "Optimization time for model  73 :  1.1623640060424805\n",
      "Optimization time for model  74 :  0.7778170108795166\n",
      "Optimization time for model  75 :  3.452983856201172\n",
      "Optimization time for model  76 :  1.969878911972046\n",
      "Optimization time for model  77 :  2.216008186340332\n",
      "Optimization time for model  78 :  0.0066339969635009766\n",
      "Optimization time for model  79 :  0.09551501274108887\n",
      "Optimization time for model  80 :  1.1385269165039062\n",
      "Optimization time for model  81 :  0.0014820098876953125\n",
      "Optimization time for model  82 :  0.7330169677734375\n",
      "Optimization time for model  83 :  0.047734975814819336\n",
      "Optimization time for model  84 :  0.5905768871307373\n",
      "Optimization time for model  85 :  1.43296217918396\n",
      "Optimization time for model  86 :  0.257587194442749\n",
      "Optimization time for model  87 :  2.4042441844940186\n",
      "Optimization time for model  88 :  0.3448920249938965\n",
      "Optimization time for model  89 :  1.8242390155792236\n",
      "Optimization time for model  90 :  3.4834649562835693\n",
      "Optimization time for model  91 :  0.06454586982727051\n",
      "Optimization time for model  92 :  0.05613303184509277\n",
      "Optimization time for model  93 :  0.35213804244995117\n",
      "Optimization time for model  94 :  1.6796338558197021\n",
      "Optimization time for model  95 :  4.236342191696167\n",
      "Optimization time for model  96 :  0.0009701251983642578\n",
      "Optimization time for model  97 :  4.4931910037994385\n",
      "Optimization time for model  98 :  0.010963916778564453\n",
      "Optimization time for model  99 :  4.745811939239502\n",
      "Optimization time for model  100 :  4.306940078735352\n",
      "Optimization time for model  101 :  1.7491040229797363\n",
      "Optimization time for model  102 :  0.2228078842163086\n",
      "Optimization time for model  103 :  0.7512290477752686\n",
      "Optimization time for model  104 :  0.02113199234008789\n",
      "Optimization time for model  105 :  2.5986039638519287\n",
      "Optimization time for model  106 :  2.0503618717193604\n",
      "Optimization time for model  107 :  0.0007278919219970703\n",
      "Optimization time for model  108 :  0.17394280433654785\n",
      "Optimization time for model  109 :  2.7896761894226074\n",
      "Optimization time for model  110 :  3.3706250190734863\n",
      "Optimization time for model  111 :  0.0007379055023193359\n",
      "Optimization time for model  112 :  1.2346398830413818\n",
      "Optimization time for model  113 :  1.3061211109161377\n",
      "Optimization time for model  114 :  1.4253041744232178\n",
      "Optimization time for model  115 :  0.11374020576477051\n",
      "Optimization time for model  116 :  2.743946075439453\n",
      "Optimization time for model  117 :  2.486027956008911\n",
      "Optimization time for model  118 :  0.3408980369567871\n",
      "Optimization time for model  119 :  0.08757805824279785\n",
      "Optimization time for model  120 :  0.002878904342651367\n",
      "Optimization time for model  121 :  0.31144094467163086\n",
      "Optimization time for model  122 :  0.04112505912780762\n",
      "Optimization time for model  123 :  2.065706968307495\n",
      "Optimization time for model  124 :  2.822100877761841\n",
      "Optimization time for model  125 :  0.054032087326049805\n",
      "Optimization time for model  126 :  6.89272403717041\n",
      "Optimization time for model  127 :  2.5481460094451904\n",
      "Optimization time for model  128 :  0.13431501388549805\n",
      "Optimization time for model  129 :  0.0014700889587402344\n",
      "Optimization time for model  130 :  5.540101051330566\n",
      "Optimization time for model  131 :  0.04721784591674805\n",
      "Optimization time for model  132 :  0.652285099029541\n",
      "Optimization time for model  133 :  0.0008790493011474609\n",
      "Optimization time for model  134 :  0.82315993309021\n",
      "Optimization time for model  135 :  0.30370593070983887\n",
      "Optimization time for model  136 :  2.768734931945801\n",
      "Optimization time for model  137 :  2.792638063430786\n",
      "Optimization time for model  138 :  12.20737600326538\n",
      "Optimization time for model  139 :  0.016330957412719727\n",
      "Optimization time for model  140 :  0.0016918182373046875\n",
      "Optimization time for model  141 :  1.4303081035614014\n",
      "Optimization time for model  142 :  0.8737139701843262\n",
      "Optimization time for model  143 :  6.568424940109253\n",
      "Optimization time for model  144 :  0.014863967895507812\n",
      "Optimization time for model  145 :  0.0010640621185302734\n",
      "Optimization time for model  146 :  1.8379201889038086\n",
      "Optimization time for model  147 :  7.239251136779785\n",
      "Optimization time for model  148 :  1.0621278285980225\n",
      "Optimization time for model  149 :  0.0034918785095214844\n",
      "Optimization time for model  150 :  3.6518819332122803\n",
      "Optimization time for model  151 :  0.18520116806030273\n",
      "Optimization time for model  152 :  1.681555986404419\n",
      "Optimization time for model  153 :  0.0035178661346435547\n",
      "Optimization time for model  154 :  0.11381101608276367\n",
      "Optimization time for model  155 :  0.0024411678314208984\n",
      "Optimization time for model  156 :  0.0036249160766601562\n",
      "Optimization time for model  157 :  0.398252010345459\n",
      "Optimization time for model  158 :  1.7793550491333008\n",
      "Optimization time for model  159 :  0.18422508239746094\n",
      "Optimization time for model  160 :  0.7496190071105957\n",
      "Optimization time for model  161 :  1.3934190273284912\n",
      "Optimization time for model  162 :  1.6588399410247803\n",
      "Optimization time for model  163 :  0.01369619369506836\n",
      "Optimization time for model  164 :  1.4218811988830566\n",
      "Optimization time for model  165 :  5.441576957702637\n",
      "Optimization time for model  166 :  3.6536409854888916\n",
      "Optimization time for model  167 :  0.0035219192504882812\n",
      "Optimization time for model  168 :  6.480052947998047\n",
      "Optimization time for model  169 :  1.8369739055633545\n",
      "Optimization time for model  170 :  0.39301109313964844\n",
      "Optimization time for model  171 :  0.8500270843505859\n",
      "Optimization time for model  172 :  1.484386920928955\n",
      "Optimization time for model  173 :  3.0778491497039795\n",
      "Optimization time for model  174 :  0.025015830993652344\n",
      "Optimization time for model  175 :  0.006910085678100586\n",
      "Optimization time for model  176 :  1.6674630641937256\n",
      "Optimization time for model  177 :  0.5973939895629883\n",
      "Optimization time for model  178 :  0.009438037872314453\n",
      "Optimization time for model  179 :  2.102254867553711\n",
      "Optimization time for model  180 :  2.5268630981445312\n",
      "Optimization time for model  181 :  0.36783504486083984\n",
      "Optimization time for model  182 :  2.505868911743164\n",
      "Optimization time for model  183 :  1.7586438655853271\n",
      "Optimization time for model  184 :  0.003496885299682617\n",
      "Optimization time for model  185 :  0.006433010101318359\n",
      "Optimization time for model  186 :  0.003643035888671875\n",
      "Optimization time for model  187 :  2.6419100761413574\n",
      "Optimization time for model  188 :  1.2016420364379883\n",
      "Optimization time for model  189 :  3.996664047241211\n",
      "Optimization time for model  190 :  1.2703330516815186\n",
      "Optimization time for model  191 :  2.275085926055908\n",
      "Optimization time for model  192 :  0.0074748992919921875\n",
      "Optimization time for model  193 :  2.5342400074005127\n",
      "Optimization time for model  194 :  0.05887889862060547\n",
      "Optimization time for model  195 :  1.9522099494934082\n",
      "Optimization time for model  196 :  0.26386594772338867\n",
      "Optimization time for model  197 :  0.5847599506378174\n",
      "Optimization time for model  198 :  0.10410308837890625\n",
      "Optimization time for model  199 :  0.10632705688476562\n",
      "Optimization time for model  200 :  0.174576997756958\n",
      "Optimization time for model  201 :  0.2182769775390625\n",
      "Optimization time for model  202 :  0.06848001480102539\n",
      "Optimization time for model  203 :  2.460955858230591\n",
      "Optimization time for model  204 :  1.2194252014160156\n",
      "Optimization time for model  205 :  0.05990886688232422\n",
      "Optimization time for model  206 :  0.4120290279388428\n",
      "Optimization time for model  207 :  2.25216007232666\n",
      "Optimization time for model  208 :  0.34431910514831543\n",
      "Optimization time for model  209 :  0.015533208847045898\n",
      "Optimization time for model  210 :  0.00333404541015625\n",
      "Optimization time for model  211 :  0.1901860237121582\n",
      "Optimization time for model  212 :  0.09283113479614258\n",
      "Optimization time for model  213 :  6.711112022399902\n",
      "Optimization time for model  214 :  0.030391931533813477\n",
      "Optimization time for model  215 :  0.01065206527709961\n",
      "Optimization time for model  216 :  0.007256984710693359\n",
      "Optimization time for model  217 :  11.84875202178955\n",
      "Optimization time for model  218 :  1.3561639785766602\n",
      "Optimization time for model  219 :  0.25226306915283203\n",
      "Optimization time for model  220 :  0.22336697578430176\n",
      "Optimization time for model  221 :  0.08136796951293945\n",
      "Optimization time for model  222 :  0.27864694595336914\n",
      "Optimization time for model  223 :  0.358212947845459\n",
      "Optimization time for model  224 :  1.618095874786377\n",
      "Optimization time for model  225 :  1.6074800491333008\n",
      "Optimization time for model  226 :  2.5504860877990723\n",
      "Optimization time for model  227 :  0.05417203903198242\n",
      "Optimization time for model  228 :  2.157256841659546\n",
      "Optimization time for model  229 :  1.6093111038208008\n",
      "Optimization time for model  230 :  0.23374104499816895\n",
      "Optimization time for model  231 :  1.3062918186187744\n",
      "Optimization time for model  232 :  0.0035309791564941406\n",
      "Optimization time for model  233 :  2.9603519439697266\n",
      "Optimization time for model  234 :  0.8412878513336182\n",
      "Optimization time for model  235 :  10.823835134506226\n",
      "Optimization time for model  236 :  1.803206205368042\n",
      "Optimization time for model  237 :  4.073400974273682\n",
      "Optimization time for model  238 :  0.32030701637268066\n",
      "Optimization time for model  239 :  2.298814058303833\n",
      "Optimization time for model  240 :  1.6554229259490967\n",
      "Optimization time for model  241 :  2.927809953689575\n",
      "Optimization time for model  242 :  0.25637006759643555\n",
      "Optimization time for model  243 :  0.4925861358642578\n",
      "Optimization time for model  244 :  0.13016605377197266\n",
      "Optimization time for model  245 :  0.0034890174865722656\n",
      "Optimization time for model  246 :  4.278681039810181\n",
      "Optimization time for model  247 :  10.698003053665161\n",
      "Optimization time for model  248 :  1.1734530925750732\n",
      "Optimization time for model  249 :  0.08050012588500977\n",
      "Optimization time for model  250 :  0.1034860610961914\n",
      "Optimization time for model  251 :  0.09876394271850586\n",
      "Optimization time for model  252 :  0.628770112991333\n",
      "Optimization time for model  253 :  0.022799968719482422\n",
      "Optimization time for model  254 :  0.000885009765625\n",
      "Optimization time for model  255 :  0.4262540340423584\n",
      "Optimization time for model  256 :  0.09073996543884277\n",
      "Optimization time for model  257 :  2.8353700637817383\n",
      "Optimization time for model  258 :  0.3926091194152832\n",
      "Optimization time for model  259 :  2.0273611545562744\n",
      "Optimization time for model  260 :  0.00837397575378418\n",
      "Optimization time for model  261 :  0.0035560131072998047\n",
      "Optimization time for model  262 :  1.8571841716766357\n",
      "Optimization time for model  263 :  6.189863204956055\n",
      "Optimization time for model  264 :  0.23076891899108887\n",
      "Optimization time for model  265 :  2.934558153152466\n",
      "Optimization time for model  266 :  0.006147861480712891\n",
      "Optimization time for model  267 :  0.0012221336364746094\n",
      "Optimization time for model  268 :  1.3564579486846924\n",
      "Optimization time for model  269 :  0.007133960723876953\n",
      "Optimization time for model  270 :  0.3664989471435547\n",
      "Optimization time for model  271 :  0.010667085647583008\n",
      "Optimization time for model  272 :  0.08518004417419434\n",
      "Optimization time for model  273 :  8.294429063796997\n",
      "Optimization time for model  274 :  0.41306209564208984\n",
      "Optimization time for model  275 :  2.2753779888153076\n",
      "Optimization time for model  276 :  0.012338876724243164\n",
      "Optimization time for model  277 :  2.4872348308563232\n",
      "Optimization time for model  278 :  0.07886815071105957\n",
      "Optimization time for model  279 :  0.10187697410583496\n",
      "Optimization time for model  280 :  0.3077571392059326\n",
      "Optimization time for model  281 :  0.4260900020599365\n",
      "Optimization time for model  282 :  0.3940720558166504\n",
      "Optimization time for model  283 :  0.29645514488220215\n",
      "Optimization time for model  284 :  0.004691123962402344\n",
      "Optimization time for model  285 :  4.436426877975464\n",
      "Optimization time for model  286 :  0.48836588859558105\n",
      "Optimization time for model  287 :  1.6961729526519775\n",
      "Optimization time for model  288 :  0.08216190338134766\n",
      "Optimization time for model  289 :  8.431641101837158\n",
      "Optimization time for model  290 :  0.33736181259155273\n",
      "Optimization time for model  291 :  0.010432958602905273\n",
      "Optimization time for model  292 :  0.0074579715728759766\n",
      "Optimization time for model  293 :  3.1213860511779785\n",
      "Optimization time for model  294 :  0.0033538341522216797\n",
      "Optimization time for model  295 :  0.003612995147705078\n",
      "Optimization time for model  296 :  1.4066600799560547\n",
      "Optimization time for model  297 :  1.7519779205322266\n",
      "Optimization time for model  298 :  0.2170109748840332\n",
      "Optimization time for model  299 :  0.003645181655883789\n",
      "Optimization time for model  300 :  1.7332301139831543\n",
      "Optimization time for model  301 :  0.00628209114074707\n",
      "Optimization time for model  302 :  1.5822858810424805\n",
      "Optimization time for model  303 :  0.9830911159515381\n",
      "Optimization time for model  304 :  0.7949450016021729\n",
      "Optimization time for model  305 :  0.003609895706176758\n",
      "Optimization time for model  306 :  0.040959835052490234\n",
      "Optimization time for model  307 :  0.06562280654907227\n",
      "Optimization time for model  308 :  1.2355310916900635\n",
      "Optimization time for model  309 :  0.0034029483795166016\n",
      "Optimization time for model  310 :  0.13572287559509277\n",
      "Optimization time for model  311 :  0.09901905059814453\n",
      "Optimization time for model  312 :  0.20908594131469727\n",
      "Optimization time for model  313 :  0.6104540824890137\n",
      "Optimization time for model  314 :  2.6659929752349854\n",
      "Optimization time for model  315 :  0.059484004974365234\n",
      "Optimization time for model  316 :  11.898661851882935\n",
      "Optimization time for model  317 :  1.2402160167694092\n",
      "Optimization time for model  318 :  2.543470859527588\n",
      "Optimization time for model  319 :  0.0023369789123535156\n",
      "Optimization time for model  320 :  1.8094711303710938\n",
      "Optimization time for model  321 :  3.2749369144439697\n",
      "Optimization time for model  322 :  0.009867191314697266\n",
      "Optimization time for model  323 :  1.2895560264587402\n",
      "Optimization time for model  324 :  0.08642005920410156\n",
      "Optimization time for model  325 :  0.5637478828430176\n",
      "Optimization time for model  326 :  0.0015139579772949219\n",
      "Optimization time for model  327 :  1.3399920463562012\n",
      "Optimization time for model  328 :  2.0080411434173584\n",
      "Optimization time for model  329 :  0.07025313377380371\n",
      "Optimization time for model  330 :  2.4647269248962402\n",
      "Optimization time for model  331 :  0.0029799938201904297\n",
      "Optimization time for model  332 :  2.5046019554138184\n",
      "Optimization time for model  333 :  0.014885187149047852\n",
      "Optimization time for model  334 :  0.18424701690673828\n",
      "Optimization time for model  335 :  0.18301796913146973\n",
      "Optimization time for model  336 :  0.0033540725708007812\n",
      "Optimization time for model  337 :  2.0534181594848633\n",
      "Optimization time for model  338 :  0.25240206718444824\n",
      "Optimization time for model  339 :  0.02406001091003418\n",
      "Optimization time for model  340 :  0.0006868839263916016\n",
      "Optimization time for model  341 :  0.8835909366607666\n",
      "Optimization time for model  342 :  1.2955408096313477\n",
      "Optimization time for model  343 :  0.021443843841552734\n",
      "Optimization time for model  344 :  0.006983041763305664\n",
      "Optimization time for model  345 :  0.04597902297973633\n",
      "Optimization time for model  346 :  0.09383606910705566\n",
      "Optimization time for model  347 :  0.036499977111816406\n",
      "Optimization time for model  348 :  2.9787540435791016\n",
      "Optimization time for model  349 :  0.19060301780700684\n",
      "Optimization time for model  350 :  0.9906620979309082\n",
      "Optimization time for model  351 :  3.5740561485290527\n",
      "Optimization time for model  352 :  1.665574073791504\n",
      "Optimization time for model  353 :  0.07669496536254883\n",
      "Optimization time for model  354 :  2.089707851409912\n",
      "Optimization time for model  355 :  14.907954931259155\n",
      "Optimization time for model  356 :  0.13894295692443848\n",
      "Optimization time for model  357 :  3.6624488830566406\n",
      "Optimization time for model  358 :  0.35776710510253906\n",
      "Optimization time for model  359 :  0.024734020233154297\n",
      "Optimization time for model  360 :  2.147062063217163\n",
      "Optimization time for model  361 :  0.00752711296081543\n",
      "Optimization time for model  362 :  1.0388281345367432\n",
      "Optimization time for model  363 :  0.021754026412963867\n",
      "Optimization time for model  364 :  0.6546590328216553\n",
      "Optimization time for model  365 :  0.2900509834289551\n",
      "Optimization time for model  366 :  0.07913923263549805\n",
      "Optimization time for model  367 :  2.0082271099090576\n",
      "Optimization time for model  368 :  0.4866211414337158\n",
      "Optimization time for model  369 :  0.0014500617980957031\n",
      "Optimization time for model  370 :  0.20191192626953125\n",
      "Optimization time for model  371 :  0.0012288093566894531\n",
      "Optimization time for model  372 :  0.014785051345825195\n",
      "Optimization time for model  373 :  2.5489959716796875\n",
      "Optimization time for model  374 :  0.003445863723754883\n",
      "Optimization time for model  375 :  0.008261919021606445\n",
      "Optimization time for model  376 :  0.5892879962921143\n",
      "Optimization time for model  377 :  2.790328025817871\n",
      "Optimization time for model  378 :  0.020353078842163086\n",
      "Optimization time for model  379 :  0.01317596435546875\n",
      "Optimization time for model  380 :  0.21550297737121582\n",
      "Optimization time for model  381 :  0.08370304107666016\n",
      "Optimization time for model  382 :  0.029207944869995117\n",
      "Optimization time for model  383 :  0.003442049026489258\n",
      "Optimization time for model  384 :  0.34018397331237793\n",
      "Optimization time for model  385 :  0.015577077865600586\n",
      "Optimization time for model  386 :  0.00637507438659668\n",
      "Optimization time for model  387 :  1.2029609680175781\n",
      "Optimization time for model  388 :  1.898970127105713\n",
      "Optimization time for model  389 :  0.042572021484375\n",
      "Optimization time for model  390 :  0.005712032318115234\n",
      "Optimization time for model  391 :  2.103055000305176\n",
      "Optimization time for model  392 :  0.018218994140625\n",
      "Optimization time for model  393 :  1.0608887672424316\n",
      "Optimization time for model  394 :  4.052716016769409\n",
      "Optimization time for model  395 :  0.866098165512085\n",
      "Optimization time for model  396 :  1.3820130825042725\n",
      "Optimization time for model  397 :  0.0068891048431396484\n",
      "Optimization time for model  398 :  0.41271209716796875\n",
      "Optimization time for model  399 :  1.2305331230163574\n",
      "Average optimization time:  1.2731879156827928\n"
     ]
    }
   ],
   "source": [
    "test_models = []\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "model_files = os.listdir(\"instances/mip/data/COR-LAT\")\n",
    "for i in range(len(test_indices)):\n",
    "    model = gb.read(\"instances/mip/data/COR-LAT/\" + model_files[test_indices[i]], env=gurobi_env)\n",
    "    test_models.append(model)\n",
    "\n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time = []\n",
    "for i in range(len(test_models)):\n",
    "    model = test_models[i]\n",
    "    model.Params.Threads = 1\n",
    "    model.optimize()\n",
    "    print(\"Optimization time for model \", i, \": \", model.Runtime)\n",
    "    opt_time.append(model.Runtime)\n",
    "\n",
    "print(\"Average optimization time: \", np.mean(opt_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diving_opt_time(models, binary_indices, y_pred):\n",
    "    \n",
    "    opt_time = []\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        \n",
    "        modelVars = model.getVars()\n",
    "        \n",
    "        instanceBinaryIndices = binary_indices\n",
    "        \n",
    "        y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "        \n",
    "        # need to relax the binary variables to continuous variables with bounds of 0 and 1, we can use the setAttr method to change their vtype attribute\n",
    "        for j in range(len(instanceBinaryIndices)):\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"C\")\n",
    "\n",
    "            # for each index in firstInstanceTestBinaryIndices, set the value of the corresponding variable to the value predicted by xgboost\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "        \n",
    "        \n",
    "        # Compute the IIS to find the list of violated constraints and variables\n",
    "        try:\n",
    "            model.computeIIS()\n",
    "            infeasible_flag = True\n",
    "        except gb.GurobiError:\n",
    "            print(\"Model is feasible\")\n",
    "            infeasible_flag = False\n",
    "            continue\n",
    "        \n",
    "        if infeasible_flag:\n",
    "            for j in range(len(instanceBinaryIndices)):\n",
    "                if modelVars[instanceBinaryIndices[j]].IISLB == 0 and modelVars[instanceBinaryIndices[j]].IISUB == 0:\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                    # for each index in binary_indices, set the value of the corresponding variable to the value predicted by model\n",
    "                    # modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "                    # modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])                 \n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", 0)\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", 1)\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"Start\", y_pred_binary[i, j])\n",
    "                    \n",
    "                    # else if the variable is in the IIS, \n",
    "                    # get the relaxed variable and \n",
    "                    # set the bounds to 0 and 1 for the relaxed binary variables\n",
    "                else:\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", 0)\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", 1)\n",
    "        \n",
    "        else:\n",
    "            for j in range(len(instanceBinaryIndices)):\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                # modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "                # modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", 0)\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", 1)\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"Start\", y_pred_binary[i, j])\n",
    "        \n",
    "        model.Params.Threads = 1\n",
    "        model.optimize()\n",
    "        print(\"Optimization time for model \", i, \": \", model.Runtime)\n",
    "        opt_time.append(model.Runtime)\n",
    "        \n",
    "    return opt_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-01\n",
      "Optimization time for model  0 :  0.27060914039611816\n",
      "Optimization time for model  1 :  1.5507690906524658\n",
      "Optimization time for model  2 :  0.0038268566131591797\n",
      "Optimization time for model  3 :  0.0038170814514160156\n",
      "Optimization time for model  4 :  0.43394994735717773\n",
      "Optimization time for model  5 :  0.3295869827270508\n",
      "Optimization time for model  6 :  0.04777884483337402\n",
      "Optimization time for model  7 :  0.0024178028106689453\n",
      "Optimization time for model  8 :  0.2057809829711914\n",
      "Optimization time for model  9 :  1.021353006362915\n",
      "Optimization time for model  10 :  1.4050397872924805\n",
      "Optimization time for model  11 :  0.4867870807647705\n",
      "Optimization time for model  12 :  6.518955945968628\n",
      "Optimization time for model  13 :  0.20032715797424316\n",
      "Optimization time for model  14 :  0.1604478359222412\n",
      "Optimization time for model  15 :  0.374176025390625\n",
      "Optimization time for model  16 :  0.6337559223175049\n",
      "Optimization time for model  17 :  0.49730896949768066\n",
      "Optimization time for model  18 :  0.13209891319274902\n",
      "Optimization time for model  19 :  0.41884684562683105\n",
      "Optimization time for model  20 :  1.2575788497924805\n",
      "Optimization time for model  21 :  0.8140850067138672\n",
      "Optimization time for model  22 :  2.069856882095337\n",
      "Optimization time for model  23 :  0.003751039505004883\n",
      "Optimization time for model  24 :  0.8084371089935303\n",
      "Optimization time for model  25 :  0.7587709426879883\n",
      "Optimization time for model  26 :  0.6742339134216309\n",
      "Optimization time for model  27 :  0.017670869827270508\n",
      "Optimization time for model  28 :  1.4127659797668457\n",
      "Optimization time for model  29 :  0.08348298072814941\n",
      "Optimization time for model  30 :  0.38849496841430664\n",
      "Optimization time for model  31 :  0.04329109191894531\n",
      "Optimization time for model  0 :  0.3265399932861328\n",
      "Optimization time for model  1 :  0.19179010391235352\n",
      "Optimization time for model  2 :  2.5128610134124756\n",
      "Optimization time for model  3 :  6.600299119949341\n",
      "Optimization time for model  4 :  0.7200980186462402\n",
      "Optimization time for model  5 :  0.20075392723083496\n",
      "Optimization time for model  6 :  3.544877052307129\n",
      "Optimization time for model  7 :  1.9188950061798096\n",
      "Optimization time for model  8 :  0.0037488937377929688\n",
      "Optimization time for model  9 :  0.05483889579772949\n",
      "Optimization time for model  10 :  0.5692369937896729\n",
      "Optimization time for model  11 :  0.07680988311767578\n",
      "Optimization time for model  12 :  2.5430779457092285\n",
      "Optimization time for model  13 :  1.1919379234313965\n",
      "Optimization time for model  14 :  0.12494397163391113\n",
      "Optimization time for model  15 :  0.0009729862213134766\n",
      "Optimization time for model  16 :  0.025185108184814453\n",
      "Optimization time for model  17 :  0.3429379463195801\n",
      "Optimization time for model  18 :  0.0030820369720458984\n",
      "Optimization time for model  19 :  0.13411712646484375\n",
      "Optimization time for model  20 :  0.0075190067291259766\n",
      "Optimization time for model  21 :  0.10141110420227051\n",
      "Optimization time for model  22 :  0.6888020038604736\n",
      "Optimization time for model  23 :  0.007498025894165039\n",
      "Optimization time for model  24 :  1.382328987121582\n",
      "Optimization time for model  25 :  1.91365385055542\n",
      "Optimization time for model  26 :  0.19460487365722656\n",
      "Optimization time for model  27 :  3.5075907707214355\n",
      "Optimization time for model  28 :  0.48108506202697754\n",
      "Optimization time for model  29 :  1.351370096206665\n",
      "Optimization time for model  30 :  6.0551629066467285\n",
      "Optimization time for model  31 :  0.15077686309814453\n",
      "Optimization time for model  0 :  2.730289936065674\n",
      "Optimization time for model  1 :  0.005105018615722656\n",
      "Optimization time for model  2 :  0.37400102615356445\n",
      "Optimization time for model  3 :  4.727313041687012\n",
      "Optimization time for model  4 :  1.329892873764038\n",
      "Optimization time for model  5 :  0.48059678077697754\n",
      "Optimization time for model  6 :  0.007565975189208984\n",
      "Optimization time for model  7 :  0.0016090869903564453\n",
      "Optimization time for model  8 :  0.8374271392822266\n",
      "Optimization time for model  9 :  0.7336978912353516\n",
      "Optimization time for model  10 :  0.8976550102233887\n",
      "Optimization time for model  11 :  1.0226030349731445\n",
      "Optimization time for model  12 :  1.3899831771850586\n",
      "Model is feasible\n",
      "Optimization time for model  14 :  0.0068759918212890625\n",
      "Optimization time for model  15 :  0.09679102897644043\n",
      "Optimization time for model  16 :  1.1367199420928955\n",
      "Optimization time for model  17 :  0.0016679763793945312\n",
      "Optimization time for model  18 :  0.5035948753356934\n",
      "Optimization time for model  19 :  0.04800295829772949\n",
      "Optimization time for model  20 :  0.705502986907959\n",
      "Optimization time for model  21 :  0.4227018356323242\n",
      "Optimization time for model  22 :  0.4115259647369385\n",
      "Optimization time for model  23 :  2.417638063430786\n",
      "Optimization time for model  24 :  0.34520411491394043\n",
      "Optimization time for model  25 :  1.1654129028320312\n",
      "Optimization time for model  26 :  2.2123119831085205\n",
      "Optimization time for model  27 :  0.0650629997253418\n",
      "Optimization time for model  28 :  0.04837989807128906\n",
      "Optimization time for model  29 :  0.35164308547973633\n",
      "Optimization time for model  30 :  1.0584909915924072\n",
      "Optimization time for model  31 :  2.4848058223724365\n",
      "Optimization time for model  0 :  0.0012030601501464844\n",
      "Optimization time for model  1 :  4.6971399784088135\n",
      "Optimization time for model  2 :  0.011279106140136719\n",
      "Optimization time for model  3 :  5.056175947189331\n",
      "Optimization time for model  4 :  4.303739070892334\n",
      "Optimization time for model  5 :  0.7620849609375\n",
      "Optimization time for model  6 :  0.3143038749694824\n",
      "Optimization time for model  7 :  0.7500739097595215\n",
      "Optimization time for model  8 :  0.021486997604370117\n",
      "Optimization time for model  9 :  3.8195619583129883\n",
      "Optimization time for model  10 :  2.0502500534057617\n",
      "Optimization time for model  11 :  0.0009090900421142578\n",
      "Optimization time for model  12 :  0.25473999977111816\n",
      "Optimization time for model  13 :  0.766855001449585\n",
      "Optimization time for model  14 :  3.905349016189575\n",
      "Optimization time for model  15 :  0.0009200572967529297\n",
      "Optimization time for model  16 :  0.5106649398803711\n",
      "Optimization time for model  17 :  0.7685699462890625\n",
      "Optimization time for model  18 :  1.422957181930542\n",
      "Optimization time for model  19 :  0.11380600929260254\n",
      "Optimization time for model  20 :  2.7391700744628906\n",
      "Optimization time for model  21 :  1.240358829498291\n",
      "Optimization time for model  22 :  0.6598269939422607\n",
      "Optimization time for model  23 :  0.12747812271118164\n",
      "Optimization time for model  24 :  0.00308990478515625\n",
      "Optimization time for model  25 :  0.18524599075317383\n",
      "Optimization time for model  26 :  0.04121685028076172\n",
      "Optimization time for model  27 :  0.8347818851470947\n",
      "Optimization time for model  28 :  1.1433110237121582\n",
      "Optimization time for model  29 :  0.05486607551574707\n",
      "Optimization time for model  30 :  7.558767080307007\n",
      "Optimization time for model  31 :  1.1196649074554443\n",
      "Optimization time for model  0 :  0.19020795822143555\n",
      "Optimization time for model  1 :  0.0016298294067382812\n",
      "Optimization time for model  2 :  5.33688497543335\n",
      "Optimization time for model  3 :  0.04048800468444824\n",
      "Optimization time for model  4 :  0.6512200832366943\n",
      "Optimization time for model  5 :  0.0010159015655517578\n",
      "Optimization time for model  6 :  0.23782682418823242\n",
      "Optimization time for model  7 :  0.30364298820495605\n",
      "Optimization time for model  8 :  2.841416835784912\n",
      "Optimization time for model  9 :  3.528174877166748\n",
      "Optimization time for model  10 :  12.213195085525513\n",
      "Optimization time for model  11 :  0.016728878021240234\n",
      "Optimization time for model  12 :  0.0019080638885498047\n",
      "Optimization time for model  13 :  1.4381599426269531\n",
      "Optimization time for model  14 :  0.9111130237579346\n",
      "Optimization time for model  15 :  6.567224025726318\n",
      "Optimization time for model  16 :  0.013484954833984375\n",
      "Optimization time for model  17 :  0.0012390613555908203\n",
      "Optimization time for model  18 :  1.5043089389801025\n",
      "Optimization time for model  19 :  5.625364065170288\n",
      "Optimization time for model  20 :  0.5387639999389648\n",
      "Optimization time for model  21 :  0.004979133605957031\n",
      "Model is feasible\n",
      "Optimization time for model  23 :  0.1857929229736328\n",
      "Optimization time for model  24 :  0.7963790893554688\n",
      "Model is feasible\n",
      "Optimization time for model  26 :  0.11403608322143555\n",
      "Optimization time for model  27 :  0.0028040409088134766\n",
      "Optimization time for model  28 :  0.00385284423828125\n",
      "Optimization time for model  29 :  0.46405506134033203\n",
      "Optimization time for model  30 :  0.9290449619293213\n",
      "Optimization time for model  31 :  0.25475287437438965\n",
      "Optimization time for model  0 :  0.8839349746704102\n",
      "Optimization time for model  1 :  0.7513298988342285\n",
      "Optimization time for model  2 :  1.4057538509368896\n",
      "Optimization time for model  3 :  0.01666092872619629\n",
      "Optimization time for model  4 :  0.9952778816223145\n",
      "Optimization time for model  5 :  5.445195913314819\n",
      "Optimization time for model  6 :  3.653625011444092\n",
      "Optimization time for model  7 :  0.0038537979125976562\n",
      "Optimization time for model  8 :  5.6177709102630615\n",
      "Optimization time for model  9 :  1.8911631107330322\n",
      "Optimization time for model  10 :  0.42275404930114746\n",
      "Optimization time for model  11 :  0.5406451225280762\n",
      "Optimization time for model  12 :  1.483469009399414\n",
      "Optimization time for model  13 :  3.151691198348999\n",
      "Optimization time for model  14 :  0.12367701530456543\n",
      "Optimization time for model  15 :  0.007161140441894531\n",
      "Optimization time for model  16 :  0.477827787399292\n",
      "Optimization time for model  17 :  0.9665110111236572\n",
      "Optimization time for model  18 :  0.009702920913696289\n",
      "Optimization time for model  19 :  2.1858971118927\n",
      "Optimization time for model  20 :  2.1574039459228516\n",
      "Optimization time for model  21 :  0.3682210445404053\n",
      "Optimization time for model  22 :  2.5640838146209717\n",
      "Optimization time for model  23 :  1.7693870067596436\n",
      "Model is feasible\n",
      "Optimization time for model  25 :  0.006721973419189453\n",
      "Optimization time for model  26 :  0.004046916961669922\n",
      "Optimization time for model  27 :  1.332326889038086\n",
      "Optimization time for model  28 :  1.1551752090454102\n",
      "Optimization time for model  29 :  2.653735876083374\n",
      "Optimization time for model  30 :  0.7704179286956787\n",
      "Optimization time for model  31 :  1.0152299404144287\n",
      "Optimization time for model  0 :  0.00976109504699707\n",
      "Optimization time for model  1 :  2.5526328086853027\n",
      "Optimization time for model  2 :  0.046427011489868164\n",
      "Optimization time for model  3 :  0.9417860507965088\n",
      "Optimization time for model  4 :  0.21854400634765625\n",
      "Optimization time for model  5 :  0.8022840023040771\n",
      "Optimization time for model  6 :  0.2841460704803467\n",
      "Optimization time for model  7 :  0.10672903060913086\n",
      "Optimization time for model  8 :  0.1750948429107666\n",
      "Optimization time for model  9 :  0.36531496047973633\n",
      "Optimization time for model  10 :  0.06859207153320312\n",
      "Optimization time for model  11 :  2.4589998722076416\n",
      "Optimization time for model  12 :  1.2202210426330566\n",
      "Optimization time for model  13 :  0.061064958572387695\n",
      "Optimization time for model  14 :  0.41177821159362793\n",
      "Optimization time for model  15 :  2.252392053604126\n",
      "Optimization time for model  16 :  0.546191930770874\n",
      "Optimization time for model  17 :  0.017889022827148438\n",
      "Optimization time for model  18 :  0.0035181045532226562\n",
      "Optimization time for model  19 :  0.19096088409423828\n",
      "Optimization time for model  20 :  0.12191295623779297\n",
      "Optimization time for model  21 :  6.75108790397644\n",
      "Optimization time for model  22 :  0.04429793357849121\n",
      "Optimization time for model  23 :  0.012885093688964844\n",
      "Optimization time for model  24 :  0.02025604248046875\n",
      "Optimization time for model  25 :  9.142035007476807\n",
      "Optimization time for model  26 :  1.3563652038574219\n",
      "Optimization time for model  27 :  0.34228086471557617\n",
      "Optimization time for model  28 :  0.30878496170043945\n",
      "Optimization time for model  29 :  0.08253216743469238\n",
      "Optimization time for model  30 :  0.2818629741668701\n",
      "Optimization time for model  31 :  0.3707740306854248\n",
      "Optimization time for model  0 :  1.2468438148498535\n",
      "Optimization time for model  1 :  1.1949200630187988\n",
      "Optimization time for model  2 :  1.5245959758758545\n",
      "Optimization time for model  3 :  0.054299116134643555\n",
      "Optimization time for model  4 :  1.625885009765625\n",
      "Optimization time for model  5 :  0.9811849594116211\n",
      "Optimization time for model  6 :  0.1700420379638672\n",
      "Optimization time for model  7 :  0.345548152923584\n",
      "Optimization time for model  8 :  0.003704071044921875\n",
      "Optimization time for model  9 :  2.524796962738037\n",
      "Optimization time for model  10 :  0.6690499782562256\n",
      "Optimization time for model  11 :  10.899277925491333\n",
      "Optimization time for model  12 :  1.812899112701416\n",
      "Optimization time for model  13 :  6.200340032577515\n",
      "Optimization time for model  14 :  0.320084810256958\n",
      "Optimization time for model  15 :  2.3499691486358643\n",
      "Optimization time for model  16 :  1.654283046722412\n",
      "Optimization time for model  17 :  1.5374369621276855\n",
      "Optimization time for model  18 :  0.300537109375\n",
      "Optimization time for model  19 :  1.0326731204986572\n",
      "Optimization time for model  20 :  0.1376330852508545\n",
      "Optimization time for model  21 :  0.003674030303955078\n",
      "Optimization time for model  22 :  3.9651529788970947\n",
      "Optimization time for model  23 :  10.746899843215942\n",
      "Optimization time for model  24 :  0.6991980075836182\n",
      "Optimization time for model  25 :  0.1156930923461914\n",
      "Optimization time for model  26 :  0.14091110229492188\n",
      "Optimization time for model  27 :  0.0992588996887207\n",
      "Optimization time for model  28 :  0.6300289630889893\n",
      "Optimization time for model  29 :  0.023150920867919922\n",
      "Optimization time for model  30 :  0.0010528564453125\n",
      "Optimization time for model  31 :  0.42656588554382324\n",
      "Optimization time for model  0 :  0.14824891090393066\n",
      "Optimization time for model  1 :  2.838834047317505\n",
      "Optimization time for model  2 :  0.40756893157958984\n",
      "Optimization time for model  3 :  2.296593189239502\n",
      "Optimization time for model  4 :  0.008805990219116211\n",
      "Optimization time for model  5 :  0.003854990005493164\n",
      "Optimization time for model  6 :  1.8563930988311768\n",
      "Optimization time for model  7 :  6.1785969734191895\n",
      "Optimization time for model  8 :  0.6617071628570557\n",
      "Optimization time for model  9 :  1.5924201011657715\n",
      "Optimization time for model  10 :  0.006514072418212891\n",
      "Optimization time for model  11 :  0.0013990402221679688\n",
      "Optimization time for model  12 :  1.368696928024292\n",
      "Optimization time for model  13 :  0.007411003112792969\n",
      "Optimization time for model  14 :  0.7435259819030762\n",
      "Optimization time for model  15 :  0.011049985885620117\n",
      "Optimization time for model  16 :  0.08752012252807617\n",
      "Optimization time for model  17 :  5.60836386680603\n",
      "Optimization time for model  18 :  0.21146798133850098\n",
      "Optimization time for model  19 :  1.6982707977294922\n",
      "Optimization time for model  20 :  0.01277303695678711\n",
      "Optimization time for model  21 :  2.840989112854004\n",
      "Optimization time for model  22 :  0.07940411567687988\n",
      "Optimization time for model  23 :  0.14408588409423828\n",
      "Optimization time for model  24 :  0.30622005462646484\n",
      "Optimization time for model  25 :  0.38973188400268555\n",
      "Optimization time for model  26 :  0.6629409790039062\n",
      "Optimization time for model  27 :  0.2963249683380127\n",
      "Optimization time for model  28 :  0.005012035369873047\n",
      "Optimization time for model  29 :  4.549345016479492\n",
      "Optimization time for model  30 :  1.3214879035949707\n",
      "Optimization time for model  31 :  0.7494480609893799\n",
      "Optimization time for model  0 :  0.08444714546203613\n",
      "Optimization time for model  1 :  4.254105091094971\n",
      "Optimization time for model  2 :  0.3389761447906494\n",
      "Optimization time for model  3 :  0.011250019073486328\n",
      "Model is feasible\n",
      "Optimization time for model  5 :  1.3993618488311768\n",
      "Optimization time for model  6 :  0.003587961196899414\n",
      "Model is feasible\n",
      "Optimization time for model  8 :  1.4585192203521729\n",
      "Optimization time for model  9 :  1.8083350658416748\n",
      "Optimization time for model  10 :  0.21736788749694824\n",
      "Model is feasible\n",
      "Optimization time for model  12 :  1.0544040203094482\n",
      "Optimization time for model  13 :  0.013957977294921875\n",
      "Optimization time for model  14 :  1.9399051666259766\n",
      "Optimization time for model  15 :  0.9373738765716553\n",
      "Optimization time for model  16 :  0.7938461303710938\n",
      "Optimization time for model  17 :  0.0037899017333984375\n",
      "Optimization time for model  18 :  0.041468143463134766\n",
      "Optimization time for model  19 :  0.06586503982543945\n",
      "Optimization time for model  20 :  1.2878239154815674\n",
      "Optimization time for model  21 :  0.003651142120361328\n",
      "Optimization time for model  22 :  0.13579082489013672\n",
      "Optimization time for model  23 :  0.08354592323303223\n",
      "Optimization time for model  24 :  0.2094271183013916\n",
      "Optimization time for model  25 :  0.6233389377593994\n",
      "Optimization time for model  26 :  1.7708380222320557\n",
      "Optimization time for model  27 :  0.059886932373046875\n",
      "Optimization time for model  28 :  9.662986993789673\n",
      "Optimization time for model  29 :  1.224200963973999\n",
      "Optimization time for model  30 :  1.8008410930633545\n",
      "Optimization time for model  31 :  0.0024580955505371094\n",
      "Optimization time for model  0 :  1.8097550868988037\n",
      "Optimization time for model  1 :  2.9432108402252197\n",
      "Optimization time for model  2 :  0.008857011795043945\n",
      "Optimization time for model  3 :  0.4874379634857178\n",
      "Optimization time for model  4 :  0.08769106864929199\n",
      "Optimization time for model  5 :  0.6683769226074219\n",
      "Optimization time for model  6 :  0.0016629695892333984\n",
      "Optimization time for model  7 :  1.1218500137329102\n",
      "Optimization time for model  8 :  2.0080478191375732\n",
      "Optimization time for model  9 :  0.09365606307983398\n",
      "Optimization time for model  10 :  2.4835009574890137\n",
      "Optimization time for model  11 :  0.003239154815673828\n",
      "Optimization time for model  12 :  2.501300096511841\n",
      "Optimization time for model  13 :  0.013373136520385742\n",
      "Optimization time for model  14 :  0.3696269989013672\n",
      "Optimization time for model  15 :  0.18321704864501953\n",
      "Optimization time for model  16 :  0.0035381317138671875\n",
      "Optimization time for model  17 :  1.169403076171875\n",
      "Optimization time for model  18 :  0.2524380683898926\n",
      "Optimization time for model  19 :  0.0242462158203125\n",
      "Optimization time for model  20 :  0.0008649826049804688\n",
      "Optimization time for model  21 :  0.6920928955078125\n",
      "Optimization time for model  22 :  1.579313039779663\n",
      "Optimization time for model  23 :  0.021833181381225586\n",
      "Optimization time for model  24 :  0.007234096527099609\n",
      "Optimization time for model  25 :  0.046137094497680664\n",
      "Optimization time for model  26 :  0.09465503692626953\n",
      "Optimization time for model  27 :  0.03622007369995117\n",
      "Optimization time for model  28 :  0.4931468963623047\n",
      "Optimization time for model  29 :  0.4474151134490967\n",
      "Optimization time for model  30 :  0.444486141204834\n",
      "Optimization time for model  31 :  3.5756068229675293\n",
      "Optimization time for model  0 :  0.9237439632415771\n",
      "Optimization time for model  1 :  0.07749104499816895\n",
      "Optimization time for model  2 :  2.091150999069214\n",
      "Optimization time for model  3 :  14.940445899963379\n",
      "Optimization time for model  4 :  0.15468811988830566\n",
      "Optimization time for model  5 :  3.681741952896118\n",
      "Optimization time for model  6 :  0.3964688777923584\n",
      "Optimization time for model  7 :  0.02593207359313965\n",
      "Optimization time for model  8 :  2.2434639930725098\n",
      "Optimization time for model  9 :  0.009719133377075195\n",
      "Optimization time for model  10 :  0.5335960388183594\n",
      "Optimization time for model  11 :  0.02684497833251953\n",
      "Optimization time for model  12 :  0.6551220417022705\n",
      "Optimization time for model  13 :  0.3863201141357422\n",
      "Optimization time for model  14 :  0.10636687278747559\n",
      "Optimization time for model  15 :  1.7245409488677979\n",
      "Optimization time for model  16 :  1.4309170246124268\n",
      "Optimization time for model  17 :  0.001631021499633789\n",
      "Optimization time for model  18 :  0.23813199996948242\n",
      "Optimization time for model  19 :  0.00140380859375\n",
      "Optimization time for model  20 :  0.014264106750488281\n",
      "Optimization time for model  21 :  2.7217299938201904\n",
      "Model is feasible\n",
      "Optimization time for model  23 :  0.009264945983886719\n",
      "Optimization time for model  24 :  0.8889269828796387\n",
      "Optimization time for model  25 :  2.6776750087738037\n",
      "Model is feasible\n",
      "Optimization time for model  27 :  0.012447118759155273\n",
      "Model is feasible\n",
      "Optimization time for model  29 :  0.08523988723754883\n",
      "Optimization time for model  30 :  0.031852006912231445\n",
      "Optimization time for model  31 :  0.0036058425903320312\n",
      "Optimization time for model  0 :  0.37786412239074707\n",
      "Optimization time for model  1 :  0.010584115982055664\n",
      "Optimization time for model  2 :  0.006693124771118164\n",
      "Optimization time for model  3 :  0.40039587020874023\n",
      "Optimization time for model  4 :  0.62888503074646\n",
      "Optimization time for model  5 :  0.04282808303833008\n",
      "Optimization time for model  6 :  0.006119966506958008\n",
      "Optimization time for model  7 :  0.8820199966430664\n",
      "Optimization time for model  8 :  0.021162033081054688\n",
      "Optimization time for model  9 :  1.1255979537963867\n",
      "Optimization time for model  10 :  2.3433849811553955\n",
      "Optimization time for model  11 :  0.9708271026611328\n",
      "Optimization time for model  12 :  1.3952720165252686\n",
      "Optimization time for model  13 :  0.010543107986450195\n",
      "Optimization time for model  14 :  1.0471258163452148\n",
      "Optimization time for model  15 :  0.9078030586242676\n"
     ]
    }
   ],
   "source": [
    "test_models = []\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "model_files = os.listdir(\"instances/mip/data/COR-LAT\")\n",
    "for i in range(len(test_indices)):\n",
    "    model = gb.read(\"instances/mip/data/COR-LAT/\" + model_files[test_indices[i]], env=gurobi_env)\n",
    "    test_models.append(model)\n",
    "    \n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time = []\n",
    "for i, data in enumerate(valid_loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # get slices of test_models according to batch size\n",
    "    len_test_models = len(test_models)\n",
    "\n",
    "    test_models_batch = test_models[i*batch_size: min((i+1)*batch_size, len_test_models)]\n",
    "    \n",
    "    opt_time_batch = calculate_diving_opt_time(test_models_batch, binary_indices, outputs.detach().cpu().numpy())\n",
    "    \n",
    "    opt_time.append(opt_time_batch)\n",
    "    \n",
    "# save opt_time\n",
    "with open(\"Data/corlat/opt_time.pickle\", \"wb\") as f:\n",
    "    pkl.dump(opt_time, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average optimization time:  1.1413019216977633\n"
     ]
    }
   ],
   "source": [
    "# flatten opt_time\n",
    "opt_time_flat = [item for sublist in opt_time for item in sublist]\n",
    "print(\"Average optimization time: \", np.mean(opt_time_flat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (optimization)",
   "language": "python",
   "name": "optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
