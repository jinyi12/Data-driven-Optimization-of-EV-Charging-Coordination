{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    corlat_dataset = pkl.load(open(\"Data/corlat/corlat_preprocessed.pickle\", \"rb\"))\n",
    "except:\n",
    "    # move dir to /ibm/gpfs/home/yjin0055/Project/DayAheadForecast\n",
    "    os.chdir(\"/ibm/gpfs/home/yjin0055/Project/DayAheadForecast\")\n",
    "    corlat_dataset = pkl.load(open(\"Data/corlat/corlat_preprocessed.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_obj_coef</th>\n",
       "      <th>num_nonzero_coef</th>\n",
       "      <th>lp_relax_val</th>\n",
       "      <th>is_lp_relax_val_frac</th>\n",
       "      <th>lp_sol_val_eq_lb</th>\n",
       "      <th>lp_sol_val_eq_ub</th>\n",
       "      <th>has_lb</th>\n",
       "      <th>has_ub</th>\n",
       "      <th>mean_degree</th>\n",
       "      <th>std_degree</th>\n",
       "      <th>min_degree</th>\n",
       "      <th>max_degree</th>\n",
       "      <th>mean_coef</th>\n",
       "      <th>std_coef</th>\n",
       "      <th>min_coef</th>\n",
       "      <th>max_coef</th>\n",
       "      <th>var_type_B</th>\n",
       "      <th>var_type_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>36.706039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-50.166667</td>\n",
       "      <td>49.837792</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>45.415367</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-48.833333</td>\n",
       "      <td>51.275129</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.442327</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>45.415367</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-50.166667</td>\n",
       "      <td>49.837792</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>45.415367</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-48.833333</td>\n",
       "      <td>51.275129</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>45.415367</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-48.833333</td>\n",
       "      <td>51.275129</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_obj_coef  num_nonzero_coef  lp_relax_val  is_lp_relax_val_frac  \\\n",
       "0           5.0               6.0      1.000000                  True   \n",
       "1           4.0               6.0      0.000000                  True   \n",
       "2           6.0               6.0      0.442327                  True   \n",
       "3           5.0               6.0     -0.000000                  True   \n",
       "4           3.0               6.0     -0.000000                  True   \n",
       "\n",
       "   lp_sol_val_eq_lb  lp_sol_val_eq_ub  has_lb  has_ub  mean_degree  \\\n",
       "0              True              True    True    True    19.000000   \n",
       "1              True              True    True    True    35.333333   \n",
       "2              True              True    True    True    35.333333   \n",
       "3              True              True    True    True    35.333333   \n",
       "4              True              True    True    True    35.333333   \n",
       "\n",
       "   std_degree  min_degree  max_degree  mean_coef   std_coef  min_coef  \\\n",
       "0   36.706039         1.0       101.0 -50.166667  49.837792    -100.0   \n",
       "1   45.415367         2.0       101.0 -48.833333  51.275129    -100.0   \n",
       "2   45.415367         2.0       101.0 -50.166667  49.837792    -100.0   \n",
       "3   45.415367         2.0       101.0 -48.833333  51.275129    -100.0   \n",
       "4   45.415367         2.0       101.0 -48.833333  51.275129    -100.0   \n",
       "\n",
       "   max_coef  var_type_B  var_type_C  \n",
       "0       1.0           1           0  \n",
       "1       9.0           1           0  \n",
       "2       1.0           1           0  \n",
       "3       9.0           1           0  \n",
       "4       9.0           1           0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corlat_dataset[0][\"input\"][\"var_node_features\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the maximum size of N_constraints and N_variables across the dataset.\n",
    "\n",
    "max_N_constraints = max(\n",
    "    len(x[\"input\"][\"constraint_node_features\"]) for x in corlat_dataset\n",
    ")\n",
    "\n",
    "max_N_variables = max(\n",
    "    len(x[\"input\"][\"var_node_features\"]) for x in corlat_dataset\n",
    ")\n",
    "\n",
    "min_N_constraints = min(\n",
    "    len(x[\"input\"][\"constraint_node_features\"]) for x in corlat_dataset\n",
    ")\n",
    "\n",
    "min_N_variables = min(\n",
    "    len(x[\"input\"][\"var_node_features\"]) for x in corlat_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of variables:  466\n",
      "Maximum number of constraints:  551\n",
      "Minimum number of variables:  466\n",
      "Minimum number of constraints:  470\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum number of variables: \", max_N_variables)\n",
    "print(\"Maximum number of constraints: \", max_N_constraints)\n",
    "print(\"Minimum number of variables: \", min_N_variables)\n",
    "print(\"Minimum number of constraints: \", min_N_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variable node features:  18\n",
      "Number of constraint node features:  10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of variable node features: \", len(corlat_dataset[0][\"input\"][\"var_node_features\"].columns))\n",
    "print(\"Number of constraint node features: \", len(corlat_dataset[0][\"input\"][\"constraint_node_features\"].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each variable node features, pad with 0s to make it the same length as the maximum number of variables\n",
    "\n",
    "var_node_features = np.stack(\n",
    "    [\n",
    "        np.pad(\n",
    "            x[\"input\"][\"var_node_features\"].values,\n",
    "            ((0, max_N_variables - len(x[\"input\"][\"var_node_features\"])), (0, 0)),\n",
    "            \"constant\",\n",
    "        )\n",
    "        for x in corlat_dataset\n",
    "    ]\n",
    ")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 466, 18)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_node_features = np.stack(\n",
    "    [\n",
    "        np.pad(\n",
    "            x[\"input\"][\"constraint_node_features\"].values,\n",
    "            ((0, max_N_constraints - len(x[\"input\"][\"constraint_node_features\"])), (0, 0)),\n",
    "            \"constant\",\n",
    "        )\n",
    "        for x in corlat_dataset\n",
    "    ]   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 551, 10)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint_node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for var_node_features and constraint_node_features, reshape to (N_samples, -1) to feed into the neural network\n",
    "var_input = var_node_features.reshape(var_node_features.shape[0], -1)\n",
    "constraint_input = constraint_node_features.reshape(constraint_node_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of variable features input:  (2000, 8388)\n",
      "Shape of constraint features input:  (2000, 5510)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of variable features input: \", var_input.shape)\n",
    "print(\"Shape of constraint features input: \", constraint_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get A matrix input by stacking the csr_matrix of each sample getting shape of N_samples x (A.shape[0] x A.shape[1])\n",
    "A_input = np.vstack([x[\"input\"][\"A\"] for x in corlat_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_feature_list = []\n",
    "for i in range(len(corlat_dataset)):\n",
    "    n_cons = corlat_dataset[i][\"input\"][\"A\"].shape[0]\n",
    "\n",
    "    # for row in range(n_vars):\n",
    "    #     for col in range(n_cons):\n",
    "    #         if input_dict_list[i][\"A\"][row, col] != 0:\n",
    "    #             adj_matrix[row, n_vars + col] = input_dict_list[i][\"A\"][row, col]\n",
    "    #             adj_matrix[n_vars + col, row] = input_dict_list[i][\"A\"][row, col]\n",
    "\n",
    "    I, J, V = scipy.sparse.find(corlat_dataset[i][\"input\"][\"A\"])\n",
    "    # adj_matrix[I, n_vars + J] = V\n",
    "    # adj_matrix[n_vars + J, I] = V\n",
    "\n",
    "    # # convert to COO format\n",
    "    edge_index = torch.stack([torch.tensor(I), torch.tensor(n_cons + J)], dim=0)\n",
    "\n",
    "    # expand V to 2D\n",
    "    edge_attr = torch.tensor(V).unsqueeze(1)\n",
    "\n",
    "    tmp_dict = {\"edge_index\": edge_index, \"edge_attr\": edge_attr}\n",
    "    A_feature_list.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sample, pad the edge_index and edge_attr to make it the same length as the maximum length of edge_index and edge_attr\n",
    "max_edge_index_len = max([len(x[\"edge_index\"][0]) for x in A_feature_list])\n",
    "max_edge_attr_len = max([len(x[\"edge_attr\"]) for x in A_feature_list])\n",
    "\n",
    "for i in range(len(A_feature_list)):\n",
    "    edge_index = A_feature_list[i][\"edge_index\"]\n",
    "    edge_attr = A_feature_list[i][\"edge_attr\"]\n",
    "\n",
    "    # pad edge_index\n",
    "    edge_index = torch.cat(\n",
    "        [\n",
    "            edge_index,\n",
    "            torch.zeros(\n",
    "                2, max_edge_index_len - len(edge_index[0]), dtype=torch.long\n",
    "            ),\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "    # pad edge_attr\n",
    "    edge_attr = torch.cat(\n",
    "        [\n",
    "            edge_attr,\n",
    "            torch.zeros(\n",
    "                max_edge_attr_len - len(edge_attr), 1, dtype=torch.float32\n",
    "            ),\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "\n",
    "    A_feature_list[i][\"edge_index\"] = edge_index\n",
    "    A_feature_list[i][\"edge_attr\"] = edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the padding is correct by checking the shape of edge_index and edge_attr\n",
    "for i in range(len(A_feature_list)):\n",
    "    assert A_feature_list[i][\"edge_index\"].shape == (2, max_edge_index_len)\n",
    "    assert A_feature_list[i][\"edge_attr\"].shape == (max_edge_attr_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of A matrix input:  (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of A matrix input: \", A_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['solution', 'indices', 'input'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corlat_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each solution convert the dictionary to a list of values\n",
    "solutions = [\n",
    "    list(corlat_dataset[i][\"solution\"].values())\n",
    "    for i in range(len(corlat_dataset[0][\"solution\"]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert solutions_list to numpy array\n",
    "solutions = np.array(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<470x466 sparse matrix of type '<class 'numpy.float64'>'\n",
       "       \twith 1751 stored elements in Compressed Sparse Row format>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_input[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (optimization)",
   "language": "python",
   "name": "optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
