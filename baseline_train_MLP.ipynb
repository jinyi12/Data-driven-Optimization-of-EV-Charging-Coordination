{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timeit import default_timer\n",
    "from collections import OrderedDict\n",
    "import dadaptation\n",
    "\n",
    "import wandb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "PROJECT_NAME = 'EVCharging'\n",
    "\n",
    "# Set the random seeds to improve reproducibility by removing stochasticity\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False # Force cuDNN to use a consistent convolution algorithm\n",
    "    torch.backends.cudnn.deterministic = True # Force cuDNN to use deterministic algorithms if available\n",
    "    torch.use_deterministic_algorithms(True) # Force torch to use deterministic algorithms if available\n",
    "\n",
    "set_seeds(0)\n",
    "\n",
    "# for deterministic pytorch algorithms, enable reproducibility.\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG']= \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train_val_split': [0.80, 0.20], # These must sum to 1.0\n",
    "    'batch_size' : 32, # Num samples to average over for gradient updates\n",
    "    'EPOCHS' : 200, # Num times to iterate over the entire dataset\n",
    "    'LEARNING_RATE' : 1e-3, # Learning rate for the optimizer\n",
    "    'BETA1' : 0.9, # Beta1 parameter for the Adam optimizer\n",
    "    'BETA2' : 0.999, # Beta2 parameter for the Adam optimizer\n",
    "    'WEIGHT_DECAY' : 1e-4, # Weight decay parameter for the Adam optimizer\n",
    "    'accum_iter': 5, # iterations to accumulate gradients\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert numpy arrays to tensor arrays\n",
    "    \"\"\"\n",
    "    def __init__(self, device=None):\n",
    "        if device is None:\n",
    "            device = \"cpu\"\n",
    "        self.device = device\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        if self.device == \"cpu\":\n",
    "            return torch.from_numpy(data)\n",
    "        else:\n",
    "            # to overlap data transfers with computation, use non_blocking=True\n",
    "            return torch.from_numpy(data).to(self.device, non_blocking=True, dtype=torch.float32)\n",
    "\n",
    "# %%\n",
    "def get_transforms(transform_dict):\n",
    "    \"\"\"\n",
    "    Given a dictionary of transform parameters, return a list of class instances for each transform\n",
    "    Arguments:\n",
    "        transform_dict (OrderedDict) with optional keys:\n",
    "            ToTensor (dict) if present, requires the 'device' key that indicates the PyTorch device\n",
    "    Returns:\n",
    "        composed_transforms (PyTorch composed transform class) containing the requested transform steps in order\n",
    "    \"\"\"\n",
    "    transform_functions = []\n",
    "    for key in transform_dict.keys():\n",
    "        if key=='ToTensor': # Convert array to a PyTorch Tensor\n",
    "            transform_functions.append(ToTensor(\n",
    "                transform_dict[key]['device']\n",
    "            ))\n",
    "        \n",
    "    composed_transforms = transforms.Compose(transform_functions)\n",
    "    return composed_transforms\n",
    "\n",
    "# %%\n",
    "# create a torch dataset\n",
    "class EVCoordDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_data, output_data, transform=None):\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        input_data = self.input_data[idx]\n",
    "        output_data = self.output_data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            input_data = self.transform(input_data)\n",
    "            output_data = self.transform(output_data)\n",
    "            \n",
    "\n",
    "        return input_data, output_data\n",
    "\n",
    "# %%\n",
    "def make_split_artifact(run, train_rows, val_rows):\n",
    "    \"\"\"\n",
    "    Creates a w&b artifact that contains the train and validation rows of the raw data\n",
    "        run (wandb run) returned from wandb.init()\n",
    "        train_rows (list of ints) indices that reference the training rows in the raw_data\n",
    "        val_rows (list of ints) indices that reference the validation rows in the raw_data\n",
    "    \"\"\"\n",
    "    split_artifact = wandb.Artifact(\n",
    "        'data-splits', type='dataset',\n",
    "        description='Train, validation, test dataset splits')\n",
    "\n",
    "    # Our data split artifact will only store index references to the original dataset to save space\n",
    "    split_artifact.add(wandb.Table(\n",
    "        data=pd.DataFrame(train_rows, columns=['indices'])), 'train-data')\n",
    "\n",
    "    split_artifact.add(wandb.Table(\n",
    "        columns=['source'],\n",
    "        data=pd.DataFrame(val_rows, columns=['indices'])), 'val-data')\n",
    "\n",
    "    run.log_artifact(split_artifact)\n",
    "\n",
    "\n",
    "def make_loaders(config, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Makes data loaders using a artifact containing the dataset splits (created using the make_split_artifact() function)\n",
    "    The function assumes that you have created a data-splits artifact and a data-transforms artifact\n",
    "    Arguments:\n",
    "        config [dict] containing keys:\n",
    "            batch_size (int) amount of rows (i.e. data instances) to be delivered in a single batch\n",
    "    Returns:\n",
    "        train_loader (PyTorch DataLoader) containing the training data\n",
    "        val_loader (PyTorch DataLoader) containing the validation data\n",
    "    \"\"\"\n",
    "    with wandb.init(project=PROJECT_NAME, job_type='package-data', config=config) as run:\n",
    "        # Load transforms\n",
    "        transform_dir = run.use_artifact('data-transforms:latest').download()\n",
    "        transform_dict = json.load(open(os.path.join(transform_dir, 'transforms.txt')), object_pairs_hook=OrderedDict)\n",
    "        composed_transforms = get_transforms(transform_dict)\n",
    "\n",
    "        split_artifact = run.use_artifact('data-splits:latest')\n",
    "\n",
    "        # Load splits\n",
    "        # its a wandb.Table data type so we can use the get() method\n",
    "        train_rows = split_artifact.get('train-data').get_column('indices', convert_to='numpy')\n",
    "        val_rows = split_artifact.get('val-data').get_column('indices', convert_to='numpy')\n",
    "\n",
    "        # Reformat data to (inputs, labels)\n",
    "        train_loader = DataLoader(EVCoordDataset(\n",
    "            input_data[train_rows], output_data=output_data, transform=composed_transforms),\n",
    "            batch_size=config['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        val_loader = DataLoader(EVCoordDataset(\n",
    "            input_data[val_rows], output_data=output_data, transform=composed_transforms),\n",
    "            batch_size=config['batch_size'],\n",
    "            batch_sampler=None,\n",
    "            shuffle=False,\n",
    "            num_workers=0)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/Jin Yi/Documents/Optimization/Data-driven-Optimization-of-EV-Charging-Coordination/wandb/run-20230209_235218-323qqocr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jyyresearch/EVCharging/runs/323qqocr\" target=\"_blank\">usual-pond-21</a></strong> to <a href=\"https://wandb.ai/jyyresearch/EVCharging\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EV-coord-raw_data:latest, 669.34MB. 1 files... Done. 0:0:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a23b9c0bb794f9cbf2031791ec6cfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">usual-pond-21</strong>: <a href=\"https://wandb.ai/jyyresearch/EVCharging/runs/323qqocr\" target=\"_blank\">https://wandb.ai/jyyresearch/EVCharging/runs/323qqocr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230209_235218-323qqocr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=PROJECT_NAME, job_type=\"split-data\", config=config) as run:\n",
    "\n",
    "    # Define raw data splits\n",
    "    raw_data = run.use_artifact('jyyresearch/EVCharging/EV-coord-raw_data:latest', type='raw_data')\n",
    "\n",
    "    raw_data_dir = raw_data.download('./Data/')\n",
    "\n",
    "    # read in the h5 files\n",
    "    input_data = h5py.File(os.path.join(raw_data_dir, 'raw_data.hdf5'), 'r')['input_data'][:]\n",
    "    output_data = h5py.File(os.path.join(raw_data_dir, 'raw_data.hdf5'), 'r')['output_data'][:]\n",
    "\n",
    "\n",
    "    # train test split of gc_data and damage_data. Obtain the respective indices\n",
    "    train_val_split = config['train_val_split']\n",
    "    train_val_indices = np.split(np.random.permutation(len(input_data)), [int(train_val_split[0]*len(input_data))])\n",
    "    \n",
    "    make_split_artifact(run, train_val_indices[0], train_val_indices[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/Jin Yi/Documents/Optimization/Data-driven-Optimization-of-EV-Charging-Coordination/wandb/run-20230209_235249-36vh0bc8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jyyresearch/EVCharging/runs/36vh0bc8\" target=\"_blank\">light-snow-22</a></strong> to <a href=\"https://wandb.ai/jyyresearch/EVCharging\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5f8ae521bb4c479034939e4f3e0680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">light-snow-22</strong>: <a href=\"https://wandb.ai/jyyresearch/EVCharging/runs/36vh0bc8\" target=\"_blank\">https://wandb.ai/jyyresearch/EVCharging/runs/36vh0bc8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230209_235249-36vh0bc8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/Jin Yi/Documents/Optimization/Data-driven-Optimization-of-EV-Charging-Coordination/wandb/run-20230209_235310-x23hobbp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jyyresearch/EVCharging/runs/x23hobbp\" target=\"_blank\">fresh-shadow-23</a></strong> to <a href=\"https://wandb.ai/jyyresearch/EVCharging\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe1033dc5774de0a578c67ccef5eeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-shadow-23</strong>: <a href=\"https://wandb.ai/jyyresearch/EVCharging/runs/x23hobbp\" target=\"_blank\">https://wandb.ai/jyyresearch/EVCharging/runs/x23hobbp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230209_235310-x23hobbp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define an initial set of transforms that we think will be useful\n",
    "with wandb.init(project=PROJECT_NAME, job_type='define-transforms', config=config) as run:\n",
    "    transform_dict = OrderedDict()\n",
    "    transform_dict['ToTensor'] = {\n",
    "        'device': DEVICE\n",
    "    }\n",
    "    # Include an operational index to verify the order\n",
    "    for key_idx, key in enumerate(transform_dict.keys()):\n",
    "        transform_dict[key]['order'] = key_idx\n",
    "    # Create an artifact for logging the transforms\n",
    "    data_transform_artifact = wandb.Artifact(\n",
    "        'data-transforms', type='parameters',\n",
    "        description='Data preprocessing functions and parameters.',\n",
    "        metadata=transform_dict) # Optional for viewing on the web app; the data is also stored in the txt file below\n",
    "    # Log the transforms in JSON format\n",
    "    with data_transform_artifact.new_file('transforms.txt') as f:\n",
    "        f.write(json.dumps(transform_dict, indent=4))\n",
    "    run.log_artifact(data_transform_artifact)\n",
    "\n",
    "config.update(transform_dict)\n",
    "\n",
    "train_loader, val_loader = make_loaders(config, input_data=input_data, output_data=output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for model\n",
    "step_size = 30\n",
    "gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, config):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    # binary cross entropy loss, dont average\n",
    "    myloss = nn.BCELoss(reduction='sum')\n",
    "\n",
    "    accum_iter = config['accum_iter']\n",
    "\n",
    "    for batch_idx, (input_data, output_data) in enumerate(train_loader):        \n",
    "    \n",
    "        input_data = input_data.to(device)\n",
    "\n",
    "        predicted_output = model(input_data)\n",
    "\n",
    "        # calculate loss\n",
    "\n",
    "        loss =  myloss(predicted_output, output_data)/accum_iter\n",
    "        loss.backward()\n",
    "\n",
    "        # perform gradient accumulation\n",
    "        if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(train_loader)):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, valid_loader, config):\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "\n",
    "    data_list = []\n",
    "    output_list = []\n",
    "    predicted_output_list = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        myloss = nn.BCELoss(reduction='sum')\n",
    "\n",
    "        for batch_idx, (input_data, output_data) in enumerate(valid_loader):      \n",
    "            input_data = input_data.to(device)\n",
    "\n",
    "            predicted_output = model(input_data)\n",
    "\n",
    "        # calculate loss\n",
    "\n",
    "            loss =  myloss(predicted_output, output_data)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            data_list.append(input_data)\n",
    "            output_list.append(output_data)\n",
    "            predicted_output_list.append(predicted_output)\n",
    "        \n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "\n",
    "    return valid_loss, data_list, output_list, predicted_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size: int, output_size: int, n_neurons: int,          \n",
    "        ):\n",
    "\n",
    "        super(BaseNet, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, n_neurons)\n",
    "        # weight initialization (Lecun Normal Default)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='linear')\n",
    "\n",
    "        self.fc2 = nn.Linear(n_neurons, 2*n_neurons)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_in', nonlinearity='linear')\n",
    "\n",
    "        self.fc3 = nn.Linear(2*n_neurons, 2*n_neurons)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight, mode='fan_in', nonlinearity='linear')\n",
    "\n",
    "        self.fc4 = nn.Linear(2*n_neurons, output_size)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.selu = nn.SELU(True)\n",
    "        # self.relu = nn.ReLU(True)\n",
    "\n",
    "        # layer normalization\n",
    "        self.layer_norm1 = nn.LayerNorm(n_neurons)\n",
    "        self.layer_norm2 = nn.LayerNorm(2*n_neurons)\n",
    "        self.layer_norm3 = nn.LayerNorm(2*n_neurons)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # selu\n",
    "        x = self.selu(self.fc1(x))\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.selu(self.fc2(x))\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.selu(self.fc3(x))\n",
    "        x = self.layer_norm3(x)\n",
    "\n",
    "        x = self.selu(self.fc4(x))\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 14796)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m MODEL_NAME_RUN \u001b[39m=\u001b[39m MODEL_NAME \u001b[39m+\u001b[39m N_neurons_str\n\u001b[1;32m     30\u001b[0m today \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m---> 32\u001b[0m model \u001b[39m=\u001b[39m BaseNet(\n\u001b[1;32m     33\u001b[0m     input_size\u001b[39m=\u001b[39;49minput_data\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m     34\u001b[0m     output_size\u001b[39m=\u001b[39;49moutput_data\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m     35\u001b[0m     n_neurons\u001b[39m=\u001b[39;49mwidth,\n\u001b[1;32m     36\u001b[0m )\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mDEVICE)\n\u001b[1;32m     38\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m     39\u001b[0m optimizer \u001b[39m=\u001b[39m AdamW(params, lr\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mLEARNING_RATE\u001b[39m\u001b[39m\"\u001b[39m], weight_decay\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/phasefield/lib/python3.8/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/miniconda3/envs/phasefield/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/phasefield/lib/python3.8/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/phasefield/lib/python3.8/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# for deterministic pytorch algorithms, enable reproducibility.\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "# n in n_list > input_data.shape[-1]\n",
    "n_list = [80]\n",
    "\n",
    "BETA1 = config[\"BETA1\"]\n",
    "BETA2 = config[\"BETA2\"]\n",
    "\n",
    "EPOCHS = config[\"EPOCHS\"]\n",
    "BATCH_SIZE = config[\"batch_size\"]\n",
    "\n",
    "MODEL_NAME = \"model_BaseNet\"\n",
    "\n",
    "LOCAL_MODEL_DIR_LIST = []\n",
    "\n",
    "for i in range(len(n_list)):\n",
    "\n",
    "    min_valid_loss = np.inf\n",
    "\n",
    "    width = n_list[i]\n",
    "\n",
    "    N_neurons_str = str(width)\n",
    "\n",
    "    MODEL_NAME_RUN = MODEL_NAME + N_neurons_str\n",
    "    LOCAL_MODEL_DIR = 'Model/' + MODEL_NAME_RUN + '.pt'\n",
    "    LOCAL_MODEL_DIR_LIST.append(LOCAL_MODEL_DIR)\n",
    "    MODEL_NAME_RUN = MODEL_NAME + N_neurons_str\n",
    "\n",
    "    today = datetime.datetime.now()\n",
    "\n",
    "    model = BaseNet(\n",
    "        input_size=input_data.shape[-1],\n",
    "        output_size=output_data.shape[-1],\n",
    "        n_neurons=width,\n",
    "    ).to(device=DEVICE)\n",
    "\n",
    "    params = list(model.parameters())\n",
    "    optimizer = AdamW(params, lr=config[\"LEARNING_RATE\"], weight_decay=1e-4)\n",
    "    optimizer = dadaptation.DAdaptAdam(\n",
    "        params, lr=1, log_every=5, betas=(BETA1, BETA2), growth_rate=1.01\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "\n",
    "    data_list = []\n",
    "    output_list = []\n",
    "    predicted_output_list = []\n",
    "\n",
    "    wandb.init(\n",
    "        anonymous=\"allow\",\n",
    "        project=PROJECT_NAME,\n",
    "        name=today.strftime(\"%Y%m%d_%H%M\"),\n",
    "        config={\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"batch_size\": BATCH_SIZE * config[\"accum_iter\"],\n",
    "            \"lr\": \"1e-3\",\n",
    "            \"step_size\": step_size,\n",
    "            \"gamma\": gamma,\n",
    "            \"width\": width,\n",
    "            \"loss \": \"L2Loss\",\n",
    "            \"activation func\": \"SELU\",\n",
    "            \"lr decay\": \"steplr, gamma=0.5\",\n",
    "            \"architecture\": \"BaseNet\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "        # get current learning rate\n",
    "        curr_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        train_loss = train(model, DEVICE, train_loader, optimizer, config)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        valid_loss, data_list, output_list, predicted_output_list = validate(\n",
    "            model, DEVICE, val_loader, config\n",
    "        )\n",
    "        print(\n",
    "            \"Epoch: {:03d}, Train Loss: {:.7f}, Valid Loss: {:.7f}, LR: {:.7f}\".format(\n",
    "                epoch, train_loss, valid_loss, curr_lr\n",
    "            )\n",
    "        )\n",
    "        # wandb.log({'train_loss': train_loss, 'valid_loss': valid_loss})\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "\n",
    "        if valid_loss < min_valid_loss:\n",
    "            print(\n",
    "                \"Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...\".format(\n",
    "                    min_valid_loss, valid_loss\n",
    "                )\n",
    "            )\n",
    "            min_valid_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            # save model with current hour as name\n",
    "            torch.save(model.state_dict(), LOCAL_MODEL_DIR )\n",
    "            print(\"Saved model at epoch {}\".format(epoch))\n",
    "\n",
    "\n",
    "    # version control model\n",
    "    run = wandb.init(project=PROJECT_NAME, job_type='version-model', config=config)\n",
    "    trained_model_at = wandb.Artifact(PROJECT_NAME + N_neurons_str, type=\"model\", description=\"trained baseline for \" + PROJECT_NAME)\n",
    "    trained_model_at.add_file(LOCAL_MODEL_DIR, name=MODEL_NAME_RUN + '.pt')\n",
    "    run.log_artifact(trained_model_at)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version control model\n",
    "run = wandb.init(project=PROJECT_NAME, job_type='version-model', config=config)\n",
    "trained_model_at = wandb.Artifact(\"FNO2D\", type=\"model\", description=\"trained baseline for FNO2D\", aliases=['baseline', 'latest'])\n",
    "trained_model_at.add_file(LOCAL_MODEL_DIR, name='model_FNO2D.pt')\n",
    "trained_model_at.add_file(LOCAL_MODEL_IPHI_DIR, name='model_iphi_FNO2D.pt')\n",
    "run.log_artifact(trained_model_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version control model\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"inference\", config=config)\n",
    "trained_model_at = run.use_artifact(\"FNO2D:latest\", type=\"model\")\n",
    "model_dir = trained_model_at.download()\n",
    "\n",
    "# load best model\n",
    "model = FNO2D.FNO2d(modes, modes, width=32, in_channels=3, out_channels=1, s1=s, s2=s).cuda()\n",
    "model_iphi = FNO2D.IPHI_constant(width=32).cuda()\n",
    "\n",
    "model = model.load_state_dict(torch.load(os.path.join(model_dir, 'model_FNO2D.pt')))\n",
    "model_iphi = model_iphi.load_state_dict(torch.load(os.path.join(model_dir, 'model_iphi_FNO2D.pt')))\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, data_list, output_list, damage_list = validate(model, device, val_loader, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phasefield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb9419f644557548447ecb0f1119aef2567eb0b9ec92744eeb7ce809f1fc1aa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
