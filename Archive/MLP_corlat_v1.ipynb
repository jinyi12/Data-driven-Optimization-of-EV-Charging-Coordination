{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for training MLP for the CORLAT dataset $\\color{lightblue}\\text{without multiple solutions}$\n",
    "\n",
    "This notebook trains a MLP for the initial CORLAT dataset named `corlat_v1` that does not contain multiple solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import os\n",
    "import gurobipy as gb\n",
    "\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch.nn.functional import relu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = (\n",
    "        False  # Force cuDNN to use a consistent convolution algorithm\n",
    "    )\n",
    "    torch.backends.cudnn.deterministic = (\n",
    "        True  # Force cuDNN to use deterministic algorithms if available\n",
    "    )\n",
    "    torch.use_deterministic_algorithms(\n",
    "        True\n",
    "    )  # Force torch to use deterministic algorithms if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'train_val_split': [0.80, 0.20], # These must sum to 1.0\n",
    "        'batch_size' : 32, # Num samples to average over for gradient updates\n",
    "        'EPOCHS' : 1000, # Num times to iterate over the entire dataset\n",
    "        'LEARNING_RATE' : 1e-3, # Learning rate for the optimizer\n",
    "        'BETA1' : 0.9, # Beta1 parameter for the Adam optimizer\n",
    "        'BETA2' : 0.999, # Beta2 parameter for the Adam optimizer\n",
    "        'WEIGHT_DECAY' : 1e-4, # Weight decay parameter for the Adam optimizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_idx = np.load(\"Data/corlat_v1_backup/train_idx_v1.npy\")\n",
    "test_idx = np.load(\"Data/corlat_v1_backup/test_idx_v1.npy\")\n",
    "\n",
    "X_train = np.load(\"Data/corlat_v1_backup/X_train_v1.npy\")\n",
    "X_test = np.load(\"Data/corlat_v1_backup/X_test_v1.npy\")\n",
    "y_train = np.load(\"Data/corlat_v1_backup/y_train_v1.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"Data/corlat_v1_backup/y_test_v1.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "out_channels = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_features//4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(n_features//4, n_features//2)\n",
    "        self.fc3 = nn.Linear(n_features//2, n_features//2)\n",
    "        self.fc4 = nn.Linear(n_features//2, out_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # add regularization\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()\n",
    "# net = torch.compile(net)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "# create the dataloader for X and solutions\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_train), torch.tensor(y_train)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_test), torch.tensor(y_test)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "params = list(net.parameters())\n",
    "\n",
    "# optimizer = AdamW(params, lr=config['LEARNING_RATE'], weight_decay=1e-4)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "# optimizer = dadaptation.DAdaptAdam(params, lr=1, log_every=5, betas=(BETA1, BETA2), weight_decay=1e-4, decouple=True)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "total_steps = len(train_loader)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config['LEARNING_RATE'], steps_per_epoch=total_steps, epochs=config['EPOCHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (fc1): Linear(in_features=13898, out_features=3474, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=3474, out_features=6949, bias=True)\n",
       "  (fc3): Linear(in_features=6949, out_features=6949, bias=True)\n",
       "  (fc4): Linear(in_features=6949, out_features=100, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config[\"EPOCHS\"]):\n",
    "    running_loss = 0.0\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f lr: %.6f' % (epoch + 1, running_loss / len(train_loader), curr_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if X_test is numpy array convert to tensor\n",
    "if isinstance(X_test, np.ndarray):\n",
    "    X_test = torch.tensor(X_test)\n",
    "    \n",
    "# if net device is cpu convert X_test to cpu, else convert to cuda\n",
    "if next(net.parameters()).device == torch.device(\"cpu\"):\n",
    "    X_test = X_test.cpu()\n",
    "else:\n",
    "    X_test = X_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7200379266750949\n",
      "Precision:  0.7599066044029353\n",
      "Recall:  0.6841441441441442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_767776/837471902.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = net(torch.tensor(X_test))\n",
      "/tmp/ipykernel_767776/837471902.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = y_test.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# validation of the model using f1 score, precision and recall\n",
    "y_pred = net(torch.tensor(X_test))\n",
    "y_pred = y_pred.cpu().detach().numpy()\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "y_test = y_test.astype(np.int)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average=\"micro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feasibility_test(batch_size, y_pred, test_models, indices):\n",
    "    \n",
    "    n_violated_constraints = []\n",
    "\n",
    "    # convert predictions of N_samples, N_variables to binary\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "    \n",
    "    # Compute the weights for each training instance\n",
    "    for i in range(len(test_models)):\n",
    "        \n",
    "        model = test_models[i]\n",
    "        \n",
    "        modelVars = model.getVars()\n",
    "        \n",
    "        instanceBinaryIndices = indices\n",
    "\n",
    "        # need to relax the binary variables to continuous variables with bounds of 0 and 1, we can use the setAttr method to change their vtype attribute\n",
    "        for j in range(len(instanceBinaryIndices)):\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"C\")\n",
    "\n",
    "            # for each index in firstInstanceTestBinaryIndices, set the value of the corresponding variable to the value predicted by xgboost\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "        \n",
    "        \n",
    "        # Compute the IIS to find the list of violated constraints and variables\n",
    "        try:\n",
    "            model.computeIIS()\n",
    "        except gb.GurobiError:\n",
    "            print(\"Model is feasible\")\n",
    "            n_violated_constraints.append(0)\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # get number of violated constraints\n",
    "        IISConstr = model.getAttr(\"IISConstr\", model.getConstrs())\n",
    "\n",
    "        # count number of non zero elements in IISConstr        \n",
    "        n_violated_constraints.append(np.count_nonzero(IISConstr))\n",
    "        \n",
    "    return n_violated_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-01\n"
     ]
    }
   ],
   "source": [
    "test_models = []\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "model_files = os.listdir(\"instances/mip/data/COR-LAT\")\n",
    "for i in range(len(test_idx)):\n",
    "    model = gb.read(\"instances/mip/data/COR-LAT/\" + model_files[test_idx[i]], env=gurobi_env)\n",
    "    test_models.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n"
     ]
    }
   ],
   "source": [
    "n_violated_constraints = []\n",
    "binary_indices = corlat_dataset[0][\"indices\"][\"indices\"]\n",
    "for i, data in enumerate(valid_loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # get slices of test_models according to batch size\n",
    "    len_test_models = len(test_models)\n",
    "    test_models_batch = test_models[i*batch_size: min((i+1)*batch_size, len_test_models)]\n",
    "    \n",
    "    n_violated_constraints_batch = feasibility_test(batch_size, outputs.detach().cpu().numpy(), test_models_batch, binary_indices)\n",
    "    \n",
    "    n_violated_constraints.append(n_violated_constraints_batch)\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of violated constraints:  3.085\n"
     ]
    }
   ],
   "source": [
    "# count average number of violated constraints by flattening the list\n",
    "n_violated_constraints = [item for sublist in n_violated_constraints for item in sublist]\n",
    "print(\"Average number of violated constraints: \", np.mean(n_violated_constraints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of n_violated_constraints:  400\n",
      "[1, 1, 36, 17, 1, 1, 1, 1, 1, 1, 2, 1, 8, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 20, 1, 1, 1, 2, 1, 1, 1, 1, 1, 17, 1, 1, 0, 1, 28, 1, 1, 2, 1, 1, 1, 1, 1, 12, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 50, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 1, 19, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 13, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 22, 1, 1, 2, 1, 1, 1, 2, 1, 30, 1, 2, 26, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 42, 1, 8, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 56, 1, 1, 2, 1, 1, 1, 51, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 24, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 5, 30, 27, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 12, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 73, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 68, 2, 1, 1, 25, 2, 1, 1, 1, 1, 24, 1, 1, 1, 1, 1, 1, 22, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of n_violated_constraints: \", len(n_violated_constraints))\n",
    "print(n_violated_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diving_opt_time(models, binary_indices, y_pred):\n",
    "    \n",
    "    opt_time = []\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        \n",
    "        modelVars = model.getVars()\n",
    "        \n",
    "        instanceBinaryIndices = binary_indices\n",
    "        \n",
    "        y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "        \n",
    "        # need to relax the binary variables to continuous variables with bounds of 0 and 1, we can use the setAttr method to change their vtype attribute\n",
    "        for j in range(len(instanceBinaryIndices)):\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"C\")\n",
    "\n",
    "            # for each index in firstInstanceTestBinaryIndices, set the value of the corresponding variable to the value predicted by xgboost\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "        \n",
    "        \n",
    "        # Compute the IIS to find the list of violated constraints and variables\n",
    "        try:\n",
    "            model.computeIIS()\n",
    "            infeasible_flag = True\n",
    "        except gb.GurobiError:\n",
    "            print(\"Model is feasible\")\n",
    "            infeasible_flag = False\n",
    "            continue\n",
    "        \n",
    "        if infeasible_flag:\n",
    "            for j in range(len(instanceBinaryIndices)):\n",
    "                if modelVars[instanceBinaryIndices[j]].IISLB == 0 and modelVars[instanceBinaryIndices[j]].IISUB == 0:\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                    # for each index in binary_indices, set the value of the corresponding variable to the value predicted by model\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])                     \n",
    "                    \n",
    "                    # else if the variable is in the IIS, \n",
    "                    # get the relaxed variable and \n",
    "                    # set the bounds to 0 and 1 for the relaxed binary variables\n",
    "                else:\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", 0)\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", 1)\n",
    "        \n",
    "        else:\n",
    "            for j in range(len(instanceBinaryIndices)):\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "        \n",
    "        model.Params.Threads = 1\n",
    "        model.optimize()\n",
    "        print(\"Optimization time for model \", i, \": \", model.Runtime)\n",
    "        opt_time.append(model.Runtime)\n",
    "        \n",
    "    return opt_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-01\n",
      "Optimization time for model  0 :  0.0003139972686767578\n",
      "Optimization time for model  1 :  0.0001800060272216797\n",
      "Optimization time for model  2 :  0.0001919269561767578\n",
      "Optimization time for model  3 :  0.0018579959869384766\n",
      "Optimization time for model  4 :  0.00015401840209960938\n",
      "Optimization time for model  5 :  0.49094700813293457\n",
      "Optimization time for model  6 :  0.00018715858459472656\n",
      "Optimization time for model  7 :  0.0001430511474609375\n",
      "Optimization time for model  8 :  0.00014495849609375\n",
      "Optimization time for model  9 :  0.00017690658569335938\n",
      "Optimization time for model  10 :  0.00014209747314453125\n",
      "Optimization time for model  11 :  0.00011897087097167969\n",
      "Optimization time for model  12 :  0.00017213821411132812\n",
      "Optimization time for model  13 :  0.0001380443572998047\n",
      "Optimization time for model  14 :  0.144395112991333\n",
      "Optimization time for model  15 :  0.3048369884490967\n",
      "Optimization time for model  16 :  0.0001990795135498047\n",
      "Optimization time for model  17 :  0.0001659393310546875\n",
      "Optimization time for model  18 :  0.00014495849609375\n",
      "Optimization time for model  19 :  0.3672611713409424\n",
      "Optimization time for model  20 :  0.00015878677368164062\n",
      "Optimization time for model  21 :  0.0001480579376220703\n",
      "Optimization time for model  22 :  1.943911075592041\n",
      "Optimization time for model  23 :  0.0002009868621826172\n",
      "Optimization time for model  24 :  0.0001780986785888672\n",
      "Optimization time for model  25 :  0.00021719932556152344\n",
      "Optimization time for model  26 :  0.00011801719665527344\n",
      "Optimization time for model  27 :  0.008033990859985352\n",
      "Optimization time for model  28 :  0.0001308917999267578\n",
      "Optimization time for model  29 :  0.0001480579376220703\n",
      "Optimization time for model  30 :  0.00012111663818359375\n",
      "Optimization time for model  31 :  0.00017595291137695312\n",
      "Optimization time for model  0 :  0.0001327991485595703\n",
      "Optimization time for model  1 :  0.00015282630920410156\n",
      "Optimization time for model  2 :  0.000186920166015625\n",
      "Optimization time for model  3 :  6.541991949081421\n",
      "Optimization time for model  4 :  0.00015020370483398438\n",
      "Optimization time for model  5 :  0.0001938343048095703\n",
      "Optimization time for model  6 :  0.00017905235290527344\n",
      "Optimization time for model  7 :  1.8188607692718506\n",
      "Optimization time for model  8 :  0.0037670135498046875\n",
      "Optimization time for model  9 :  0.00015282630920410156\n",
      "Optimization time for model  10 :  0.0001380443572998047\n",
      "Optimization time for model  11 :  0.0001399517059326172\n",
      "Optimization time for model  12 :  2.3798959255218506\n",
      "Optimization time for model  13 :  0.00025916099548339844\n",
      "Optimization time for model  14 :  0.00016689300537109375\n",
      "Optimization time for model  15 :  0.00014901161193847656\n",
      "Optimization time for model  16 :  0.00014519691467285156\n",
      "Optimization time for model  17 :  1.0812759399414062\n",
      "Optimization time for model  18 :  0.00020599365234375\n",
      "Optimization time for model  19 :  0.1362149715423584\n",
      "Optimization time for model  20 :  0.0002040863037109375\n",
      "Optimization time for model  21 :  0.00015616416931152344\n",
      "Optimization time for model  22 :  0.0001780986785888672\n",
      "Optimization time for model  23 :  0.00017118453979492188\n",
      "Optimization time for model  24 :  0.0001220703125\n",
      "Optimization time for model  25 :  0.0001468658447265625\n",
      "Optimization time for model  26 :  0.0001289844512939453\n",
      "Optimization time for model  27 :  0.00012993812561035156\n",
      "Optimization time for model  28 :  0.00017714500427246094\n",
      "Optimization time for model  29 :  0.00014400482177734375\n",
      "Optimization time for model  30 :  0.00019407272338867188\n",
      "Optimization time for model  31 :  0.0001590251922607422\n",
      "Optimization time for model  0 :  0.00013399124145507812\n",
      "Optimization time for model  1 :  0.0001900196075439453\n",
      "Optimization time for model  2 :  0.00017905235290527344\n",
      "Optimization time for model  3 :  0.00017786026000976562\n",
      "Optimization time for model  4 :  0.0004200935363769531\n",
      "Optimization time for model  5 :  0.0001850128173828125\n",
      "Optimization time for model  6 :  0.00017786026000976562\n",
      "Optimization time for model  7 :  0.00015211105346679688\n",
      "Optimization time for model  8 :  2.5845959186553955\n",
      "Optimization time for model  9 :  0.00021004676818847656\n",
      "Optimization time for model  10 :  0.00013899803161621094\n",
      "Optimization time for model  11 :  0.00015497207641601562\n",
      "Optimization time for model  12 :  0.00017404556274414062\n",
      "Optimization time for model  13 :  2.239474058151245\n",
      "Optimization time for model  14 :  0.0002071857452392578\n",
      "Optimization time for model  15 :  0.00015306472778320312\n",
      "Optimization time for model  16 :  0.00013899803161621094\n",
      "Optimization time for model  17 :  0.00014090538024902344\n",
      "Optimization time for model  18 :  0.7420029640197754\n",
      "Optimization time for model  19 :  0.0001609325408935547\n",
      "Optimization time for model  20 :  0.0001728534698486328\n",
      "Optimization time for model  21 :  0.00015807151794433594\n",
      "Optimization time for model  22 :  0.26131510734558105\n",
      "Optimization time for model  23 :  2.43320894241333\n",
      "Optimization time for model  24 :  0.0002079010009765625\n",
      "Optimization time for model  25 :  1.8483080863952637\n",
      "Optimization time for model  26 :  0.00017905235290527344\n",
      "Optimization time for model  27 :  0.00015401840209960938\n",
      "Optimization time for model  28 :  0.00019097328186035156\n",
      "Optimization time for model  29 :  0.00015282630920410156\n",
      "Optimization time for model  30 :  1.6951789855957031\n",
      "Optimization time for model  31 :  0.0002090930938720703\n",
      "Optimization time for model  0 :  0.00015401840209960938\n",
      "Optimization time for model  1 :  4.526065826416016\n",
      "Optimization time for model  2 :  0.00020813941955566406\n",
      "Optimization time for model  3 :  2.634657859802246\n",
      "Optimization time for model  4 :  0.0001780986785888672\n",
      "Optimization time for model  5 :  1.770819902420044\n",
      "Optimization time for model  6 :  0.22507500648498535\n",
      "Optimization time for model  7 :  0.0001609325408935547\n",
      "Optimization time for model  8 :  0.00014400482177734375\n",
      "Optimization time for model  9 :  0.0001671314239501953\n",
      "Optimization time for model  10 :  0.0001919269561767578\n",
      "Optimization time for model  11 :  0.0001289844512939453\n",
      "Optimization time for model  12 :  0.0004031658172607422\n",
      "Optimization time for model  13 :  0.0001690387725830078\n",
      "Optimization time for model  14 :  0.00014710426330566406\n",
      "Optimization time for model  15 :  0.00012683868408203125\n",
      "Optimization time for model  16 :  0.00011897087097167969\n",
      "Optimization time for model  17 :  0.00016689300537109375\n",
      "Optimization time for model  18 :  0.00011897087097167969\n",
      "Optimization time for model  19 :  0.00011992454528808594\n",
      "Optimization time for model  20 :  0.00011706352233886719\n",
      "Optimization time for model  21 :  0.000141143798828125\n",
      "Optimization time for model  22 :  0.0001659393310546875\n",
      "Optimization time for model  23 :  0.0001380443572998047\n",
      "Optimization time for model  24 :  0.0001251697540283203\n",
      "Optimization time for model  25 :  0.000164031982421875\n",
      "Optimization time for model  26 :  0.0001220703125\n",
      "Optimization time for model  27 :  0.00012493133544921875\n",
      "Optimization time for model  28 :  0.0001430511474609375\n",
      "Optimization time for model  29 :  0.00012111663818359375\n",
      "Optimization time for model  30 :  0.00014281272888183594\n",
      "Optimization time for model  31 :  2.560688018798828\n",
      "Optimization time for model  0 :  0.00015807151794433594\n",
      "Optimization time for model  1 :  0.00014901161193847656\n",
      "Optimization time for model  2 :  5.564981937408447\n",
      "Optimization time for model  3 :  0.019583940505981445\n",
      "Optimization time for model  4 :  4.807080984115601\n",
      "Optimization time for model  5 :  0.00015997886657714844\n",
      "Optimization time for model  6 :  0.00020194053649902344\n",
      "Optimization time for model  7 :  0.00013899803161621094\n",
      "Optimization time for model  8 :  0.00019097328186035156\n",
      "Optimization time for model  9 :  0.0001862049102783203\n",
      "Optimization time for model  10 :  12.28572392463684\n",
      "Optimization time for model  11 :  0.0001628398895263672\n",
      "Optimization time for model  12 :  0.0001430511474609375\n",
      "Optimization time for model  13 :  0.00012993812561035156\n",
      "Optimization time for model  14 :  0.000125885009765625\n",
      "Optimization time for model  15 :  0.00011801719665527344\n",
      "Optimization time for model  16 :  0.00017189979553222656\n",
      "Optimization time for model  17 :  0.00012803077697753906\n",
      "Optimization time for model  18 :  0.0001609325408935547\n",
      "Optimization time for model  19 :  0.00017595291137695312\n",
      "Optimization time for model  20 :  0.00018978118896484375\n",
      "Optimization time for model  21 :  0.0001780986785888672\n",
      "Optimization time for model  22 :  0.00014090538024902344\n",
      "Optimization time for model  23 :  0.00012302398681640625\n",
      "Optimization time for model  24 :  0.00016617774963378906\n",
      "Model is feasible\n",
      "Optimization time for model  26 :  0.00013399124145507812\n",
      "Optimization time for model  27 :  0.0001308917999267578\n",
      "Model is feasible\n",
      "Optimization time for model  29 :  0.3261430263519287\n",
      "Optimization time for model  30 :  1.7921149730682373\n",
      "Optimization time for model  31 :  0.00013589859008789062\n",
      "Optimization time for model  0 :  0.7560892105102539\n",
      "Optimization time for model  1 :  0.0002090930938720703\n",
      "Optimization time for model  2 :  1.671525001525879\n",
      "Optimization time for model  3 :  0.0002028942108154297\n",
      "Optimization time for model  4 :  0.0001900196075439453\n",
      "Optimization time for model  5 :  0.00015783309936523438\n",
      "Optimization time for model  6 :  0.00012683868408203125\n",
      "Optimization time for model  7 :  0.00012612342834472656\n",
      "Optimization time for model  8 :  0.00015306472778320312\n",
      "Optimization time for model  9 :  0.00012183189392089844\n",
      "Optimization time for model  10 :  0.00015115737915039062\n",
      "Optimization time for model  11 :  0.0001709461212158203\n",
      "Optimization time for model  12 :  0.00011992454528808594\n",
      "Optimization time for model  13 :  0.00014495849609375\n",
      "Optimization time for model  14 :  0.0001709461212158203\n",
      "Optimization time for model  15 :  0.0001671314239501953\n",
      "Optimization time for model  16 :  1.2522480487823486\n",
      "Optimization time for model  17 :  0.00020003318786621094\n",
      "Optimization time for model  18 :  0.009544849395751953\n",
      "Optimization time for model  19 :  0.00015401840209960938\n",
      "Optimization time for model  20 :  2.538400888442993\n",
      "Optimization time for model  21 :  0.00015401840209960938\n",
      "Optimization time for model  22 :  0.00018715858459472656\n",
      "Optimization time for model  23 :  0.0001780986785888672\n",
      "Optimization time for model  24 :  0.00017189979553222656\n",
      "Optimization time for model  25 :  0.00012612342834472656\n",
      "Optimization time for model  26 :  0.00017189979553222656\n",
      "Optimization time for model  27 :  0.0001881122589111328\n",
      "Optimization time for model  28 :  0.0001800060272216797\n",
      "Optimization time for model  29 :  0.0001728534698486328\n",
      "Optimization time for model  30 :  0.0001220703125\n",
      "Optimization time for model  31 :  0.00013685226440429688\n",
      "Optimization time for model  0 :  0.00017690658569335938\n",
      "Optimization time for model  1 :  0.00017404556274414062\n",
      "Optimization time for model  2 :  0.0599980354309082\n",
      "Optimization time for model  3 :  0.00012993812561035156\n",
      "Optimization time for model  4 :  0.00012803077697753906\n",
      "Optimization time for model  5 :  0.0001461505889892578\n",
      "Optimization time for model  6 :  0.00024199485778808594\n",
      "Optimization time for model  7 :  0.0001537799835205078\n",
      "Optimization time for model  8 :  0.00015306472778320312\n",
      "Optimization time for model  9 :  0.0001590251922607422\n",
      "Optimization time for model  10 :  0.00013709068298339844\n",
      "Optimization time for model  11 :  0.0001480579376220703\n",
      "Optimization time for model  12 :  0.00018095970153808594\n",
      "Optimization time for model  13 :  0.00012993812561035156\n",
      "Optimization time for model  14 :  0.0001201629638671875\n",
      "Optimization time for model  15 :  2.274129867553711\n",
      "Optimization time for model  16 :  0.5511901378631592\n",
      "Optimization time for model  17 :  0.0002090930938720703\n",
      "Optimization time for model  18 :  0.0001552104949951172\n",
      "Optimization time for model  19 :  0.00015020370483398438\n",
      "Optimization time for model  20 :  0.00018310546875\n",
      "Optimization time for model  21 :  0.0001461505889892578\n",
      "Optimization time for model  22 :  0.00017213821411132812\n",
      "Optimization time for model  23 :  0.010849952697753906\n",
      "Optimization time for model  24 :  0.0003960132598876953\n",
      "Optimization time for model  25 :  0.00017499923706054688\n",
      "Optimization time for model  26 :  0.00019097328186035156\n",
      "Optimization time for model  27 :  0.00014495849609375\n",
      "Optimization time for model  28 :  0.0001430511474609375\n",
      "Optimization time for model  29 :  0.00013709068298339844\n",
      "Optimization time for model  30 :  0.0001819133758544922\n",
      "Optimization time for model  31 :  0.0001239776611328125\n",
      "Optimization time for model  0 :  0.00018405914306640625\n",
      "Optimization time for model  1 :  0.0001709461212158203\n",
      "Optimization time for model  2 :  0.00017714500427246094\n",
      "Optimization time for model  3 :  0.00012683868408203125\n",
      "Optimization time for model  4 :  0.0001518726348876953\n",
      "Optimization time for model  5 :  1.6234161853790283\n",
      "Optimization time for model  6 :  0.0013668537139892578\n",
      "Optimization time for model  7 :  0.0001919269561767578\n",
      "Optimization time for model  8 :  0.0001800060272216797\n",
      "Optimization time for model  9 :  0.00042891502380371094\n",
      "Optimization time for model  10 :  0.1782209873199463\n",
      "Optimization time for model  11 :  0.00015211105346679688\n",
      "Optimization time for model  12 :  0.0001900196075439453\n",
      "Optimization time for model  13 :  4.063139915466309\n",
      "Optimization time for model  14 :  0.00015211105346679688\n",
      "Optimization time for model  15 :  0.0001900196075439453\n",
      "Optimization time for model  16 :  0.00015592575073242188\n",
      "Optimization time for model  17 :  2.947299003601074\n",
      "Optimization time for model  18 :  0.00015401840209960938\n",
      "Optimization time for model  19 :  0.00019097328186035156\n",
      "Optimization time for model  20 :  0.0001289844512939453\n",
      "Model is feasible\n",
      "Optimization time for model  22 :  0.00015401840209960938\n",
      "Optimization time for model  23 :  0.0001499652862548828\n",
      "Optimization time for model  24 :  0.00017404556274414062\n",
      "Optimization time for model  25 :  0.08199095726013184\n",
      "Optimization time for model  26 :  0.10550498962402344\n",
      "Optimization time for model  27 :  0.000141143798828125\n",
      "Optimization time for model  28 :  0.00015497207641601562\n",
      "Optimization time for model  29 :  0.0001289844512939453\n",
      "Optimization time for model  30 :  0.00012183189392089844\n",
      "Optimization time for model  31 :  0.4284939765930176\n",
      "Optimization time for model  0 :  0.06361103057861328\n",
      "Optimization time for model  1 :  0.00014090538024902344\n",
      "Optimization time for model  2 :  0.00015306472778320312\n",
      "Optimization time for model  3 :  2.0408170223236084\n",
      "Optimization time for model  4 :  0.00015306472778320312\n",
      "Optimization time for model  5 :  0.0026900768280029297\n",
      "Optimization time for model  6 :  1.6086549758911133\n",
      "Optimization time for model  7 :  0.00015306472778320312\n",
      "Optimization time for model  8 :  0.00015997886657714844\n",
      "Optimization time for model  9 :  2.9477360248565674\n",
      "Optimization time for model  10 :  0.0001862049102783203\n",
      "Optimization time for model  11 :  0.0001270771026611328\n",
      "Optimization time for model  12 :  0.00017690658569335938\n",
      "Optimization time for model  13 :  0.0001678466796875\n",
      "Optimization time for model  14 :  0.36800217628479004\n",
      "Optimization time for model  15 :  0.0002009868621826172\n",
      "Optimization time for model  16 :  0.00020384788513183594\n",
      "Optimization time for model  17 :  0.00019121170043945312\n",
      "Optimization time for model  18 :  0.00017905235290527344\n",
      "Optimization time for model  19 :  0.00019693374633789062\n",
      "Optimization time for model  20 :  0.0001289844512939453\n",
      "Optimization time for model  21 :  0.0001671314239501953\n",
      "Optimization time for model  22 :  0.0001220703125\n",
      "Optimization time for model  23 :  0.0001659393310546875\n",
      "Optimization time for model  24 :  0.00017595291137695312\n",
      "Optimization time for model  25 :  0.00016999244689941406\n",
      "Optimization time for model  26 :  0.39542508125305176\n",
      "Optimization time for model  27 :  0.00013113021850585938\n",
      "Optimization time for model  28 :  0.0001761913299560547\n",
      "Optimization time for model  29 :  0.0001480579376220703\n",
      "Optimization time for model  30 :  0.49051594734191895\n",
      "Optimization time for model  31 :  0.0001418590545654297\n",
      "Optimization time for model  0 :  0.0001418590545654297\n",
      "Optimization time for model  1 :  8.46695590019226\n",
      "Optimization time for model  2 :  0.000141143798828125\n",
      "Optimization time for model  3 :  0.0001938343048095703\n",
      "Optimization time for model  4 :  0.0074918270111083984\n",
      "Optimization time for model  5 :  1.4990530014038086\n",
      "Optimization time for model  6 :  0.0002028942108154297\n",
      "Optimization time for model  7 :  0.00017404556274414062\n",
      "Optimization time for model  8 :  0.0001690387725830078\n",
      "Optimization time for model  9 :  0.00012302398681640625\n",
      "Optimization time for model  10 :  0.0001239776611328125\n",
      "Optimization time for model  11 :  0.0001678466796875\n",
      "Optimization time for model  12 :  0.00011587142944335938\n",
      "Optimization time for model  13 :  0.00016999244689941406\n",
      "Optimization time for model  14 :  0.000141143798828125\n",
      "Optimization time for model  15 :  0.9889841079711914\n",
      "Optimization time for model  16 :  0.00015616416931152344\n",
      "Optimization time for model  17 :  0.0002181529998779297\n",
      "Optimization time for model  18 :  0.00012993812561035156\n",
      "Optimization time for model  19 :  0.00012493133544921875\n",
      "Optimization time for model  20 :  0.00014710426330566406\n",
      "Optimization time for model  21 :  0.0031180381774902344\n",
      "Optimization time for model  22 :  0.00013017654418945312\n",
      "Optimization time for model  23 :  0.0001239776611328125\n",
      "Optimization time for model  24 :  0.00012087821960449219\n",
      "Optimization time for model  25 :  0.00017309188842773438\n",
      "Optimization time for model  26 :  0.000141143798828125\n",
      "Optimization time for model  27 :  0.0001201629638671875\n",
      "Optimization time for model  28 :  0.00013899803161621094\n",
      "Optimization time for model  29 :  0.000164031982421875\n",
      "Optimization time for model  30 :  0.00011992454528808594\n",
      "Optimization time for model  31 :  0.0001220703125\n",
      "Optimization time for model  0 :  0.00018215179443359375\n",
      "Optimization time for model  1 :  3.2901771068573\n",
      "Optimization time for model  2 :  0.0001919269561767578\n",
      "Optimization time for model  3 :  0.0001239776611328125\n",
      "Optimization time for model  4 :  0.00012493133544921875\n",
      "Optimization time for model  5 :  0.5659329891204834\n",
      "Optimization time for model  6 :  0.00013589859008789062\n",
      "Optimization time for model  7 :  0.00017690658569335938\n",
      "Optimization time for model  8 :  0.0007250308990478516\n",
      "Optimization time for model  9 :  0.07112884521484375\n",
      "Optimization time for model  10 :  2.4789772033691406\n",
      "Optimization time for model  11 :  0.0001380443572998047\n",
      "Optimization time for model  12 :  0.00012302398681640625\n",
      "Optimization time for model  13 :  0.014943122863769531\n",
      "Optimization time for model  14 :  0.0001800060272216797\n",
      "Optimization time for model  15 :  0.00012803077697753906\n",
      "Optimization time for model  16 :  0.00016999244689941406\n",
      "Optimization time for model  17 :  0.0001671314239501953\n",
      "Optimization time for model  18 :  0.00012302398681640625\n",
      "Optimization time for model  19 :  0.00011920928955078125\n",
      "Optimization time for model  20 :  0.0001201629638671875\n",
      "Optimization time for model  21 :  0.8865818977355957\n",
      "Optimization time for model  22 :  0.0001811981201171875\n",
      "Optimization time for model  23 :  0.00012493133544921875\n",
      "Optimization time for model  24 :  0.006880044937133789\n",
      "Optimization time for model  25 :  0.00013399124145507812\n",
      "Optimization time for model  26 :  0.0001289844512939453\n",
      "Optimization time for model  27 :  0.0001518726348876953\n",
      "Optimization time for model  28 :  0.0001418590545654297\n",
      "Optimization time for model  29 :  0.00017118453979492188\n",
      "Optimization time for model  30 :  0.00016808509826660156\n",
      "Optimization time for model  31 :  0.00011801719665527344\n",
      "Optimization time for model  0 :  0.0001800060272216797\n",
      "Optimization time for model  1 :  0.0001277923583984375\n",
      "Optimization time for model  2 :  0.00012302398681640625\n",
      "Optimization time for model  3 :  0.00017213821411132812\n",
      "Optimization time for model  4 :  0.14014196395874023\n",
      "Optimization time for model  5 :  0.00012993812561035156\n",
      "Optimization time for model  6 :  0.35994410514831543\n",
      "Optimization time for model  7 :  0.025128841400146484\n",
      "Optimization time for model  8 :  0.00021505355834960938\n",
      "Optimization time for model  9 :  0.0001430511474609375\n",
      "Optimization time for model  10 :  0.0001220703125\n",
      "Optimization time for model  11 :  0.022099018096923828\n",
      "Optimization time for model  12 :  0.00013303756713867188\n",
      "Optimization time for model  13 :  0.0001819133758544922\n",
      "Optimization time for model  14 :  0.00016999244689941406\n",
      "Optimization time for model  15 :  0.0001881122589111328\n",
      "Optimization time for model  16 :  0.48902201652526855\n",
      "Optimization time for model  17 :  0.0001327991485595703\n",
      "Optimization time for model  18 :  0.00017905235290527344\n",
      "Optimization time for model  19 :  0.00013399124145507812\n",
      "Optimization time for model  20 :  0.006618022918701172\n",
      "Optimization time for model  21 :  2.557596206665039\n",
      "Optimization time for model  22 :  0.0002009868621826172\n",
      "Optimization time for model  23 :  0.00018405914306640625\n",
      "Optimization time for model  24 :  0.0001728534698486328\n",
      "Optimization time for model  25 :  0.00014495849609375\n",
      "Optimization time for model  26 :  0.0205230712890625\n",
      "Optimization time for model  27 :  0.00018596649169921875\n",
      "Optimization time for model  28 :  0.00014901161193847656\n",
      "Optimization time for model  29 :  0.00014400482177734375\n",
      "Optimization time for model  30 :  0.00017595291137695312\n",
      "Optimization time for model  31 :  0.0001862049102783203\n",
      "Optimization time for model  0 :  0.3421599864959717\n",
      "Optimization time for model  1 :  0.000186920166015625\n",
      "Optimization time for model  2 :  0.00017595291137695312\n",
      "Optimization time for model  3 :  0.0001671314239501953\n",
      "Optimization time for model  4 :  0.5110511779785156\n",
      "Optimization time for model  5 :  0.00015306472778320312\n",
      "Optimization time for model  6 :  0.00014019012451171875\n",
      "Optimization time for model  7 :  0.00017499923706054688\n",
      "Optimization time for model  8 :  0.01838397979736328\n",
      "Optimization time for model  9 :  0.00019598007202148438\n",
      "Optimization time for model  10 :  4.071478843688965\n",
      "Optimization time for model  11 :  0.0002357959747314453\n",
      "Optimization time for model  12 :  0.0002009868621826172\n",
      "Optimization time for model  13 :  0.007035017013549805\n",
      "Optimization time for model  14 :  0.41610193252563477\n",
      "Optimization time for model  15 :  1.2379651069641113\n"
     ]
    }
   ],
   "source": [
    "test_models = []\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "model_files = os.listdir(\"instances/mip/data/COR-LAT\")\n",
    "for i in range(len(test_idx)):\n",
    "    model = gb.read(\"instances/mip/data/COR-LAT/\" + model_files[test_idx[i]], env=gurobi_env)\n",
    "    test_models.append(model)\n",
    "    \n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time = []\n",
    "for i, data in enumerate(valid_loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # get slices of test_models according to batch size\n",
    "    len_test_models = len(test_models)\n",
    "\n",
    "    test_models_batch = test_models[i*batch_size: min((i+1)*batch_size, len_test_models)]\n",
    "    \n",
    "    opt_time_batch = calculate_diving_opt_time(test_models_batch, binary_indices, outputs.detach().cpu().numpy())\n",
    "    \n",
    "    opt_time.append(opt_time_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average optimization time:  0.29866028432581826\n"
     ]
    }
   ],
   "source": [
    "# flatten opt_time\n",
    "opt_time_flat = [item for sublist in opt_time for item in sublist]\n",
    "\n",
    "print(\"Average optimization time: \", np.mean(opt_time_flat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "# save neural network model\n",
    "print(\"Saving model...\")\n",
    "# statedict\n",
    "torch.save(net.state_dict(), \"Models/Tabular/neural_network_model_corlat.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91040/2751798150.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = y_test.astype(np.int)\n",
      "/tmp/ipykernel_91040/2751798150.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = y_train.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model\n",
    "y_test = y_test.astype(np.int)\n",
    "y_train = y_train.astype(np.int)\n",
    "clf = XGBClassifier(tree_method='hist')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9237003241685676\n",
      "Precision:  0.9232569302772111\n",
      "Recall:  0.9241441441441441\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score: \", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "# save xgboost model\n",
    "print(\"Saving model...\")\n",
    "pkl.dump(clf, open(\"Models/Tabular/xgboost_model_corlat.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to load the model net = NeuralNetwork()\n",
    "net.load_state_dict(torch.load(\"Models/Tabular/neural_network_model_corlat.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load xgboost model\n",
    "clf = pkl.load(open(\"Models/Tabular/xgboost_model_corlat.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_767776/551078606.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = y_test.astype(np.int)\n",
      "/tmp/ipykernel_767776/551078606.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = y_train.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test = y_test.astype(np.int)\n",
    "y_train = y_train.astype(np.int)\n",
    "y_pred = clf.predict(X_test.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9237003241685676\n",
      "Precision:  0.9232569302772111\n",
      "Recall:  0.9241441441441441\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score: \", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n"
     ]
    }
   ],
   "source": [
    "binary_indices = corlat_dataset[0][\"indices\"][\"indices\"]\n",
    "    \n",
    "n_violated_constraints = feasibility_test(len(y_pred), y_pred, test_models, binary_indices)    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of violated constraints:  3.78\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of violated constraints: \", np.mean(n_violated_constraints))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (optimization)",
   "language": "python",
   "name": "optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
