{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as tg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch.nn.functional import relu\n",
    "from torch_geometric.nn import Sequential, GCNConv, JumpingKnowledge\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    corlat_dataset = pkl.load(open(\"Data/corlat/corlat.pickle\", \"rb\"))\n",
    "except:\n",
    "    # move dir to /ibm/gpfs/home/yjin0055/Project/DayAheadForecast\n",
    "    os.chdir(\"/ibm/gpfs/home/yjin0055/Project/DayAheadForecast\")\n",
    "    corlat_dataset = pkl.load(open(\"Data/corlat/corlat.pickle\", \"rb\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 12 15:37:18 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:17:00.0 Off |                   On |\n",
      "| N/A   41C    P0    64W / 300W |   1523MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:65:00.0 Off |                   On |\n",
      "| N/A   34C    P0    43W / 300W |     26MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  On   | 00000000:CA:00.0 Off |                   On |\n",
      "| N/A   35C    P0    42W / 300W |     24MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  On   | 00000000:E3:00.0 Off |                   On |\n",
      "| N/A   36C    P0    46W / 300W |     24MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  1    3   0   0  |      9MiB / 19968MiB | 28      0 |  2   0    1    0    0 |\n",
      "|                  |      0MiB / 32767MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0    6    0    1531370      C   ...python/3.10.5/bin/python3     1495MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['solution', 'indices', 'input'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corlat_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corlat_dataset[0]['solution'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['indices'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corlat_dataset[0]['indices'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A', 'cost_vectors', 'rhs'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corlat_dataset[0]['input'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = corlat_dataset[0][\"input\"][\"A\"].shape[1]\n",
    "n_cons = corlat_dataset[0][\"input\"][\"A\"].shape[0]\n",
    "\n",
    "N_list = []\n",
    "n_vars_list = []\n",
    "n_cons_list = []\n",
    "\n",
    "for i in range(len(corlat_dataset)):\n",
    "    n_vars_list.append(corlat_dataset[i][\"input\"][\"A\"].shape[1])\n",
    "    n_cons_list.append(corlat_dataset[i][\"input\"][\"A\"].shape[0])\n",
    "    N_list.append(corlat_dataset[i][\"input\"][\"A\"].shape[1] + corlat_dataset[i][\"input\"][\"A\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = len(corlat_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_sample):\n",
    "\n",
    "    tmp_dict = {}\n",
    "\n",
    "    # for row in range(n_vars):\n",
    "    #     for col in range(n_cons):\n",
    "    #         if input_dict_list[i][\"A\"][row, col] != 0:\n",
    "    #             adj_matrix[row, n_vars + col] = input_dict_list[i][\"A\"][row, col]\n",
    "    #             adj_matrix[n_vars + col, row] = input_dict_list[i][\"A\"][row, col]\n",
    "\n",
    "    I, J, V = scipy.sparse.find(corlat_dataset[i][\"input\"][\"A\"])\n",
    "    # adj_matrix[I, n_vars + J] = V\n",
    "    # adj_matrix[n_vars + J, I] = V\n",
    "\n",
    "    # # convert to COO format\n",
    "    edge_index = torch.stack([torch.tensor(I), torch.tensor(n_cons + J)], dim=0)\n",
    "\n",
    "    # expand V to 2D\n",
    "    edge_attr = torch.tensor(V).unsqueeze(1)\n",
    "\n",
    "    tmp_dict[\"edge_index\"] = edge_index\n",
    "    tmp_dict[\"edge_attr\"] = edge_attr\n",
    "\n",
    "    input_data.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of edge_index:  torch.Size([2, 1751])\n",
      "shape of edge_attr:  torch.Size([1751, 1])\n"
     ]
    }
   ],
   "source": [
    "# print shape of edge_index and edge_attr\n",
    "print(\"shape of edge_index: \", input_data[0][\"edge_index\"].shape)\n",
    "print(\"shape of edge_attr: \", input_data[0][\"edge_attr\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3322905/3468960143.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(corlat_dataset[0][\"input\"][\"rhs\"]).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([470])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(corlat_dataset[0][\"input\"][\"rhs\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([466])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(corlat_dataset[i][\"input\"][\"cost_vectors\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corlat_dataset[1][\"input\"][\"rhs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3322905/2367782774.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(corlat_dataset[1][\"input\"][\"rhs\"]).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([470])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(corlat_dataset[1][\"input\"][\"rhs\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3322905/4166542999.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [torch.tensor(corlat_dataset[i][\"input\"][\"rhs\"]), torch.tensor(corlat_dataset[i][\"input\"][\"cost_vectors\"])]\n"
     ]
    }
   ],
   "source": [
    "# node features\n",
    "for i in range(n_sample):\n",
    "    input_data[i][\"x\"] = torch.cat(\n",
    "        [torch.tensor(corlat_dataset[i][\"input\"][\"rhs\"]), torch.tensor(corlat_dataset[i][\"input\"][\"cost_vectors\"])]\n",
    "    )\n",
    "\n",
    "    # expand dimension\n",
    "    input_data[i][\"x\"] = input_data[i][\"x\"].unsqueeze(1)    \n",
    "    \n",
    "    input_data[i][\"batch\"] = torch.tensor([i] * input_data[i][\"x\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_nodes = []\n",
    "BATCH_SIZE = 2\n",
    "variable_nodes = [\n",
    "    range(n_cons_list[i] + i * N_list[i], (i + 1) * N_list[i]) for i in range(BATCH_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(470, 936), range(1406, 1872)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable nodes are located at range(n_cons + i * N, (i + 1) * N) for i in range(BATCH_SIZE)\n",
    "\n",
    "BinaryNodes = [\n",
    "    range(n_cons_list[i] + i * N_list[i] + corlat_dataset[0][\"indices\"][\"indices\"][0], n_cons_list[i] + i * N_list[i] + corlat_dataset[0][\"indices\"][\"indices\"][0] + (corlat_dataset[0][\"indices\"][\"indices\"][-1] - corlat_dataset[0][\"indices\"][\"indices\"][0]) + 1) for i in range(BATCH_SIZE)]\n",
    "\n",
    "assert np.array_equal(n_cons + np.array(corlat_dataset[0][\"indices\"][\"indices\"]), np.array(BinaryNodes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output nodes indices array\n",
    "output_nodes = BinaryNodes  \n",
    "# flatten output_nodes\n",
    "output_nodes = np.array(output_nodes).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output keys are DayAheadBuySellStatus and DayAheadOnOffChargingStatus\n",
    "output_data_dict = []\n",
    "for i in range(n_sample):\n",
    "    BinarySolution = torch.Tensor(list(corlat_dataset[i][\"solution\"].values()))\n",
    "\n",
    "    # convert to binary\n",
    "    BinarySolution = torch.where(BinarySolution > 0.5, 1, 0)\n",
    "    \n",
    "    \n",
    "    tmp_dict = {\"y\": torch.from_numpy(np.array(BinarySolution))}\n",
    "    output_data_dict.append(tmp_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = output_data_dict[0][\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_floating_point(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(y).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(y.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a pytorch geometric dataset\n",
    "1. Graph - Pass in edge_index, edge_attr\n",
    "2. Node - Pass in the node features tensor for x\n",
    "3. Create a dataset by subclassing PyTorch Geometric's Dataset class. At a minimum you need to implement:\n",
    "\n",
    "    len - Returns the number of graphs in the dataset\n",
    "    get - Retrieves a graph object by its index\n",
    "\n",
    "4. You can also add additional functionality like transforms, downloading data, etc.\n",
    "\"\"\"\n",
    "\n",
    "class MIPDataset(tg.data.InMemoryDataset):\n",
    "    def __init__(self, root, input_data_dict, output_data_dict, transform=None, pre_transform=None):\n",
    "        self.input_data_dict = input_data_dict\n",
    "        self.output_data_dict = output_data_dict\n",
    "        super(MIPDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data.pt\"]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for i in range(n_sample):\n",
    "\n",
    "            data = tg.data.Data(\n",
    "                x= self.input_data_dict[i][\"x\"],\n",
    "                edge_index=self.input_data_dict[i][\"edge_index\"],\n",
    "                edge_attr=self.input_data_dict[i][\"edge_attr\"],\n",
    "                y=self.output_data_dict[i][\"y\"],\n",
    "                batch=self.input_data_dict[i][\"batch\"],\n",
    "            )\n",
    "            data_list.append(data)\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        \n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement a GCN model\n",
    "\n",
    "Modification to the GCN model:\n",
    "1. Extend the node embeddings for layer l + 1 by concatenating the node embeddings from layer l. Specifically, we now define the embedding for layer l + 1 to be  ̃ Z(l+1) = (Z(l+1),  ̃ Z(l)), i.e., the concatenation of the matrices row-wise, with  ̃ Z(0) = Z0\n",
    "2. Apply layer norm at the output of each layer\n",
    "3.  modification made to a Multi-Layer Perceptron (MLP) function called fθ. \n",
    "The original function was a linear mapping followed by a fixed nonlinearity in a standard Graph Convolutional Network (GCN) developed by Kipf and Welling in 2016. \n",
    "However, in this paper, the researchers have generalized fθ to be an MLP,\n",
    "\"\"\"\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, output_nodes):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = tg.nn.GCNConv(\n",
    "            in_channels, hidden_channels, cached=False, normalize=False, add_self_loops=False\n",
    "        )\n",
    "\n",
    "\n",
    "        self.conv2 = tg.nn.GCNConv(\n",
    "            hidden_channels, hidden_channels, cached=False, normalize=False, add_self_loops=False\n",
    "        )\n",
    "\n",
    "        self.conv3 = tg.nn.GCNConv(\n",
    "            2*hidden_channels, hidden_channels, cached=False, normalize=False, add_self_loops=False\n",
    "        )\n",
    "\n",
    "        self.mlp3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_channels, hidden_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \n",
    "        # concatenate the node embeddings from layer l. Specifically, we now define the embedding for layer l + 1 to be  ̃ Z(l+1) = (Z(l+1),  ̃ Z(l)), i.e., the concatenation of the matrices row-wise, with  ̃ Z(0) = Z0 (the first layer )\n",
    "\n",
    "        # use a prev_x to store the previous layer's node embeddings\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        Z_tilde_0 = x\n",
    "        relu(Z_tilde_0, inplace=True)\n",
    "        # print(\"Z_tilde_0 shape after mlp1: \", Z_tilde_0.shape)\n",
    "\n",
    "        Z_tilde = self.conv2(Z_tilde_0, edge_index, edge_attr)\n",
    "        relu(Z_tilde, inplace=True)\n",
    "        # print(\"Z_tilde shape after mlp2: \", Z_tilde.shape)\n",
    "\n",
    "        Z_tilde = torch.cat([Z_tilde, Z_tilde_0], dim=-1)\n",
    "        relu(Z_tilde, inplace=True)\n",
    "        # print(\"Z_tilde shape after cat: \", Z_tilde.shape)\n",
    "\n",
    "        Z_tilde = self.conv3(Z_tilde, edge_index, edge_attr)\n",
    "        relu(Z_tilde, inplace=True)\n",
    "\n",
    "        # print(\"Z_tilde shape after conv3: \", Z_tilde.shape)\n",
    "\n",
    "        # out = Z_tilde[self.output_nodes]\n",
    "        out = Z_tilde\n",
    "\n",
    "        # print(\"out shape: \", out.shape)\n",
    "\n",
    "        out = self.mlp3(out)[self.output_nodes]\n",
    "\n",
    "        return torch.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjin0055/.conda/envs/optimization/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# create dataloader\n",
    "data_root_dir = \"./Data/input_data_corlat/\"\n",
    "dataset = MIPDataset(root=data_root_dir, input_data_dict=input_data, output_data_dict=output_data_dict, transform=None, pre_transform=None)\n",
    "dataloader = tg.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list available cuda device\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): GCNConv(1, 64)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): GCNConv(64, 64)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): <function <lambda> at 0x1555518704c0>\n",
      "  (6): JumpingKnowledge(cat)\n",
      "  (7): <function global_mean_pool at 0x15548dcc69e0>\n",
      "  (8): Linear(in_features=128, out_features=100, bias=True)\n",
      "  (9): ReLU(inplace=True)\n",
      "  (10): Dropout(p=0.5, inplace=False)\n",
      "  (11): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (12): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "out_channels=1\n",
    "num_classes = 100\n",
    "model = GCN(in_channels=1, out_channels=out_channels, hidden_channels=8, output_nodes=output_nodes).to(device)\n",
    "\n",
    "\n",
    "model_test = Sequential('x, edge_index, edge_attr, batch', [\n",
    "    (Dropout(p=0.5), 'x -> x'),\n",
    "    (GCNConv(dataset.num_features, 64), 'x, edge_index -> x1'),\n",
    "    ReLU(inplace=True),\n",
    "    (GCNConv(64, 64), 'x1, edge_index -> x2'),\n",
    "    ReLU(inplace=True),\n",
    "    (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n",
    "    (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n",
    "    (global_mean_pool, 'x, batch -> x'),\n",
    "    Linear(2 * 64, num_classes),\n",
    "    ReLU(inplace=True),\n",
    "    Dropout(p=0.5),\n",
    "    Linear(num_classes, num_classes),\n",
    "    torch.nn.Sigmoid(),\n",
    "]).to(device)\n",
    "\n",
    "print(model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1, 8)\n",
      "  (conv2): GCNConv(8, 8)\n",
      "  (conv3): GCNConv(16, 8)\n",
      "  (mlp3): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7083542866110801\n",
      "Epoch 2, Loss: 0.7083561928272247\n",
      "Epoch 3, Loss: 0.7083542426228523\n",
      "Epoch 4, Loss: 0.7083551099896431\n",
      "Epoch 5, Loss: 0.7083535273075103\n",
      "Epoch 6, Loss: 0.7083550285100937\n",
      "Epoch 7, Loss: 0.7083536430597305\n",
      "Epoch 8, Loss: 0.7083549926280975\n",
      "Epoch 9, Loss: 0.7083534873723983\n",
      "Epoch 10, Loss: 0.7083545327186584\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "EPOCHS = 10\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ensure x is of shape (N, 1), if not, reshape, use try except\n",
    "        # ensure edge_index is of shape (2, E), if not, reshape, use try except\n",
    "        # ensure edge_attr is of shape (E, 1), if not, reshape, use try except\n",
    "\n",
    "        try:\n",
    "            assert data.x.shape[1] == 1\n",
    "\n",
    "            assert data.edge_index.shape[0] == 2\n",
    "\n",
    "            assert data.edge_attr.shape[1] == 1\n",
    "\n",
    "        except:\n",
    "            data.x = data.x.reshape(-1, 1)\n",
    "            data.edge_index = data.edge_index.reshape(2, -1)\n",
    "            data.edge_attr = data.edge_attr.reshape(-1, 1)\n",
    "\n",
    "        # convert to float\n",
    "        data.x = data.x.float().to(device)\n",
    "        data.edge_index = data.edge_index.long().to(device)\n",
    "        data.edge_attr = data.edge_attr.float().to(device)\n",
    "        data.y = data.y.float().to(device)\n",
    "        data.batch = data.batch.long().to(device)\n",
    "        \n",
    "        # print(\"device of x: \", data.x.device)\n",
    "        # print(\"device of edge_index: \", data.edge_index.device)\n",
    "        # print(\"device of edge_attr: \", data.edge_attr.device)\n",
    "        # print(\"device of y: \", data.y.device)\n",
    "        # print(\"device of batch: \", data.batch.device)\n",
    "        \n",
    "        \n",
    "\n",
    "        # print(\"Shape of x: \", data.x.shape)\n",
    "        # print(\"Shape of edge_index: \", data.edge_index.shape)\n",
    "        # print(\"Shape of edge_attr: \", data.edge_attr.shape)\n",
    "        # out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze().cpu()\n",
    "        out = model(data.x, data.edge_index, data.edge_attr).squeeze().cpu()\n",
    "\n",
    "        # require_grad = True\n",
    "        \n",
    "        loss = loss_fn(out.reshape(-1), data.y.cpu())    \n",
    "        # loss.requires_grad = True    \n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # # convert out to binary\n",
    "        # binary_out = torch.where(out > 0.5, 1, 0)\n",
    "\n",
    "        # # F1 score\n",
    "        # # type cast data.y from float of 0s and 1s to binary\n",
    "        # target_y = torch.where(data.y.cpu() > 0.5, 1, 0)\n",
    "        # f1 = f1_score(target_y, binary_out, average='macro')\n",
    "\n",
    "        # print(\"f1 score: \", f1)\n",
    "    \n",
    "    total_loss /= len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (optimization)",
   "language": "python",
   "name": "optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
