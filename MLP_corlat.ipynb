{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import os\n",
    "import gurobipy as gb\n",
    "\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch.nn.functional import relu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = (\n",
    "        False  # Force cuDNN to use a consistent convolution algorithm\n",
    "    )\n",
    "    torch.backends.cudnn.deterministic = (\n",
    "        True  # Force cuDNN to use deterministic algorithms if available\n",
    "    )\n",
    "    torch.use_deterministic_algorithms(\n",
    "        True\n",
    "    )  # Force torch to use deterministic algorithms if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'train_val_split': [0.80, 0.20], # These must sum to 1.0\n",
    "        'batch_size' : 32, # Num samples to average over for gradient updates\n",
    "        'EPOCHS' : 1000, # Num times to iterate over the entire dataset\n",
    "        'LEARNING_RATE' : 1e-3, # Learning rate for the optimizer\n",
    "        'BETA1' : 0.9, # Beta1 parameter for the Adam optimizer\n",
    "        'BETA2' : 0.999, # Beta2 parameter for the Adam optimizer\n",
    "        'WEIGHT_DECAY' : 1e-4, # Weight decay parameter for the Adam optimizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    corlat_dataset = pkl.load(open(\"Data/corlat/corlat_preprocessed_v1.pickle\", \"rb\"))\n",
    "except:\n",
    "    # move dir to /ibm/gpfs/home/yjin0055/Project/DayAheadForecast\n",
    "    os.chdir(\"/ibm/gpfs/home/yjin0055/Project/DayAheadForecast\")\n",
    "    corlat_dataset = pkl.load(open(\"Data/corlat/corlat_preprocessed_v1.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_obj_coef</th>\n",
       "      <th>num_nonzero_coef</th>\n",
       "      <th>lp_relax_val</th>\n",
       "      <th>is_lp_relax_val_frac</th>\n",
       "      <th>lp_sol_val_eq_lb</th>\n",
       "      <th>lp_sol_val_eq_ub</th>\n",
       "      <th>has_lb</th>\n",
       "      <th>has_ub</th>\n",
       "      <th>mean_degree</th>\n",
       "      <th>std_degree</th>\n",
       "      <th>min_degree</th>\n",
       "      <th>max_degree</th>\n",
       "      <th>mean_coef</th>\n",
       "      <th>std_coef</th>\n",
       "      <th>min_coef</th>\n",
       "      <th>max_coef</th>\n",
       "      <th>var_type_B</th>\n",
       "      <th>var_type_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>36.706039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-50.166667</td>\n",
       "      <td>49.837792</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>45.415367</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-48.833333</td>\n",
       "      <td>51.275129</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.442327</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>45.415367</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-50.166667</td>\n",
       "      <td>49.837792</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>45.415367</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-48.833333</td>\n",
       "      <td>51.275129</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>45.415367</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-48.833333</td>\n",
       "      <td>51.275129</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_obj_coef  num_nonzero_coef  lp_relax_val  is_lp_relax_val_frac  \\\n",
       "0           5.0               6.0      1.000000                  True   \n",
       "1           4.0               6.0      0.000000                  True   \n",
       "2           6.0               6.0      0.442327                  True   \n",
       "3           5.0               6.0     -0.000000                  True   \n",
       "4           3.0               6.0     -0.000000                  True   \n",
       "\n",
       "   lp_sol_val_eq_lb  lp_sol_val_eq_ub  has_lb  has_ub  mean_degree  \\\n",
       "0              True              True    True    True    19.000000   \n",
       "1              True              True    True    True    35.333333   \n",
       "2              True              True    True    True    35.333333   \n",
       "3              True              True    True    True    35.333333   \n",
       "4              True              True    True    True    35.333333   \n",
       "\n",
       "   std_degree  min_degree  max_degree  mean_coef   std_coef  min_coef  \\\n",
       "0   36.706039         1.0       101.0 -50.166667  49.837792    -100.0   \n",
       "1   45.415367         2.0       101.0 -48.833333  51.275129    -100.0   \n",
       "2   45.415367         2.0       101.0 -50.166667  49.837792    -100.0   \n",
       "3   45.415367         2.0       101.0 -48.833333  51.275129    -100.0   \n",
       "4   45.415367         2.0       101.0 -48.833333  51.275129    -100.0   \n",
       "\n",
       "   max_coef  var_type_B  var_type_C  \n",
       "0       1.0           1           0  \n",
       "1       9.0           1           0  \n",
       "2       1.0           1           0  \n",
       "3       9.0           1           0  \n",
       "4       9.0           1           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corlat_dataset[0][\"input\"][\"var_node_features\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the maximum size of N_constraints and N_variables across the dataset.\n",
    "\n",
    "max_N_constraints = max(\n",
    "    len(x[\"input\"][\"constraint_node_features\"]) for x in corlat_dataset\n",
    ")\n",
    "\n",
    "max_N_variables = max(\n",
    "    len(x[\"input\"][\"var_node_features\"]) for x in corlat_dataset\n",
    ")\n",
    "\n",
    "min_N_constraints = min(\n",
    "    len(x[\"input\"][\"constraint_node_features\"]) for x in corlat_dataset\n",
    ")\n",
    "\n",
    "min_N_variables = min(\n",
    "    len(x[\"input\"][\"var_node_features\"]) for x in corlat_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of variables:  466\n",
      "Maximum number of constraints:  551\n",
      "Minimum number of variables:  466\n",
      "Minimum number of constraints:  470\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum number of variables: \", max_N_variables)\n",
    "print(\"Maximum number of constraints: \", max_N_constraints)\n",
    "print(\"Minimum number of variables: \", min_N_variables)\n",
    "print(\"Minimum number of constraints: \", min_N_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variable node features:  18\n",
      "Number of constraint node features:  10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of variable node features: \", len(corlat_dataset[0][\"input\"][\"var_node_features\"].columns))\n",
    "print(\"Number of constraint node features: \", len(corlat_dataset[0][\"input\"][\"constraint_node_features\"].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each variable node features, pad with 0.0s to make it the same length as the maximum number of variables\n",
    "\n",
    "var_node_features = np.stack(\n",
    "    [\n",
    "        np.pad(\n",
    "            x[\"input\"][\"var_node_features\"].values,\n",
    "            ((0, max_N_variables - len(x[\"input\"][\"var_node_features\"])), (0, 0)),\n",
    "            \"constant\",\n",
    "            constant_values=0.0,\n",
    "        )\n",
    "        for x in corlat_dataset\n",
    "    ]\n",
    ")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 466, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_node_features = np.stack(\n",
    "    [\n",
    "        np.pad(\n",
    "            x[\"input\"][\"constraint_node_features\"].values,\n",
    "            ((0, max_N_constraints - len(x[\"input\"][\"constraint_node_features\"])), (0, 0)),\n",
    "            \"constant\",\n",
    "            constant_values=0.0,\n",
    "        )\n",
    "        for x in corlat_dataset\n",
    "    ]   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 551, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint_node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for var_node_features and constraint_node_features, reshape to (N_samples, -1) to feed into the neural network\n",
    "var_input = var_node_features.reshape(var_node_features.shape[0], -1)\n",
    "constraint_input = constraint_node_features.reshape(constraint_node_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of variable features input:  (2000, 8388)\n",
      "Shape of constraint features input:  (2000, 5510)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of variable features input: \", var_input.shape)\n",
    "print(\"Shape of constraint features input: \", constraint_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get A matrix input by stacking the csr_matrix of each sample getting shape of N_samples x (A.shape[0] x A.shape[1])\n",
    "A_input = np.vstack([x[\"input\"][\"A\"] for x in corlat_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_feature_list = []\n",
    "for i in range(len(corlat_dataset)):\n",
    "    n_cons = corlat_dataset[i][\"input\"][\"A\"].shape[0]\n",
    "\n",
    "    # for row in range(n_vars):\n",
    "    #     for col in range(n_cons):\n",
    "    #         if input_dict_list[i][\"A\"][row, col] != 0:\n",
    "    #             adj_matrix[row, n_vars + col] = input_dict_list[i][\"A\"][row, col]\n",
    "    #             adj_matrix[n_vars + col, row] = input_dict_list[i][\"A\"][row, col]\n",
    "\n",
    "    I, J, V = scipy.sparse.find(corlat_dataset[i][\"input\"][\"A\"])\n",
    "    # adj_matrix[I, n_vars + J] = V\n",
    "    # adj_matrix[n_vars + J, I] = V\n",
    "\n",
    "    # # convert to COO format\n",
    "    edge_index = torch.stack([torch.tensor(I), torch.tensor(n_cons + J)], dim=0)\n",
    "\n",
    "    # expand V to 2D\n",
    "    edge_attr = torch.tensor(V).unsqueeze(1)\n",
    "\n",
    "    tmp_dict = {\"edge_index\": edge_index, \"edge_attr\": edge_attr}\n",
    "    A_feature_list.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sample, pad the edge_index and edge_attr to make it the same length as the maximum length of edge_index and edge_attr\n",
    "max_edge_index_len = max([len(x[\"edge_index\"][0]) for x in A_feature_list])\n",
    "max_edge_attr_len = max([len(x[\"edge_attr\"]) for x in A_feature_list])\n",
    "\n",
    "for i in range(len(A_feature_list)):\n",
    "    edge_index = A_feature_list[i][\"edge_index\"]\n",
    "    edge_attr = A_feature_list[i][\"edge_attr\"]\n",
    "\n",
    "    # pad edge_index\n",
    "    edge_index = torch.cat(\n",
    "        [\n",
    "            edge_index,\n",
    "            torch.zeros(\n",
    "                2, max_edge_index_len - len(edge_index[0]), dtype=torch.long\n",
    "            ),\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "    # pad edge_attr\n",
    "    edge_attr = torch.cat(\n",
    "        [\n",
    "            edge_attr,\n",
    "            torch.zeros(\n",
    "                max_edge_attr_len - len(edge_attr), 1, dtype=torch.float32\n",
    "            ),\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "\n",
    "    A_feature_list[i][\"edge_index\"] = edge_index\n",
    "    A_feature_list[i][\"edge_attr\"] = edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the padding is correct by checking the shape of edge_index and edge_attr\n",
    "for i in range(len(A_feature_list)):\n",
    "    assert A_feature_list[i][\"edge_index\"].shape == (2, max_edge_index_len)\n",
    "    assert A_feature_list[i][\"edge_attr\"].shape == (max_edge_attr_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of A matrix input:  (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of A matrix input: \", A_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['solution', 'indices', 'input'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corlat_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each solution convert the dictionary to a list of values\n",
    "solutions = [\n",
    "    list(corlat_dataset[i][\"solution\"].values())\n",
    "    for i in range(len(corlat_dataset))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert solutions_list to numpy array\n",
    "solutions = np.array(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the variable features and constraint features into a single input\n",
    "X = np.hstack([var_input, constraint_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "out_channels = solutions.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 13898)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_features//4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(n_features//4, n_features//2)\n",
    "        self.fc3 = nn.Linear(n_features//2, n_features//2)\n",
    "        self.fc4 = nn.Linear(n_features//2, out_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # add regularization\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check type for one sample of solutions\n",
    "solutions[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X and solutions to float32\n",
    "X = X.astype(np.float32)\n",
    "solutions = solutions.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all samples have same dimension\n",
    "for i in range(len(solutions)):\n",
    "    assert solutions[i].shape == (100,)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    assert X[i].shape == (13898,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split to get indices for train and test\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(solutions)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_train = solutions[train_idx]\n",
    "y_test = solutions[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, solutions, test_size=0.2, random_state=42, shuffle=True)\n",
    "# save the train and test data in the directory Data/corlat/\n",
    "np.save(\"Data/corlat/X_train_v1.npy\", X_train)\n",
    "np.save(\"Data/corlat/X_test_v1.npy\", X_test)\n",
    "np.save(\"Data/corlat/y_train_v1.npy\", y_train)\n",
    "np.save(\"Data/corlat/y_test_v1.npy\", y_test)\n",
    "np.save(\"Data/corlat/train_idx_v1.npy\", train_idx)\n",
    "np.save(\"Data/corlat/test_idx_v1.npy\", test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()\n",
    "# net = torch.compile(net)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "# create the dataloader for X and solutions\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_train), torch.tensor(y_train)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_test), torch.tensor(y_test)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "params = list(net.parameters())\n",
    "\n",
    "# optimizer = AdamW(params, lr=config['LEARNING_RATE'], weight_decay=1e-4)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "# optimizer = dadaptation.DAdaptAdam(params, lr=1, log_every=5, betas=(BETA1, BETA2), weight_decay=1e-4, decouple=True)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "total_steps = len(train_loader)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config['LEARNING_RATE'], steps_per_epoch=total_steps, epochs=config['EPOCHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (fc1): Linear(in_features=13898, out_features=3474, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=3474, out_features=6949, bias=True)\n",
       "  (fc3): Linear(in_features=6949, out_features=6949, bias=True)\n",
       "  (fc4): Linear(in_features=6949, out_features=100, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.804 lr: 0.000040\n",
      "Epoch 2 loss: 0.702 lr: 0.000040\n",
      "Epoch 3 loss: 0.668 lr: 0.000040\n",
      "Epoch 4 loss: 0.648 lr: 0.000040\n",
      "Epoch 5 loss: 0.633 lr: 0.000040\n",
      "Epoch 6 loss: 0.623 lr: 0.000041\n",
      "Epoch 7 loss: 0.614 lr: 0.000041\n",
      "Epoch 8 loss: 0.605 lr: 0.000041\n",
      "Epoch 9 loss: 0.598 lr: 0.000042\n",
      "Epoch 10 loss: 0.591 lr: 0.000042\n",
      "Epoch 11 loss: 0.586 lr: 0.000043\n",
      "Epoch 12 loss: 0.580 lr: 0.000043\n",
      "Epoch 13 loss: 0.575 lr: 0.000044\n",
      "Epoch 14 loss: 0.570 lr: 0.000044\n",
      "Epoch 15 loss: 0.565 lr: 0.000045\n",
      "Epoch 16 loss: 0.562 lr: 0.000046\n",
      "Epoch 17 loss: 0.557 lr: 0.000047\n",
      "Epoch 18 loss: 0.554 lr: 0.000048\n",
      "Epoch 19 loss: 0.550 lr: 0.000049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      3\u001b[0m curr_lr \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, \u001b[39m0\u001b[39m):\n\u001b[1;32m      5\u001b[0m     inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m      6\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/optimization/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/optimization/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/optimization/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.conda/envs/optimization/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    204\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/.conda/envs/optimization/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/optimization/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/optimization/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.conda/envs/optimization/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(config[\"EPOCHS\"]):\n",
    "    running_loss = 0.0\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f lr: %.6f' % (epoch + 1, running_loss / len(train_loader), curr_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if X_test is numpy array convert to tensor\n",
    "if isinstance(X_test, np.ndarray):\n",
    "    X_test = torch.tensor(X_test)\n",
    "    \n",
    "# if net device is cpu convert X_test to cpu, else convert to cuda\n",
    "if next(net.parameters()).device == torch.device(\"cpu\"):\n",
    "    X_test = X_test.cpu()\n",
    "else:\n",
    "    X_test = X_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7200379266750949\n",
      "Precision:  0.7599066044029353\n",
      "Recall:  0.6841441441441442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_767776/837471902.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = net(torch.tensor(X_test))\n",
      "/tmp/ipykernel_767776/837471902.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = y_test.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# validation of the model using f1 score, precision and recall\n",
    "y_pred = net(torch.tensor(X_test))\n",
    "y_pred = y_pred.cpu().detach().numpy()\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "y_test = y_test.astype(np.int)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average=\"micro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feasibility_test(batch_size, y_pred, test_models, indices):\n",
    "    \n",
    "    n_violated_constraints = []\n",
    "\n",
    "    # convert predictions of N_samples, N_variables to binary\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "    \n",
    "    # Compute the weights for each training instance\n",
    "    for i in range(len(test_models)):\n",
    "        \n",
    "        model = test_models[i]\n",
    "        \n",
    "        modelVars = model.getVars()\n",
    "        \n",
    "        instanceBinaryIndices = indices\n",
    "\n",
    "        # need to relax the binary variables to continuous variables with bounds of 0 and 1, we can use the setAttr method to change their vtype attribute\n",
    "        for j in range(len(instanceBinaryIndices)):\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"C\")\n",
    "\n",
    "            # for each index in firstInstanceTestBinaryIndices, set the value of the corresponding variable to the value predicted by xgboost\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "        \n",
    "        \n",
    "        # Compute the IIS to find the list of violated constraints and variables\n",
    "        try:\n",
    "            model.computeIIS()\n",
    "        except gb.GurobiError:\n",
    "            print(\"Model is feasible\")\n",
    "            n_violated_constraints.append(0)\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # get number of violated constraints\n",
    "        IISConstr = model.getAttr(\"IISConstr\", model.getConstrs())\n",
    "\n",
    "        # count number of non zero elements in IISConstr        \n",
    "        n_violated_constraints.append(np.count_nonzero(IISConstr))\n",
    "        \n",
    "    return n_violated_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-01\n"
     ]
    }
   ],
   "source": [
    "test_models = []\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "model_files = os.listdir(\"instances/mip/data/COR-LAT\")\n",
    "for i in range(len(test_idx)):\n",
    "    model = gb.read(\"instances/mip/data/COR-LAT/\" + model_files[test_idx[i]], env=gurobi_env)\n",
    "    test_models.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n"
     ]
    }
   ],
   "source": [
    "n_violated_constraints = []\n",
    "binary_indices = corlat_dataset[0][\"indices\"][\"indices\"]\n",
    "for i, data in enumerate(valid_loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # get slices of test_models according to batch size\n",
    "    len_test_models = len(test_models)\n",
    "    test_models_batch = test_models[i*batch_size: min((i+1)*batch_size, len_test_models)]\n",
    "    \n",
    "    n_violated_constraints_batch = feasibility_test(batch_size, outputs.detach().cpu().numpy(), test_models_batch, binary_indices)\n",
    "    \n",
    "    n_violated_constraints.append(n_violated_constraints_batch)\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of violated constraints:  3.085\n"
     ]
    }
   ],
   "source": [
    "# count average number of violated constraints by flattening the list\n",
    "n_violated_constraints = [item for sublist in n_violated_constraints for item in sublist]\n",
    "print(\"Average number of violated constraints: \", np.mean(n_violated_constraints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of n_violated_constraints:  400\n",
      "[1, 1, 36, 17, 1, 1, 1, 1, 1, 1, 2, 1, 8, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 20, 1, 1, 1, 2, 1, 1, 1, 1, 1, 17, 1, 1, 0, 1, 28, 1, 1, 2, 1, 1, 1, 1, 1, 12, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 50, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 1, 19, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 13, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 22, 1, 1, 2, 1, 1, 1, 2, 1, 30, 1, 2, 26, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 42, 1, 8, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 56, 1, 1, 2, 1, 1, 1, 51, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 24, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 5, 30, 27, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 12, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 73, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 68, 2, 1, 1, 25, 2, 1, 1, 1, 1, 24, 1, 1, 1, 1, 1, 1, 22, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of n_violated_constraints: \", len(n_violated_constraints))\n",
    "print(n_violated_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diving_opt_time(models, binary_indices, y_pred):\n",
    "    \n",
    "    opt_time = []\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        \n",
    "        modelVars = model.getVars()\n",
    "        \n",
    "        instanceBinaryIndices = binary_indices\n",
    "        \n",
    "        y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "        \n",
    "        # need to relax the binary variables to continuous variables with bounds of 0 and 1, we can use the setAttr method to change their vtype attribute\n",
    "        for j in range(len(instanceBinaryIndices)):\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"C\")\n",
    "\n",
    "            # for each index in firstInstanceTestBinaryIndices, set the value of the corresponding variable to the value predicted by xgboost\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "            modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "        \n",
    "        \n",
    "        # Compute the IIS to find the list of violated constraints and variables\n",
    "        try:\n",
    "            model.computeIIS()\n",
    "            infeasible_flag = True\n",
    "        except gb.GurobiError:\n",
    "            print(\"Model is feasible\")\n",
    "            infeasible_flag = False\n",
    "            continue\n",
    "        \n",
    "        if infeasible_flag:\n",
    "            for j in range(len(instanceBinaryIndices)):\n",
    "                if modelVars[instanceBinaryIndices[j]].IISLB == 0 and modelVars[instanceBinaryIndices[j]].IISUB == 0:\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                    # for each index in binary_indices, set the value of the corresponding variable to the value predicted by model\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])                     \n",
    "                    \n",
    "                    # else if the variable is in the IIS, \n",
    "                    # get the relaxed variable and \n",
    "                    # set the bounds to 0 and 1 for the relaxed binary variables\n",
    "                else:\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", 0)\n",
    "                    modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", 1)\n",
    "        \n",
    "        else:\n",
    "            for j in range(len(instanceBinaryIndices)):\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"VType\", \"B\")\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"LB\", y_pred_binary[i, j])\n",
    "                modelVars[instanceBinaryIndices[j]].setAttr(\"UB\", y_pred_binary[i, j])\n",
    "        \n",
    "        model.Params.Threads = 1\n",
    "        model.optimize()\n",
    "        print(\"Optimization time for model \", i, \": \", model.Runtime)\n",
    "        opt_time.append(model.Runtime)\n",
    "        \n",
    "    return opt_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-01\n",
      "Optimization time for model  0 :  0.0003139972686767578\n",
      "Optimization time for model  1 :  0.0001800060272216797\n",
      "Optimization time for model  2 :  0.0001919269561767578\n",
      "Optimization time for model  3 :  0.0018579959869384766\n",
      "Optimization time for model  4 :  0.00015401840209960938\n",
      "Optimization time for model  5 :  0.49094700813293457\n",
      "Optimization time for model  6 :  0.00018715858459472656\n",
      "Optimization time for model  7 :  0.0001430511474609375\n",
      "Optimization time for model  8 :  0.00014495849609375\n",
      "Optimization time for model  9 :  0.00017690658569335938\n",
      "Optimization time for model  10 :  0.00014209747314453125\n",
      "Optimization time for model  11 :  0.00011897087097167969\n",
      "Optimization time for model  12 :  0.00017213821411132812\n",
      "Optimization time for model  13 :  0.0001380443572998047\n",
      "Optimization time for model  14 :  0.144395112991333\n",
      "Optimization time for model  15 :  0.3048369884490967\n",
      "Optimization time for model  16 :  0.0001990795135498047\n",
      "Optimization time for model  17 :  0.0001659393310546875\n",
      "Optimization time for model  18 :  0.00014495849609375\n",
      "Optimization time for model  19 :  0.3672611713409424\n",
      "Optimization time for model  20 :  0.00015878677368164062\n",
      "Optimization time for model  21 :  0.0001480579376220703\n",
      "Optimization time for model  22 :  1.943911075592041\n",
      "Optimization time for model  23 :  0.0002009868621826172\n",
      "Optimization time for model  24 :  0.0001780986785888672\n",
      "Optimization time for model  25 :  0.00021719932556152344\n",
      "Optimization time for model  26 :  0.00011801719665527344\n",
      "Optimization time for model  27 :  0.008033990859985352\n",
      "Optimization time for model  28 :  0.0001308917999267578\n",
      "Optimization time for model  29 :  0.0001480579376220703\n",
      "Optimization time for model  30 :  0.00012111663818359375\n",
      "Optimization time for model  31 :  0.00017595291137695312\n",
      "Optimization time for model  0 :  0.0001327991485595703\n",
      "Optimization time for model  1 :  0.00015282630920410156\n",
      "Optimization time for model  2 :  0.000186920166015625\n",
      "Optimization time for model  3 :  6.541991949081421\n",
      "Optimization time for model  4 :  0.00015020370483398438\n",
      "Optimization time for model  5 :  0.0001938343048095703\n",
      "Optimization time for model  6 :  0.00017905235290527344\n",
      "Optimization time for model  7 :  1.8188607692718506\n",
      "Optimization time for model  8 :  0.0037670135498046875\n",
      "Optimization time for model  9 :  0.00015282630920410156\n",
      "Optimization time for model  10 :  0.0001380443572998047\n",
      "Optimization time for model  11 :  0.0001399517059326172\n",
      "Optimization time for model  12 :  2.3798959255218506\n",
      "Optimization time for model  13 :  0.00025916099548339844\n",
      "Optimization time for model  14 :  0.00016689300537109375\n",
      "Optimization time for model  15 :  0.00014901161193847656\n",
      "Optimization time for model  16 :  0.00014519691467285156\n",
      "Optimization time for model  17 :  1.0812759399414062\n",
      "Optimization time for model  18 :  0.00020599365234375\n",
      "Optimization time for model  19 :  0.1362149715423584\n",
      "Optimization time for model  20 :  0.0002040863037109375\n",
      "Optimization time for model  21 :  0.00015616416931152344\n",
      "Optimization time for model  22 :  0.0001780986785888672\n",
      "Optimization time for model  23 :  0.00017118453979492188\n",
      "Optimization time for model  24 :  0.0001220703125\n",
      "Optimization time for model  25 :  0.0001468658447265625\n",
      "Optimization time for model  26 :  0.0001289844512939453\n",
      "Optimization time for model  27 :  0.00012993812561035156\n",
      "Optimization time for model  28 :  0.00017714500427246094\n",
      "Optimization time for model  29 :  0.00014400482177734375\n",
      "Optimization time for model  30 :  0.00019407272338867188\n",
      "Optimization time for model  31 :  0.0001590251922607422\n",
      "Optimization time for model  0 :  0.00013399124145507812\n",
      "Optimization time for model  1 :  0.0001900196075439453\n",
      "Optimization time for model  2 :  0.00017905235290527344\n",
      "Optimization time for model  3 :  0.00017786026000976562\n",
      "Optimization time for model  4 :  0.0004200935363769531\n",
      "Optimization time for model  5 :  0.0001850128173828125\n",
      "Optimization time for model  6 :  0.00017786026000976562\n",
      "Optimization time for model  7 :  0.00015211105346679688\n",
      "Optimization time for model  8 :  2.5845959186553955\n",
      "Optimization time for model  9 :  0.00021004676818847656\n",
      "Optimization time for model  10 :  0.00013899803161621094\n",
      "Optimization time for model  11 :  0.00015497207641601562\n",
      "Optimization time for model  12 :  0.00017404556274414062\n",
      "Optimization time for model  13 :  2.239474058151245\n",
      "Optimization time for model  14 :  0.0002071857452392578\n",
      "Optimization time for model  15 :  0.00015306472778320312\n",
      "Optimization time for model  16 :  0.00013899803161621094\n",
      "Optimization time for model  17 :  0.00014090538024902344\n",
      "Optimization time for model  18 :  0.7420029640197754\n",
      "Optimization time for model  19 :  0.0001609325408935547\n",
      "Optimization time for model  20 :  0.0001728534698486328\n",
      "Optimization time for model  21 :  0.00015807151794433594\n",
      "Optimization time for model  22 :  0.26131510734558105\n",
      "Optimization time for model  23 :  2.43320894241333\n",
      "Optimization time for model  24 :  0.0002079010009765625\n",
      "Optimization time for model  25 :  1.8483080863952637\n",
      "Optimization time for model  26 :  0.00017905235290527344\n",
      "Optimization time for model  27 :  0.00015401840209960938\n",
      "Optimization time for model  28 :  0.00019097328186035156\n",
      "Optimization time for model  29 :  0.00015282630920410156\n",
      "Optimization time for model  30 :  1.6951789855957031\n",
      "Optimization time for model  31 :  0.0002090930938720703\n",
      "Optimization time for model  0 :  0.00015401840209960938\n",
      "Optimization time for model  1 :  4.526065826416016\n",
      "Optimization time for model  2 :  0.00020813941955566406\n",
      "Optimization time for model  3 :  2.634657859802246\n",
      "Optimization time for model  4 :  0.0001780986785888672\n",
      "Optimization time for model  5 :  1.770819902420044\n",
      "Optimization time for model  6 :  0.22507500648498535\n",
      "Optimization time for model  7 :  0.0001609325408935547\n",
      "Optimization time for model  8 :  0.00014400482177734375\n",
      "Optimization time for model  9 :  0.0001671314239501953\n",
      "Optimization time for model  10 :  0.0001919269561767578\n",
      "Optimization time for model  11 :  0.0001289844512939453\n",
      "Optimization time for model  12 :  0.0004031658172607422\n",
      "Optimization time for model  13 :  0.0001690387725830078\n",
      "Optimization time for model  14 :  0.00014710426330566406\n",
      "Optimization time for model  15 :  0.00012683868408203125\n",
      "Optimization time for model  16 :  0.00011897087097167969\n",
      "Optimization time for model  17 :  0.00016689300537109375\n",
      "Optimization time for model  18 :  0.00011897087097167969\n",
      "Optimization time for model  19 :  0.00011992454528808594\n",
      "Optimization time for model  20 :  0.00011706352233886719\n",
      "Optimization time for model  21 :  0.000141143798828125\n",
      "Optimization time for model  22 :  0.0001659393310546875\n",
      "Optimization time for model  23 :  0.0001380443572998047\n",
      "Optimization time for model  24 :  0.0001251697540283203\n",
      "Optimization time for model  25 :  0.000164031982421875\n",
      "Optimization time for model  26 :  0.0001220703125\n",
      "Optimization time for model  27 :  0.00012493133544921875\n",
      "Optimization time for model  28 :  0.0001430511474609375\n",
      "Optimization time for model  29 :  0.00012111663818359375\n",
      "Optimization time for model  30 :  0.00014281272888183594\n",
      "Optimization time for model  31 :  2.560688018798828\n",
      "Optimization time for model  0 :  0.00015807151794433594\n",
      "Optimization time for model  1 :  0.00014901161193847656\n",
      "Optimization time for model  2 :  5.564981937408447\n",
      "Optimization time for model  3 :  0.019583940505981445\n",
      "Optimization time for model  4 :  4.807080984115601\n",
      "Optimization time for model  5 :  0.00015997886657714844\n",
      "Optimization time for model  6 :  0.00020194053649902344\n",
      "Optimization time for model  7 :  0.00013899803161621094\n",
      "Optimization time for model  8 :  0.00019097328186035156\n",
      "Optimization time for model  9 :  0.0001862049102783203\n",
      "Optimization time for model  10 :  12.28572392463684\n",
      "Optimization time for model  11 :  0.0001628398895263672\n",
      "Optimization time for model  12 :  0.0001430511474609375\n",
      "Optimization time for model  13 :  0.00012993812561035156\n",
      "Optimization time for model  14 :  0.000125885009765625\n",
      "Optimization time for model  15 :  0.00011801719665527344\n",
      "Optimization time for model  16 :  0.00017189979553222656\n",
      "Optimization time for model  17 :  0.00012803077697753906\n",
      "Optimization time for model  18 :  0.0001609325408935547\n",
      "Optimization time for model  19 :  0.00017595291137695312\n",
      "Optimization time for model  20 :  0.00018978118896484375\n",
      "Optimization time for model  21 :  0.0001780986785888672\n",
      "Optimization time for model  22 :  0.00014090538024902344\n",
      "Optimization time for model  23 :  0.00012302398681640625\n",
      "Optimization time for model  24 :  0.00016617774963378906\n",
      "Model is feasible\n",
      "Optimization time for model  26 :  0.00013399124145507812\n",
      "Optimization time for model  27 :  0.0001308917999267578\n",
      "Model is feasible\n",
      "Optimization time for model  29 :  0.3261430263519287\n",
      "Optimization time for model  30 :  1.7921149730682373\n",
      "Optimization time for model  31 :  0.00013589859008789062\n",
      "Optimization time for model  0 :  0.7560892105102539\n",
      "Optimization time for model  1 :  0.0002090930938720703\n",
      "Optimization time for model  2 :  1.671525001525879\n",
      "Optimization time for model  3 :  0.0002028942108154297\n",
      "Optimization time for model  4 :  0.0001900196075439453\n",
      "Optimization time for model  5 :  0.00015783309936523438\n",
      "Optimization time for model  6 :  0.00012683868408203125\n",
      "Optimization time for model  7 :  0.00012612342834472656\n",
      "Optimization time for model  8 :  0.00015306472778320312\n",
      "Optimization time for model  9 :  0.00012183189392089844\n",
      "Optimization time for model  10 :  0.00015115737915039062\n",
      "Optimization time for model  11 :  0.0001709461212158203\n",
      "Optimization time for model  12 :  0.00011992454528808594\n",
      "Optimization time for model  13 :  0.00014495849609375\n",
      "Optimization time for model  14 :  0.0001709461212158203\n",
      "Optimization time for model  15 :  0.0001671314239501953\n",
      "Optimization time for model  16 :  1.2522480487823486\n",
      "Optimization time for model  17 :  0.00020003318786621094\n",
      "Optimization time for model  18 :  0.009544849395751953\n",
      "Optimization time for model  19 :  0.00015401840209960938\n",
      "Optimization time for model  20 :  2.538400888442993\n",
      "Optimization time for model  21 :  0.00015401840209960938\n",
      "Optimization time for model  22 :  0.00018715858459472656\n",
      "Optimization time for model  23 :  0.0001780986785888672\n",
      "Optimization time for model  24 :  0.00017189979553222656\n",
      "Optimization time for model  25 :  0.00012612342834472656\n",
      "Optimization time for model  26 :  0.00017189979553222656\n",
      "Optimization time for model  27 :  0.0001881122589111328\n",
      "Optimization time for model  28 :  0.0001800060272216797\n",
      "Optimization time for model  29 :  0.0001728534698486328\n",
      "Optimization time for model  30 :  0.0001220703125\n",
      "Optimization time for model  31 :  0.00013685226440429688\n",
      "Optimization time for model  0 :  0.00017690658569335938\n",
      "Optimization time for model  1 :  0.00017404556274414062\n",
      "Optimization time for model  2 :  0.0599980354309082\n",
      "Optimization time for model  3 :  0.00012993812561035156\n",
      "Optimization time for model  4 :  0.00012803077697753906\n",
      "Optimization time for model  5 :  0.0001461505889892578\n",
      "Optimization time for model  6 :  0.00024199485778808594\n",
      "Optimization time for model  7 :  0.0001537799835205078\n",
      "Optimization time for model  8 :  0.00015306472778320312\n",
      "Optimization time for model  9 :  0.0001590251922607422\n",
      "Optimization time for model  10 :  0.00013709068298339844\n",
      "Optimization time for model  11 :  0.0001480579376220703\n",
      "Optimization time for model  12 :  0.00018095970153808594\n",
      "Optimization time for model  13 :  0.00012993812561035156\n",
      "Optimization time for model  14 :  0.0001201629638671875\n",
      "Optimization time for model  15 :  2.274129867553711\n",
      "Optimization time for model  16 :  0.5511901378631592\n",
      "Optimization time for model  17 :  0.0002090930938720703\n",
      "Optimization time for model  18 :  0.0001552104949951172\n",
      "Optimization time for model  19 :  0.00015020370483398438\n",
      "Optimization time for model  20 :  0.00018310546875\n",
      "Optimization time for model  21 :  0.0001461505889892578\n",
      "Optimization time for model  22 :  0.00017213821411132812\n",
      "Optimization time for model  23 :  0.010849952697753906\n",
      "Optimization time for model  24 :  0.0003960132598876953\n",
      "Optimization time for model  25 :  0.00017499923706054688\n",
      "Optimization time for model  26 :  0.00019097328186035156\n",
      "Optimization time for model  27 :  0.00014495849609375\n",
      "Optimization time for model  28 :  0.0001430511474609375\n",
      "Optimization time for model  29 :  0.00013709068298339844\n",
      "Optimization time for model  30 :  0.0001819133758544922\n",
      "Optimization time for model  31 :  0.0001239776611328125\n",
      "Optimization time for model  0 :  0.00018405914306640625\n",
      "Optimization time for model  1 :  0.0001709461212158203\n",
      "Optimization time for model  2 :  0.00017714500427246094\n",
      "Optimization time for model  3 :  0.00012683868408203125\n",
      "Optimization time for model  4 :  0.0001518726348876953\n",
      "Optimization time for model  5 :  1.6234161853790283\n",
      "Optimization time for model  6 :  0.0013668537139892578\n",
      "Optimization time for model  7 :  0.0001919269561767578\n",
      "Optimization time for model  8 :  0.0001800060272216797\n",
      "Optimization time for model  9 :  0.00042891502380371094\n",
      "Optimization time for model  10 :  0.1782209873199463\n",
      "Optimization time for model  11 :  0.00015211105346679688\n",
      "Optimization time for model  12 :  0.0001900196075439453\n",
      "Optimization time for model  13 :  4.063139915466309\n",
      "Optimization time for model  14 :  0.00015211105346679688\n",
      "Optimization time for model  15 :  0.0001900196075439453\n",
      "Optimization time for model  16 :  0.00015592575073242188\n",
      "Optimization time for model  17 :  2.947299003601074\n",
      "Optimization time for model  18 :  0.00015401840209960938\n",
      "Optimization time for model  19 :  0.00019097328186035156\n",
      "Optimization time for model  20 :  0.0001289844512939453\n",
      "Model is feasible\n",
      "Optimization time for model  22 :  0.00015401840209960938\n",
      "Optimization time for model  23 :  0.0001499652862548828\n",
      "Optimization time for model  24 :  0.00017404556274414062\n",
      "Optimization time for model  25 :  0.08199095726013184\n",
      "Optimization time for model  26 :  0.10550498962402344\n",
      "Optimization time for model  27 :  0.000141143798828125\n",
      "Optimization time for model  28 :  0.00015497207641601562\n",
      "Optimization time for model  29 :  0.0001289844512939453\n",
      "Optimization time for model  30 :  0.00012183189392089844\n",
      "Optimization time for model  31 :  0.4284939765930176\n",
      "Optimization time for model  0 :  0.06361103057861328\n",
      "Optimization time for model  1 :  0.00014090538024902344\n",
      "Optimization time for model  2 :  0.00015306472778320312\n",
      "Optimization time for model  3 :  2.0408170223236084\n",
      "Optimization time for model  4 :  0.00015306472778320312\n",
      "Optimization time for model  5 :  0.0026900768280029297\n",
      "Optimization time for model  6 :  1.6086549758911133\n",
      "Optimization time for model  7 :  0.00015306472778320312\n",
      "Optimization time for model  8 :  0.00015997886657714844\n",
      "Optimization time for model  9 :  2.9477360248565674\n",
      "Optimization time for model  10 :  0.0001862049102783203\n",
      "Optimization time for model  11 :  0.0001270771026611328\n",
      "Optimization time for model  12 :  0.00017690658569335938\n",
      "Optimization time for model  13 :  0.0001678466796875\n",
      "Optimization time for model  14 :  0.36800217628479004\n",
      "Optimization time for model  15 :  0.0002009868621826172\n",
      "Optimization time for model  16 :  0.00020384788513183594\n",
      "Optimization time for model  17 :  0.00019121170043945312\n",
      "Optimization time for model  18 :  0.00017905235290527344\n",
      "Optimization time for model  19 :  0.00019693374633789062\n",
      "Optimization time for model  20 :  0.0001289844512939453\n",
      "Optimization time for model  21 :  0.0001671314239501953\n",
      "Optimization time for model  22 :  0.0001220703125\n",
      "Optimization time for model  23 :  0.0001659393310546875\n",
      "Optimization time for model  24 :  0.00017595291137695312\n",
      "Optimization time for model  25 :  0.00016999244689941406\n",
      "Optimization time for model  26 :  0.39542508125305176\n",
      "Optimization time for model  27 :  0.00013113021850585938\n",
      "Optimization time for model  28 :  0.0001761913299560547\n",
      "Optimization time for model  29 :  0.0001480579376220703\n",
      "Optimization time for model  30 :  0.49051594734191895\n",
      "Optimization time for model  31 :  0.0001418590545654297\n",
      "Optimization time for model  0 :  0.0001418590545654297\n",
      "Optimization time for model  1 :  8.46695590019226\n",
      "Optimization time for model  2 :  0.000141143798828125\n",
      "Optimization time for model  3 :  0.0001938343048095703\n",
      "Optimization time for model  4 :  0.0074918270111083984\n",
      "Optimization time for model  5 :  1.4990530014038086\n",
      "Optimization time for model  6 :  0.0002028942108154297\n",
      "Optimization time for model  7 :  0.00017404556274414062\n",
      "Optimization time for model  8 :  0.0001690387725830078\n",
      "Optimization time for model  9 :  0.00012302398681640625\n",
      "Optimization time for model  10 :  0.0001239776611328125\n",
      "Optimization time for model  11 :  0.0001678466796875\n",
      "Optimization time for model  12 :  0.00011587142944335938\n",
      "Optimization time for model  13 :  0.00016999244689941406\n",
      "Optimization time for model  14 :  0.000141143798828125\n",
      "Optimization time for model  15 :  0.9889841079711914\n",
      "Optimization time for model  16 :  0.00015616416931152344\n",
      "Optimization time for model  17 :  0.0002181529998779297\n",
      "Optimization time for model  18 :  0.00012993812561035156\n",
      "Optimization time for model  19 :  0.00012493133544921875\n",
      "Optimization time for model  20 :  0.00014710426330566406\n",
      "Optimization time for model  21 :  0.0031180381774902344\n",
      "Optimization time for model  22 :  0.00013017654418945312\n",
      "Optimization time for model  23 :  0.0001239776611328125\n",
      "Optimization time for model  24 :  0.00012087821960449219\n",
      "Optimization time for model  25 :  0.00017309188842773438\n",
      "Optimization time for model  26 :  0.000141143798828125\n",
      "Optimization time for model  27 :  0.0001201629638671875\n",
      "Optimization time for model  28 :  0.00013899803161621094\n",
      "Optimization time for model  29 :  0.000164031982421875\n",
      "Optimization time for model  30 :  0.00011992454528808594\n",
      "Optimization time for model  31 :  0.0001220703125\n",
      "Optimization time for model  0 :  0.00018215179443359375\n",
      "Optimization time for model  1 :  3.2901771068573\n",
      "Optimization time for model  2 :  0.0001919269561767578\n",
      "Optimization time for model  3 :  0.0001239776611328125\n",
      "Optimization time for model  4 :  0.00012493133544921875\n",
      "Optimization time for model  5 :  0.5659329891204834\n",
      "Optimization time for model  6 :  0.00013589859008789062\n",
      "Optimization time for model  7 :  0.00017690658569335938\n",
      "Optimization time for model  8 :  0.0007250308990478516\n",
      "Optimization time for model  9 :  0.07112884521484375\n",
      "Optimization time for model  10 :  2.4789772033691406\n",
      "Optimization time for model  11 :  0.0001380443572998047\n",
      "Optimization time for model  12 :  0.00012302398681640625\n",
      "Optimization time for model  13 :  0.014943122863769531\n",
      "Optimization time for model  14 :  0.0001800060272216797\n",
      "Optimization time for model  15 :  0.00012803077697753906\n",
      "Optimization time for model  16 :  0.00016999244689941406\n",
      "Optimization time for model  17 :  0.0001671314239501953\n",
      "Optimization time for model  18 :  0.00012302398681640625\n",
      "Optimization time for model  19 :  0.00011920928955078125\n",
      "Optimization time for model  20 :  0.0001201629638671875\n",
      "Optimization time for model  21 :  0.8865818977355957\n",
      "Optimization time for model  22 :  0.0001811981201171875\n",
      "Optimization time for model  23 :  0.00012493133544921875\n",
      "Optimization time for model  24 :  0.006880044937133789\n",
      "Optimization time for model  25 :  0.00013399124145507812\n",
      "Optimization time for model  26 :  0.0001289844512939453\n",
      "Optimization time for model  27 :  0.0001518726348876953\n",
      "Optimization time for model  28 :  0.0001418590545654297\n",
      "Optimization time for model  29 :  0.00017118453979492188\n",
      "Optimization time for model  30 :  0.00016808509826660156\n",
      "Optimization time for model  31 :  0.00011801719665527344\n",
      "Optimization time for model  0 :  0.0001800060272216797\n",
      "Optimization time for model  1 :  0.0001277923583984375\n",
      "Optimization time for model  2 :  0.00012302398681640625\n",
      "Optimization time for model  3 :  0.00017213821411132812\n",
      "Optimization time for model  4 :  0.14014196395874023\n",
      "Optimization time for model  5 :  0.00012993812561035156\n",
      "Optimization time for model  6 :  0.35994410514831543\n",
      "Optimization time for model  7 :  0.025128841400146484\n",
      "Optimization time for model  8 :  0.00021505355834960938\n",
      "Optimization time for model  9 :  0.0001430511474609375\n",
      "Optimization time for model  10 :  0.0001220703125\n",
      "Optimization time for model  11 :  0.022099018096923828\n",
      "Optimization time for model  12 :  0.00013303756713867188\n",
      "Optimization time for model  13 :  0.0001819133758544922\n",
      "Optimization time for model  14 :  0.00016999244689941406\n",
      "Optimization time for model  15 :  0.0001881122589111328\n",
      "Optimization time for model  16 :  0.48902201652526855\n",
      "Optimization time for model  17 :  0.0001327991485595703\n",
      "Optimization time for model  18 :  0.00017905235290527344\n",
      "Optimization time for model  19 :  0.00013399124145507812\n",
      "Optimization time for model  20 :  0.006618022918701172\n",
      "Optimization time for model  21 :  2.557596206665039\n",
      "Optimization time for model  22 :  0.0002009868621826172\n",
      "Optimization time for model  23 :  0.00018405914306640625\n",
      "Optimization time for model  24 :  0.0001728534698486328\n",
      "Optimization time for model  25 :  0.00014495849609375\n",
      "Optimization time for model  26 :  0.0205230712890625\n",
      "Optimization time for model  27 :  0.00018596649169921875\n",
      "Optimization time for model  28 :  0.00014901161193847656\n",
      "Optimization time for model  29 :  0.00014400482177734375\n",
      "Optimization time for model  30 :  0.00017595291137695312\n",
      "Optimization time for model  31 :  0.0001862049102783203\n",
      "Optimization time for model  0 :  0.3421599864959717\n",
      "Optimization time for model  1 :  0.000186920166015625\n",
      "Optimization time for model  2 :  0.00017595291137695312\n",
      "Optimization time for model  3 :  0.0001671314239501953\n",
      "Optimization time for model  4 :  0.5110511779785156\n",
      "Optimization time for model  5 :  0.00015306472778320312\n",
      "Optimization time for model  6 :  0.00014019012451171875\n",
      "Optimization time for model  7 :  0.00017499923706054688\n",
      "Optimization time for model  8 :  0.01838397979736328\n",
      "Optimization time for model  9 :  0.00019598007202148438\n",
      "Optimization time for model  10 :  4.071478843688965\n",
      "Optimization time for model  11 :  0.0002357959747314453\n",
      "Optimization time for model  12 :  0.0002009868621826172\n",
      "Optimization time for model  13 :  0.007035017013549805\n",
      "Optimization time for model  14 :  0.41610193252563477\n",
      "Optimization time for model  15 :  1.2379651069641113\n"
     ]
    }
   ],
   "source": [
    "test_models = []\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "model_files = os.listdir(\"instances/mip/data/COR-LAT\")\n",
    "for i in range(len(test_idx)):\n",
    "    model = gb.read(\"instances/mip/data/COR-LAT/\" + model_files[test_idx[i]], env=gurobi_env)\n",
    "    test_models.append(model)\n",
    "    \n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time = []\n",
    "for i, data in enumerate(valid_loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # get slices of test_models according to batch size\n",
    "    len_test_models = len(test_models)\n",
    "\n",
    "    test_models_batch = test_models[i*batch_size: min((i+1)*batch_size, len_test_models)]\n",
    "    \n",
    "    opt_time_batch = calculate_diving_opt_time(test_models_batch, binary_indices, outputs.detach().cpu().numpy())\n",
    "    \n",
    "    opt_time.append(opt_time_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average optimization time:  0.29866028432581826\n"
     ]
    }
   ],
   "source": [
    "# flatten opt_time\n",
    "opt_time_flat = [item for sublist in opt_time for item in sublist]\n",
    "\n",
    "print(\"Average optimization time: \", np.mean(opt_time_flat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "# save neural network model\n",
    "print(\"Saving model...\")\n",
    "# statedict\n",
    "torch.save(net.state_dict(), \"Models/Tabular/neural_network_model_corlat.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91040/2751798150.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = y_test.astype(np.int)\n",
      "/tmp/ipykernel_91040/2751798150.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = y_train.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model\n",
    "y_test = y_test.astype(np.int)\n",
    "y_train = y_train.astype(np.int)\n",
    "clf = XGBClassifier(tree_method='hist')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9237003241685676\n",
      "Precision:  0.9232569302772111\n",
      "Recall:  0.9241441441441441\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score: \", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "# save xgboost model\n",
    "print(\"Saving model...\")\n",
    "pkl.dump(clf, open(\"Models/Tabular/xgboost_model_corlat.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to load the model net = NeuralNetwork()\n",
    "net.load_state_dict(torch.load(\"Models/Tabular/neural_network_model_corlat.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load xgboost model\n",
    "clf = pkl.load(open(\"Models/Tabular/xgboost_model_corlat.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_767776/551078606.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = y_test.astype(np.int)\n",
      "/tmp/ipykernel_767776/551078606.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = y_train.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test = y_test.astype(np.int)\n",
    "y_train = y_train.astype(np.int)\n",
    "y_pred = clf.predict(X_test.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9237003241685676\n",
      "Precision:  0.9232569302772111\n",
      "Recall:  0.9241441441441441\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score: \", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n",
      "Model is feasible\n"
     ]
    }
   ],
   "source": [
    "binary_indices = corlat_dataset[0][\"indices\"][\"indices\"]\n",
    "    \n",
    "n_violated_constraints = feasibility_test(len(y_pred), y_pred, test_models, binary_indices)    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of violated constraints:  3.78\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of violated constraints: \", np.mean(n_violated_constraints))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (optimization)",
   "language": "python",
   "name": "optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
